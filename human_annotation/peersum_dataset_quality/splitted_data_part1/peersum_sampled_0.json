{"source_documents": ["We tackle the problem of deep object-centric learning from a point cloud which is crucial for high-level relational reasoning and scalable machine intelligence. \nIn particular, we introduce a framework, SPAIR3D, to factorize a 3D point cloud into a spatial mixture model where each component corresponds to one object. \nTo model the spatial mixture model on point clouds, we derive the Chamfer Mixture Loss, which fits naturally into our variational training pipeline. Moreover, we adopt an object-specification scheme that describes each object’s location relative to its local voxel grid cell. \nSuch a scheme allows SPAIR3D to model scenes with an arbitrary number of objects. \nWe evaluate our method on the task of unsupervised scene decomposition.\nExperimental results demonstrate that SPAIR3D has strong scalability and is capable of detecting and segmenting an unknown number of objects from a point cloud in an unsupervised manner.", " 1. As pointed out by the reviewer yyA6, improving the performance of SPAIR3D on a real-world dataset can take some extra effort but is definitely possible.\nOne key design is to use a voxel grid with multiple scales and transform the generative model to its hierarchical version.\nNote that SPAIR3D is already a two-layer hierarchical structure (entire scene, each object).\nBut this idea is not even implemented in the 2D object-centric learning community where the original SPAIR framework is proposed.\nWe believe that a pipeline built on this idea can perform well and deal with objects of different sizes.\nBut that will take more than one paper to complete.\nAlso, we want to highlight the fact that, the SPAIR framework, among all generative based object-centric learning frameworks, is most suitable to point cloud data since the glimpse structure allows point-cloud reconstruction in its local coordinate while other frameworks reconstruct under the global coordinate. Uncentered point cloud-based object reconstruction is itself a really challenging work.\n\n2. As suggested by reviewer yyA6, we conduct additional experiments on the S3DIS dataset. The results can be found in the supplementary zip file. As the first work that extends the SPAIR framework to point cloud, we hope through this work to show the potential to borrow ideas from the generative model-based object-centric learning community.\nReviewer yyA6 and orM7 agree that while with some limitations, this work, being the first work on this line, demonstrates the potential of this idea.\n\n3. The ground can be segmented from the objects due to our prior glimpse sizes.\nThe prior encourages glimpse to shrink and to contain only the parts that cannot be modeled well by other components.\nSince the ground can be modeled well by our scene layout branch, there is no reason to keep them as part of foreground objects.\nFor stacked objects, the concerns are different.\nFor objects with similar sizes, with the missing surfaces, one glimpse may be able to model them well.\nIf object sizes are too different, then that falls back to the large object concerns.\n\n4. We will enlarge the legends as suggested. Thanks for your suggestion\n", " Thanks for the responses. \n\nAfter reading the authors' responses and other reviews, I am curious that whether Spair3D can deal with scenes with objects of varying sizes. In the paper, the objects in each scene are similar in size. In real life, it is common that some objects are way larger than others. Is it possible that the Chamfer Mixture Loss can work for this kind of data? \n\nI do not quite agree with the authors about the first reason for using synthetic data, you can totally train on unlabeled data to show the power of unsupervised training, and test on synthetic datasets. It is fair to compare on a generated evaluation set which is unseen for all methods. I guess the second reason is the major one, it is common that captured point clouds are often incomplete. \n\nWhen two objects are stacked, if they are not able to be separated due to the missing points on touching surfaces. I am curious that why objects and the ground can be separated, as in all the demos in the paper. \n\nFurthermore, it would be good to enlarge the legends in Figure 1, which is a little bit hard to read in the current version. ", " Given the authors' rebuttal, I would like to keep my rating. Although the proposed method is currently limited, e.g., relatively easy dataset without occlusion and strong size prior, it shows the potential of learning-based unsupervised 3D instance segmentation methods (compared against classical heuristic methods).", " 1. Thanks for the authors' detailed reply! I appreciate the careful comments on 1. Chamfer mixture loss and 6. concept of \"information bottleneck\" and the loss design. The locally divided glimpse makes the computation affordable on common GPUs. \n\n2. Regarding the additional results on S3DIS, both visually and quantitatively it didn't look impressive to me as also pointed out by Reviewer PtZ1. The method simply fails on long and complex objects, possibly failing at the step when determining the boundaries from each glimpse. But this is as expected, as the originally proposed pipeline is mainly designed to handle more complete and simple point clouds using the local anchor-like glimpse mechanism and reconstruction loss. It seems the main bottleneck comes from the reconstruction heads. Based on the author's pipeline, there should be a few easy fixs to tune the pipeline for real-world data, like weighting the two different items of mixture Chamfer loss, using multiple scales of the same input to deal with objects with different sizes and adding post merging, and etc. \n\n3. When it comes to the evaluation of this paper, I still think this work well demonstrated the possibility of unsupervised learning of 'object' concept using information bottleneck principles from 3D scene point cloud data for the first time. While its application to 3D instance segmentation is not that good on real-world data, it promises future directions left to be explored. When there is no texture information and other necessary prior knowledge, it is even hard for us human to tell apart different 'objects'. \n\nBased on existing discussions I'd like to keep my original rating, but open to further opinions from other reviewers. ", " We would like to thank all reviewers for their feedback.\nWe're happy to hear that reviewers agree that our paper \"is a pioneering work that extends the success of unsupervised object-centric learning in 2D images to 3D scene point clouds\"(yyA6) and \"is the first to extend 2D object-centric representation learning to 3D point clouds\"(orM7).\nA major concern raised by reviewers is the simplicity of our simulated dataset.\nTo demonstrate the effectiveness of our model, we follow suggestions from reviewers and conduct experiments on the S3DIS dataset.\nThe S3DIS dataset contains point clouds of real-world indoor scenes of varying sizes.\nWe report that our model achieves in mIoU Chair: 0.603, Table: 0.375, and Sofa: 0.482.\nAs a baseline, we also report that the Meanshift (with floors manually removed) achieves Chair:0.634, Table:0.297, Sofa:0.272.\nDetailed experimental setup, quantitative results as well as qualitative visualizations can be found in the supplementary zip file.\n\nWe also test our model on the UOR dataset with varying point density or with injected noises.\nThe results show that the performance of our model is stable under such variations.\nSee supplementary zip file for details.\n\nWe would like to emphasize that, our work mainly focuses on object-centric representation learning that produces meaningful object representation with unsupervised instance segmentation as one application.\n\nBuilt on the widely adopted SPAIR framework (especially for 2D images), SPAIR3D paves the way to taking advantage of the rich unsupervised techniques developed in the 2D object-centric learning community.\n", " I appreciate the authors' efforts in the rebuttal.\n\nThe additional experiments on S3DIS dataset with real world scans are much more sensible than the original results on uniform-sized objects and clean scenes. However, the results suggest that the model hardly outperforms the simple clustering baseline Meanshift in these noisy real world scenes. I think these results do not appear convincing enough to me for the claim of effective unsupervised object centric learning.\n\nBesides, I find the authors' argument on uncolored point clouds slightly misleading. 3D point clouds do not necessarily have to be textureless; in fact, it is often much easier to obtain color information compared the scans themselves. It is a restriction of the setup in this paper. Of course there are use cases of a method dealing with untextured point clouds, but I find it misleading to claim 3D point clouds are more challenging because they come with no color information.\n\nOverall, I think the proposed method might be interesting, but do not think the currents results are convincing enough, and will keep my rating at 5.", " We thank the reviewer for the suggested baseline and we are glad that the reviewer finds that our results and analysis provide meaningful insights.\nWhile openreview no longer allows us to update our writing at the moment,  we will certainly include the new results and the analysis in our appendix.", " Thanks for the timely update.\n\nIt is nice to see the comparison against classical heuristic methods, and I suggest it could be included in the appendix to provide readers with more insights into the advantage of learning-based unsupervised scene decomposition methods. Besides, I understand that since SPAIR, most related works have not analyzed how their inductive bias affects the performance compared to VAE (especially probability modeling). From my personal experience, sometimes SPAIR-style framework still can work if there are no latent codes for each glimpse (e.g., a single-shot detection/reconstruction framework). However, there are no strong 2D heuristic baselines. Thus, the comparable performance of heuristic baselines somehow indicates the inductive bias is at least as important as VAE for unsupervised scene decomposition, which is valuable to the community.", " We thank reviewer or7M for their feedback\n\n1. Following your suggestion, we introduce a rule-based baseline on the cleaned S3DIS dataset (see the supplementary zip file for details) with floors manually removed.\nWe tried both the Meanshift and the DBSCAN algorithm.\nThe best results are achieved by the Meanshift algorithm after doing the grid-search on the bandwidth parameter for chairs and tables separately.\nWith the bandwidth tuned for chair (0.05), the best mIoU is Chair:0.634, Table:0.297, Sofa:0.272.\nWith the bandwidth tuned for table (0.1), the best mIoU is Chair:0.535, Table:0.442, Sofa:0.471.\nAs stated in the supplementary zip file, our model achieves Chair: 0.603, Table:0.375, and Sofa: 0.482.\nNote that the bandwidth parameter of the Meanshift algorithm reflects the average object size.\nThus, when the bandwidth is tuned for chairs whose sizes are much smaller on average compared to tables, tables and sofas are largely over-segmented, hence resulting in the low value in mIoU.\nWhen the bandwidth is tuned for tables, chairs tend to be under-segmented.\nFor our work, while the average sizes of tables and sofas are much larger than the maximum glimpses sizes, SPAIR3D still tries to expand the glimpses sizes to better model larger objects while keeping the total number of glimpses low.\nWe believe that the relaxation of the glimpses sizes limitation is a key research direction for our future work.\n\n2. Yes, beta-VAE is known for better feature disentanglement, and in our work, the major disentanglement is enforced by our network structure.\nHowever, due to the KL regularisation,  VAE, in general, presents a more structured latent space where each class tends to occupy one connected region, as shown in Fig. 3 in our paper.\nVAE is adopted by not only derivations of SPAIR but almost all generative model based unsupervised object-centric representation learning frameworks [1,2,3,4,5,6].\nIt is fair to say that VAE is the default choice in the object-centric representation learning community.\nThe KL term also allows a dynamic trade-off between information budget and reconstruction likelihood during the training process either via weights annealing (this work) or in a systematic way [7].\nSuch fine level control is not possible with AE where one can only set the dimension of the latent variable.\nIn this work, we want to demonstrate that the SPAIR framework (with VAE being a core component) can be extended to point cloud data which is confirmed by our experimental results.\nPotential modification/improvement on the SPAIR framework, in general, is beyond the scope of our work.\n\n[1] Christopher Burgess, Loic Matthey, Nicholas Watters, Rishabh Kabra, Irina Higgins, Matt Botvinick,\nand Alexander Lerchner. Monet: Unsupervised scene decomposition and representation. ArXiv,\nabs/1901.11390, 01 2019. URL https://arxiv.org/abs/1901.11390.\n\n[2] Eric Crawford and Joelle Pineau. Spatially invariant unsupervised object detection with convolutional\nneural networks. AAAI, 33:3412–3420, 07 2019. doi: 10.1609/aaai.v33i01.33013412.\n\n[3] Eric Crawford and Joelle Pineau. Exploiting spatial invariance for scalable unsupervised object\ntracking. AAAI, 34:3684–3692, 04 2020. doi: 10.1609/aaai.v34i04.5777.\n\n[4] Martin Engelcke, Adam R. Kosiorek, Oiwi Parker Jones, and Ingmar Posner. Genesis: Generative\nscene inference and sampling with object-centric latent representations. In ICLR, 2020. URL\nhttps://openreview.net/forum?id=BkxfaTVFwH.\n\n[5] Paul Henderson and Christoph H. Lampert. Unsupervised object-centric video generation and\ndecomposition in 3D. In NeurIPS, 2020.\n\n[6] Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri, Weihao Sun, Gautam Singh, Fei Deng, Jindong\nJiang, and Sungjin Ahn. Space: Unsupervised object-oriented scene representation via spatial\nattention and decomposition. In ICLR, 2020. URL https://openreview.net/forum?\nid=rkl03ySYDH.\n\n[7] Danilo Jimenez Rezende and Fabio Viola. Taming VAEs. arXiv preprint arXiv:1810.00597, 2018.", " Thanks for the authors' reply.\n\n1. The reason why it is better to compare with a heuristic-based method is that it is really a strong and in fact generalizable baseline on 3D scenes. A very special property of 3D scenes is that objects are usually spatially separable. For example, such cluster-based segmentation (DB-Scan, Meanshift, connected component) methods can work quite well even on both indoor and outdoor real scenes (like ScanNet and SemanticKitti). With slight efforts on parameter tunning, such baselines can perform on par with learning-based methods (e.g. GSPN) on ScanNet instance segmentation. Moreover, the proposed SPAIR3D in fact shares some underlying ideas with GSPN[1], except GSPN is a supervised method.\nFrom my perspective, the heuristic-based method is usually spatial-invariant as well, and can deal with input of arbitrary size. Since the SPAIR3D also needs hyperparameters for glimpse/cell size, it is hard to tell whether SPAIR3D is a more robust and generalizable method.\nHowever, object-centric representation is indeed useful, which can distinguish SPAIR3D from those spatial heuristic-based methods. Thus, I agree with the contribution of SPAIR3D, but can not agree with the explanation why the authors do not compare with those strong baselines.\n\n2. I think beta-VAE focuses on the disentanglement of latent factors; however, in this work, such disentanglement is implicitly achieved by the inductive bias of network architectures. Thus, it is quite different. Please correct me if I am wrong.\n\n[1] Gspn: Generative shape proposal network for 3d instance segmentation in point cloud", " Minor comments: \nIn Figures 2 (i) and (j), the value of alpha is shown by colors.\nWe use the standard \"plasma\" color map from the matplotlib where bright yellow is 1 and dark blue is zero.\n\"Invariant\" means that the foreground glimpse encoder and decoder operate without knowing the global coordinates of the points, which is the key to high scalability.\nNote that by using GNN with a fixed radius, we implicitly make the assumption that only local information is needed to detect objects.\nThus, it is spatially invariant like a CNN layer on a 2D image.\nA CNN layer can take a 2D image with an arbitrary size, so can our foreground VAE.\nMore glimpse visualization can also be found in the supplementary file  Sec. 3.\n\nHopefully, the majority of your concerns are addressed.\nPlease let us know if you have further concerns.\n\n[1] Klaus Greff, Rapha ̈el Lopez Kaufman, Rishabh Kabra, Nick Watters, Christopher Burgess, Daniel Zoran, Lo ̈ıc Matthey, Matthew M Botvinick, and Alexander Lerchner Multi-object representation learning with iterative variational inference. In ICML, 2019.\n\n[2] Paul Henderson and Christoph H. Lampert. Unsupervised object-centric video generation and decomposition in 3D. In NeurIPS, 2020.\n\n[3] Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri, Weihao Sun, Gautam Singh, Fei Deng, Jindong Jiang, and Sungjin Ahn. Space: Unsupervised object-oriented scene representation via spatial attention and decomposition. In ICLR, 2020.\n\n[4] Francesco Locatello, Dirk Weissenborn, Thomas Unterthiner, Aravindh Mahendran, Georg Heigold, Jakob Uszkoreit, Alexey osovitskiy, and Thomas Kipf. Object-centric learning with slot attention. In NeurIPS, 2020\n\n[5] rina Higgins, Lo ̈ıc Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew M Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In ICLR, 2017\n\n[6] Christopher P. Burgess, Irina Higgins, Arka Pal, Lo ̈ıc Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner. Understanding disentangling in beta-vae. ArXiv, abs/1804.03599, 2018.", " We thank the reviewer for the feedback.\nBelow we address the concerns.\n\n1. Rule-based baseline:\nYes, for the UOR and UOT datasets, the rule-based segmentation method should indeed achieve good segmentation results. \nHowever, we consider our work an attempt to achieve object-centric learning on point cloud data.\nThe object representation embedding is shown in figure 7 also shows that our learned representation is meaningful.\nThe rule-based baseline does not learn an object-centric representation that can be used for downstream tasks.\nSegmentation is only an application of our method and is evidence that our model indeed learns representation in an object-centric way.\nAlso, the rule-based baselines do not allow the sampling of new objects.\nScalability: our foreground VAE model is agnostic to the absolute coordinate of input points and only works on a local receptive field.\nThus, it is spatially invariant, just like a CNN layer.\nA CNN layer can take a 2D image with an arbitrary size, so can our foreground VAE.\nOur model essentially learns a probability distribution p(o|z) where o is the observation and z is the latent variable.\nThis probability interpretation makes our model compatible with other probabilistic frameworks like SLAM.\nWe thank the reviewer for bringing the related over-segmentation baselines to our attention.\n\n2. VAE is crucial to representation learning, and this result is established by well-cited papers [1][2].\nWe detailed the important role of VAE and KL terms in point 6 of our replies to reviewer yyA6. \n\n3. The main difference between our Chamfer mixture loss and Chamfer distance is at the backward exponential weighting.\nThe proposed glimpses inevitably contain points that do not belong to the corresponding objects.\nThe backward exponential weighting makes sure that such points have no influence on the final likelihood and thus do not pull generated points toward their location.\nAs a consequence, those points do not have effects on glimpse center and size prediction.\nIn single object reconstruction tasks, this is never an issue since all points are known to belong to the one object in the scene.\nOn the UOR dataset, we rerun our experiments without exponential weighting, and the ARI score drops from 0.915 to 0.552.\n\n4. Partial observation:\nYour conclusion about partial observation is correct.\nEven with a complete supervision point cloud, partial observation is quite challenging for our model for two reasons.\n(1) With partial information it is hard to determine the correct object location.\n(2) With partial information it is hard to determine the number of points to generate for each glimpse.\nThus, our current model cannot handle partial observations.\nTo further evaluate our model, we run additional experiments.\nThe results are shown in the newly updated supplementary zip file.\n\nHopefully, the majority of your concerns are addressed.\nPlease let us know if you have further concerns.\n\n[1] rina Higgins, Lo ̈ıc Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew M Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In ICLR, 2017\n\n[2] Christopher P. Burgess, Irina Higgins, Arka Pal, Lo ̈ıc Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner. Understanding disentangling in beta-vae. ArXiv, abs/1804.03599, 2018.\n", " We thank the reviewer for the detailed feedback and the acknowledgment of our contribution as a pioneering work for object-centric learning for the 3D scene point cloud.\nBelow we address the concerns.\n\n1. Compared with training a point cloud generation model for the entire scene as a whole, the time complexity of chamfer mixture loss for foreground objects is, in fact, much lower.\nThe key to reducing the time complexity is the local glimpse proposal scheme.\nWhen computing the chamfer mixture loss, the bidirectional closest point searching only happens within each glimpse.\nNamely, we do not need to compute the pairwise distance for the point cloud of the scene but rather for points only within each glimpse.\nHere we provide an example to illustrate the reduced magnitude of time complexity.\nAssume a scene consists of 10,000 points.\nWe need to compute the distances of 50 million unique pairs of points.\nIn contrast, there are around 1,000 points (10% of 10,000) in each glimpse, and 500k (1% of 50,000,000) unique pairs of points.\nThus, with non-overlapping voxel grid cells, the total time complexity should be much lower than twice of chamfer distance.\nWe believe the irregularity of point cloud is of both pros and cons.\nIndeed, voxel is a plausible way to obtain correspondences.\nBut it is known that computation on voxel data tends to consume a large amount of memory.\nMore importantly, under the regularity of voxel, gradient w.r.t to glimpse parameters are harder to obtain.\nOne benefit of working with point cloud is that the point coordinates are real-valued and thus differentiable w.r.t coordinate transformation, including but not limited to scaling, translation, and rotation.\n\n2. &\n3. We follow the reviewer’s suggestion and evaluate our approach on S3DIS, a real dataset for 3D scenes.\nOur experiments mainly focus on scenes with regular object structures.\nWe run additional experiments, and the results are shown in the newly updated supplementary files for clarity.\nRegarding partial observation, the main difficulty of working with partial observation (but complete supervision) is to determine the number of points in the reconstructed point cloud.\nThe big difference between the number of reconstruction points and the number of input points destroys the balance between the forward and the backward loss.\n\n4. Below, we provide more detail regarding our pipeline.\nIt is expected that each glimpse contains a varying but non-zero number of points.\nBoth the PointConv layer and the PointGNN layer are not constrained to the input of a fixed number of points.\nReference of those two types of layers can be found in Sec. 3.4.\nForeground glimpse encoder and decoder process all glimpses in parallel as each glimpse only focus on a local region.\nIn our implementation, all glimpses are extracted and batched before being sent into the encoder.\nAll weights are the same for global VAE and glimpse VAE.\n\n5. We thank the reviewer for bringing this work to our attention.\nThis work has a different setup to ours but is definitely related to our topics.\nWhile this work requires rough bounding boxes/spheres of the target objects (which already requires prior knowledge) and detects one type of object at a time, our model process the entire scene in one go.", " We believe that our work is inspiring for the community for two reasons.\n\n(1) For the 3D point cloud community, we show that it is possible to learn a generative model that can naturally decompose scenes. \nAlmost all previous (single object) point cloud generation pipeline requires the reconstruction target to be centered and normalized.\nWhen it comes to object-centric scene generation, it is almost impossible to require all parts of the raw input to be centered and normalized at the same time.\nThe local attention mechanism and the spatial invariant property of our model make sure that all objects are reconstructed in their local object coordinate systems instead of the global coordinate.\n\n(2) For the object-centric learning community, we show that the generative model-based/the VAE based object-centric learning idea can be applied to not only color but to spatial structure as well.\nWith more and more data modalities added, the object-centric representation should be more and more meaningful.\n\nHopefully, the majority of your concerns are addressed.\nPlease let us know if you have further concerns.\n\n[1] Klaus Greff, Rapha ̈el Lopez Kaufman, Rishabh Kabra, Nick Watters, Christopher Burgess, Daniel Zoran, Lo ̈ıc Matthey, Matthew M Botvinick, and Alexander Lerchner Multi-object representation learning with iterative variational inference. In ICML, 2019.\n\n[2] Paul Henderson and Christoph H. Lampert. Unsupervised object-centric video generation and decomposition in 3D. In NeurIPS, 2020.\n\n[3] Zhixuan Lin, Yi-Fu Wu, Skand Vishwanath Peri, Weihao Sun, Gautam Singh, Fei Deng, Jindong Jiang, and Sungjin Ahn. Space: Unsupervised object-oriented scene representation via spatial attention and decomposition. In ICLR, 2020.\n\n[4] rina Higgins, Lo ̈ıc Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew M Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. In ICLR, 2017\n\n[5] Christopher P. Burgess, Irina Higgins, Arka Pal, Lo ̈ıc Matthey, Nick Watters, Guillaume Desjardins, and Alexander Lerchner. Understanding disentangling in beta-vae. ArXiv, abs/1804.03599, 2018.\n", " We thank the reviewer for their time.\n\n*1. While our work is indeed built on SPAIR, at the beginning of Sec 3, we detail the gap between this work and previous literature, the major challenges, and our novel solutions to those challenges.\n\n*2. The reviewer may miss Sec 4.5 and 4.6.\nThe effectiveness of the multi-layer PointGNN z_pres decoder is proven by the ablation study in Sec, 4.5.\nThe effectiveness of Point Graph Decider is demonstrated in Sec, 4.6.\nThe main difference between our Chamfer mixture loss and Chamfer distance is at the backward exponential weighting.\nThe proposed glimpses inevitably contain points that do not belong to the corresponding objects.\nThe backward exponential weighting makes sure that such points have no influence on the likelihood and do not pull the generated points toward their location.\nIn single object reconstruction tasks, this is not an issue since all points are known to belong to the one object in the scene.\nOn the UOR dataset, we rerun our experiments without exponential weighting, and the ARI score drops from 0.915 to 0.552.\nTo further evaluate our model, we run additional experiments.\nThe results are shown in the newly uploaded supplementary zip file.\n\n*3. The complete definition of ELBO is provided in the last paragraph of Sec. 3.3.\nDue to limited space, we give the definition of the L_KL term in appendix A equation (2).\nThe derivation of ELBO follows the vanilla variational inference framework.\nWe will make the section clear.\n\n*4 Similar to previous works on generative model-based scene decomposition [1][[2][3], our model relies on the concept of \"information bottleneck\". Unsupervised object-centric learning is essentially an attempt to define objectness. While rule-based unsupervised segmentation algorithms code low-level heuristics/human prior knowledge directly, generative model-based object-centric models are built on a high-level heuristic. That is, the concept of \"objectness\" is a consequence of agents trying to model the world as accurately as possible but also trying to process as little information as possible due to the limited computational power.\n\nThat is, the term \"object\" should refer to matters that are highly correlated with each other. Correlation means both predictability and compressibility. Using VAE is a good way to enforce such high-level heuristics. In fact, a VAE effectively compresses the input and tries to reconstruct it under an information budget. Thus, highly correlated parts of inputs are forced to be compressed together, and the union of those parts is considered an object. See beta-VAE related work [4][5] for the in-depth introduction.\n\nFrom the technical perspective, the segmentation performance is a consequence of the balance between multiple terms. \n\n(1) reconstruction likelihood: One trivial suboptimal of the forward likelihood is to distribute reconstruction points densely and evenly across the entire space so that for any input point there exists a close reconstruction point. One trivial suboptimal of the backward loss is to distribute all reconstruction points close to one input point. The balance between the number of input points and reconstruction points suggests the trivial suboptimal for one loss is an extremely bad solution for the other loss. Also, note that the reconstruction likelihood as a whole encourages over-segmentation. More glimpses lead to smaller parts that are easier to reconstruct compared with the whole object with a non-trivial structure.\n\n(2) KL term of z_pres: to counter the over-segmentation tendency, the prior of z_pres encourages glimpse rejection. Note that once the glimpse is rejected, this glimpse will not increase the final loss. \n\n(3) KL term of z_what: The KL term of z_what implements the information bottleneck idea. While the KL term of z_pres encourages glimpse rejection, the bottleneck makes sure that one glimpse does not have enough capacity to model all objects well. Most importantly, z_what of scene layout branch makes sure that scene glimpse along cannot achieve a high-quality reconstruction of the entire scene. Compared with AE, VAE allows a trade-off between reconstruction quality and information budget in a dynamic way through the training.\n\n(4) KL term of z_where: This term serves as a tie-breaker. When multiple glimpses try to model the same object, this KL term encourages the closest glimpse to take the object.\n\n(5) KL term of glimpse size and the boundary loss: The size of glimpses is encouraged to shrink so that each object only contains points that absolutely belong to this object. To be more specific, if one part of an object (or floor) is already modeled by one glimpse well, then excluding this part from other glimpses will not decrease the likelihood. The boundary loss changes the hard \"excluding\" process into its soft version. Thus, a point being gradually excluded will change the mask in a differentiable way.\n\nA balance between them gives a good segmentation result.\n\n", " *6. Similar to previous works on generative model-based scene decomposition in 2D or 3D [1][3], our model relies on the concept of \"information bottleneck\". Unsupervised object-centric learning is essentially an attempt to define objectness.\nWhile rule-based unsupervised segmentation algorithms code low-level heuristics/human prior knowledge directly, generative model-based object-centric models are built on a high-level heuristic.\nThat is, the concept of \"objectness\" is a consequence of agents trying to model the world as accurately as possible but at the same time trying to process as little information as possible due to the limited computational power.\n\nTo be more concrete, the term \"object\" should refer to matters that are highly correlated with each other.\nCorrelation means both predictability and compressibility.\nUsing VAE is a good way to enforce such high-level heuristics.\nIn fact, a VAE effectively compresses the input and tries to reconstruct it under an information budget.\nThus, highly correlated parts of inputs are forced to be compressed together, and the union of those parts is considered an object.\nSee beta-VAE related work [5][6] for the in-depth introduction.\n\nPrevious works [1][2][3][4] applied this idea to environments with strong color cues.\nWhile all works following this line heavily rely on color cues, the aim of this work is to show that the information bottleneck principle is general and can be applied to multiple data modalities, including point cloud.\n\nFrom the technical perspective, the segmentation performance is a consequence of the balance between multiple terms.\nBelow we discuss each term in detail.\n\n(1) reconstruction likelihood:\nThe forward likelihood and backward loss each have a trivial suboptimal.\nThe forward loss encourages reconstruction to be close to all input points.\nOne trivial suboptimal is to distribute reconstruction points densely and evenly across the entire space so that for any input point there exists a close reconstruction point.\nThe backward loss encourages reconstruction to be close to at least one input point.\nOne trivial suboptimal is to distribute all reconstruction points close to one input point.\nThe balance between the number of input points and reconstruction points suggests the trivial suboptimal for one loss is an extremely bad solution for the other loss.\nAlso, note that the reconstruction likelihood as a whole encourages over-segmentation.\nMore specifically, more glimpses lead to model parts that are easier to reconstruct compared with the whole object with non-trivial structure.\n\n(2) KL term of z_pres:\nto counter the over-segmentation tendency, the prior of z_pres encourage glimpse rejection.\nNote that once the glimpse is rejected with z_pres = 0, this glimpse will not contribute to the final loss anymore.\nThis design further encourages glimpse rejection.\n\n(3) KL term of z_what:\nThe KL term of z_what implements the information bottleneck idea.\nWhile the KL term of z_pres encourages glimpse rejection, the bottleneck makes sure that one glimpse does not have enough capacity to model more than one object well.\nMost importantly, z_what of scene layout branch makes sure that scene glimpse along cannot achieve a high-quality reconstruction of the entire scene.\nCompared with AE, VAE allows a trade-off between reconstruction quality and information budget within a range.\n\n(4) KL term of z_where:\nThis term serves as a tie-breaker.\nWhen multiple glimpses try to model the same object, this KL term encourages the closest glimpse to take the object.\n\n(5) KL term of glimpse size and the boundary loss:\nThe size of glimpses is encouraged to shrink so that each object only contains points that absolutely belong to this object.\nThat is how floors are excluded from each object.\nTo be more specific, if one part of an object (or floor) is already modeled by one glimpse well, then excluding this part from other glimpses will not decrease the likelihood at all.\nThe boundary loss changes the hard \"excluding\" process into its soft version.\nThus, a point being gradually excluded will change the likelihood or the mask in a differentiable way.\n\nThose terms regularized the behavior of glimpses.\nA balance between them gives a good segmentation result.", " We thank the reviewer for the feedback.\nBelow we address the concerns.\n\n1. Unsupervised generative model training tends to require a large amount of data.\nTake widely adopted 2D object-centric learning datasets as examples,\nThe CLEVR dataset[1] contains 100K images.\n\"Object Room\" by deepmind[2] contains 1M scenes.\nOur model is trained on 50K scenes.\nGenerating data from a simulated environment make sure that we have enough labeled data to use.\nNote that we do need ground truth labels to evaluate the performance and train our supervised baseline.\nThe second reason is that our model works on complete point cloud data.\nAlso, in some complicated scenes, color usually serves as a strong indication of objectness.\nOur model relies purely on structure information.\nTo further evaluate our model, we run additional experiments.\nThe results are shown in the newly updated supplementary zip file.\n\n2. Our complete point clouds are obtained by merging depth maps.\nThus, when objects are stacked on top of each other, it is not possible to capture touching surfaces resulting in an incomplete point cloud.\nIn this case, by structural correlation alone, it is hard to perform the segmentation well.\nBut with other data modalities like RGB, there is a better chance to segment the objects with high accuracy.\n\n3. We thank the reviewer for pointing out the typo.\n\nHopefully, the majority of your concerns are addressed.\nPlease let us know if you have further concerns.\n\n[1] Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Zitnick, and Ross Girshick. Clevr: A diagnostic dataset for compositional language and elementary visual reasoning. pp. 1988–1997, 07 2017. doi: 10.1109/CVPR.2017.215\n\n[2] Rishabh Kabra, Chris Burgess, Loic Matthey, Raphael Lopez Kaufman, Klaus Greff, MalcolmReynolds, and Alexander Lerchner. Multi-object datasets. https://github.com/deepmind/multi-object-datasets/, 2019", " We thank the reviewer for the feedback.\nBelow we address the concerns.\n\n1. When compared with 2D cases, complete 3D point clouds indeed do not have occlusion, but we also lost color as a strong cue of objectness.\nAt the beginning of Sec 3, we detailed the gap between this work and previous literature as well as the major challenges.\nWe believe that extending SPAIR to 3D point cloud is not a trivial task.\n\n2. Via failure examples, we want to show the fact that when our model fails, there tend to be objects that are touching each other or over-size.\nThose two cases are indeed challenging.\nBut other examples in the appendix, especially in Figures 17, 18, show that our model can handle touching objects.\nThe fact that the performance does not drop when evaluated on scenes with 6-12 objects (with much more touching surfaces) shows that our model can handle touching surfaces.\n\n3. As specified in the appendix, the object sizes in our dataset vary in a pre-defined range.\nIn the appendix, we also demonstrate our model on scenes with four walls surrounding the plane.\nThe results show that our model segment walls as part of the scene layout.\nTo address the reviewer's concern, we run additional experiments and train our model with different point densities or added noise.\nFor clarity, we submit our new results in the supplementary zip.\nThe results are shown in the newly updated supplementary file Sec. 2.\n\nHopefully, the majority of your concerns are addressed.\nPlease let us know if you have further concerns.\n", "This paper is a pioneering work that extends the success of unsupervised object-centric learning in 2D images to 3D scene point clouds. The framework could detect and segment multiple 3D objects from a 3D scene point cloud through a decompose-by-reconstruct strategy in an unsupervised manner. \n\nTheir variational training pipeline utilizes a VAE-based generative model that jointly considers the global 3D background and local individual objects, and a novel chamfer mixture loss is proposed for irregular 3D point clouds.  The method is validated on two synthetic datasets, and the performance is demonstrated to be close to a supervised SOTA method.\n \nStrengths\n[novelty]  \n1. According to my knowledge, this is the first work that explores variational generative methods for scene-level 3D point cloud understanding; the learnt representation could be used for unsupervised 3D  instance segmentation, or scene decomposition, while existing methods like PointGroup[Jiang et al.] or 3D-BoNet[Yang et al.] requires ground truth labels to cluster neighborhood points or refine from the detected bounding boxes; \n\n2. The proposed mixture chamfer loss is novel, which treats each point as a Gaussian distribution and turns the original Chamfer distance better for variational inference. It also utilizes a weighting mechanism when deciding each point’s corresponding glimpse, this formulation is critical for closed loop mask prediction;\n\n[effectiveness] \n1. The detection-inspired local voxel attention mechanism makes it possible to handle arbitrary number of objects in the 3D scene, handling well with 2-12 objects from their experiments;\n\n2. The proposed method achieves performance that is on a par with supervised SOTA method on two synthetic scene point cloud datasets, including challenging cases like almost touch surfaces;\n\n[completeness]\nThe author provides both quantitative and qualitative results, with ablation studies on reconstruction point number, voxel size, etc. They also mentioned its drawbacks like handling large objects that are much bigger than the voxel size, mixed objects inside one voxel. \n\n\nWeakness\nThough this work is sound overall, after going through the details carefully in the paper, here I’d like to point out several concerns/issues below. I have examined the key claims over the technical contributions, together with the experimental settings.\n\n1. The chamfer mixture distance loss seems to be critical for the variational model training,  but the additional per-point probability modeling and bidirectional closest point finding, plus multiple glimpse proposals seem to make the loss computation very expensive, does the author have rough estimation of the increased computation compared to the original Chamfer distance loss? One quick related question, is it possible for the reconstruction to come in the form of regular voxels? In this way, regular one-to-one correspondence could be established naturally, without the expensive argmax operation, or searching for the closest pairs;\n\n2. Current experiments are performed on synthetic complete scene point clouds, which is still quite a toy setting. On these datasets, there is strong bias that a flat and clean desk/room background is presented, would it be possible that the model simply learns to discard the flat plane when segmenting the object instead of learning good object-centric representations? A simple way to verify that is trying to tilt the point cloud data, so the desk plane would not be flat. Also I guess the proposed method might be limited when handling partial 3D point clouds, especially for the point cloud reconstruction supervision, is that expected?\n\n3. Following the previous question, is it possible for the proposed method to test on S3DIS dataset as well? This is a common benchmark for 3D instance segmentation and doesn’t have quite challenging partial data. Even though there might be challenging cases due to various object scales, the author should be able to find a reasonable voxel size for glimpse generation. \n\n4. The author is expected to provide more training details, like each glimpse may contain a different number of points, in the glimpse encoder and decoder, are different glimpses processed in batch or sequentially? Is there any difference for loss weights when training global VAE and per-glimpse VAE?\n\n5. The author needs to be aware of some recent works in this direction, like this ICCV 2021 paper: Unsupervised Point Cloud Object Co-Segmentation by Co-Contrastive Learning and Mutual Attention Sampling[Yang et al.]\n\n6. Could the author leverage more intuition about why this method could learn to develop a concept of visual entities in an unsupervised way? It is still amazing the proposed pipeline achieves such a good performance even on the toy datasets. But if the per-glimpse reconstruction generates points containing background points, the loss would not change, but then there is no way that  model could tell the object mask. And why do we need this global VAE for background when each glimpse module already handles the target  foreground objects?\n\nMinor comments about weakness:\nWhat is the foreground alpha in figure 2 (i) and (j). Besides the glimpse alpha and scene layout reconstruction, Could the author also show more reconstruction visualization in individual glimpses?\nIn the title, there is a word ‘Invariant', which I found quite interesting. What does this ‘invariant’ mean exactly?\nPage 2. Section 3, 2nd paragraph should be ‘However, point cloud data is ...’\n\n This paper is a valuable pioneering work on unsupervised 3D scene segmentation, with a full variational training pipeline built up for irregular 3D point cloud data. ", "This paper studies the problem of unsupervised object-centric learning in the context of point clouds. Specifically, the goal is to learn a generative model of 3D objects from a collection of untextured point clouds of multi-object scenes, and this is achieved via a VAE-based generative framework.\n\nThis task extends the setup of prior work on image-based 2D object-centric learning to 3D. To be able to handle irregular structures of point clouds, a novel Chamfer Mixture Loss is proposed as reconstruction loss, which essentially extends the Chamfer distance with probability mixture modeling. The resulting model seems to work well on simple scenes with small isolated objects on a plane. ### Strengths\n#### S1 - Important problem\n- Unsupervised 3D object learning is an important important problem. This paper studies a specific case of it, which is detecting 3D objects in point clouds.\n\n#### S2 - Carefully designed framework\n- The proposed method is carefully designed for handling the irregular structure of point clouds in a VAE framework. Specifically, it adopts a likelihood-based extension of Chamfer distance as a reconstruction loss for point clouds, and incorporates several recent architectures, including pointCNN and pointGNN.\n\n### Weaknesses\n#### W1 - Over-complicated method on simplistic datasets\n- A major concern with this paper is the simplicity of the evaluation experiments. The datasets used in this paper appear extremely simple, with almost perfect shapes, uncluttered scenes and clean, planar background, which makes task of foreground object detection seem rather trivial, and hence the learning of 3D object representations. Moreover, compared to the previous studies in 2D images, the 3D scenes here intrinsically alleviate challenges like occlusion and illumination effects. In contrast to this seemingly trivial task, the proposed method appears overly complicated.\n- Also, the failure examples shown in appendix (Fig. 15 and Fig. 16) suggests the model is still unable to handle scenes where objects are closer.\n- I would suggest increasing the diversity of the 3D scenes to verify the effectiveness of the proposed method, eg, using more complicated geometries for the background, varying the sizes and point densities of the objects, introducing noise to the point clouds etc.\n Overall, I think the problem is interesting, and the proposed framework is technical sound, but the results presented on the simplistic datasets cannot sufficiently verify the effectiveness of the method.", "This paper introduces a framework, SPAIR3D, to decompose a 3D point cloud into several objects (point cloud segmentation). The framework is unsupervised, driven by a Chamfer Mixture Loss. Two training datasets, UOR and UOT are rendered by Unity to train and evaluate the proposed method. In experiments, the method is compared with a supervised method PointGroup, where PointGroup outperforms SPAIR3D, but the performances are comparable.  The paper proposes an unsupervised object-level segmentation framework from point cloud input. The framework is unsupervised, driven by a Chamfer Mixture Loss. Two training datasets, UOR and UOT are rendered by Unity to train and evaluate the proposed method. In experiments, the method is compared with a supervised method PointGroup, where PointGroup outperforms SPAIR3D, but the performances are comparable. \nThe unsupervised method and the new loss are good and novel, but I have a few confusions below:\n1. Firstly the problem setting is a little confusing, since the framework is unsupervised, I thought that the training data would be captured point clouds or those from other various datasets, since GT is not needed. However, the authors still make a lot of efforts to render UOR and UOT. If so, the GT is easy to get, why do we need an unsupervised framework for these synthetic datasets? On the other hand, the synthesized datasets look relatively simple and objects are placed sparsely and at similar sizes. I would like to see results on more challenging data, and I would like to hear the reason why the training is not performed on real point clouds or existing datasets. \n2. In a real scene, objects are often stacked. Would SPAIR3D work and how is it work? \n3. Typos: title of 3.1 \"Local\". \n The idea of unsupervised point cloud segmentation is cool since point clouds are hard to annotate, and they are easy to capture or collect. However, the dataset and evaluations are not quite reasonable to me, as described above. Thus I give a borderline reject for now. ", "The paper tackles unsupervised 3D scene decomposition/object discovery from point clouds. It proposes SPAIR3D, inspired by the 2D counterpart SPAIR, to factorize a 3D point cloud into a spatial object-centric mixture model. It derives the Chamfer Mixture Loss to fit 3D reconstruction into the variational training pipeline. It introduces two customized point-cloud datasets, and compares with a supervised baseline PointGroup. # Strengths\n- The overall writing is clear.\n- The paper is the first to extend 2D object-centric representation learning to 3D point clouds. The Chamfer Mixture Loss is a reasonable adaptation for variational training.\n\n# Weaknesses/Questions\n1. Lack of baselines. Although there are no direct 3D object-centric representation learning baselines, 3D object discovery is not an unexplored field. Apart from \"Unsupervised Discovery of Repetitive Objects\", a common baseline in 3D object detection is to cluster/group 3D points according to their spatial relationship. Concretely, the authors can compare with a baseline, where the background/scene layout (planes in the paper's datasets) is first detected by a RANSAC and the rest objects are separated by DBSCAN/MeanShift (hyperparameters need to be tuned/searched). Although such a baseline is not scalable to more complicated scenes, SPAIR3D is not shown to have stronger scalability currently. Besides, the authors can introduce some 3D over-segementation baselines (e.g., [1], [2])\n\n2. How important is VAE in the object-centric representation learning framework? It might be a general question (also for 2D counterparts). From some experience, I suspect that the prior of model structure, like sliding window in 2D/3D grid and relative center prediction (techniques studied in 2D/3D detection), is the most important. VAE, especially the probabilistic model, mainly provides a sampling procedure during training, which might be considered as a search process (Monto-Carlo sampling). An easy way to check is to remove KL divergence terms between the prior and posterior probability of latent codes, and only maximize posterior probabilities of observations.\n\n3. I am a little confused about the claim \"Unfortunately, the Chamfer distance does not fit into the variational-inference framework\". There is no detailed explanation about it. From my understanding, the Chamfer Mixture Loss just introduces additional variance term and changes the distance to probability, since the variance term is a hyperparameter rather than per-point prediction and the likelihood is only based on the best/maximum matched point.\n\n4. As mentioned in Sec 4.1, the point cloud is fused from 10 different views. Can SPAIR3D work on partial 3D scenes? Theoretically, current SPAIR3D may have difficulty since the Chamfer Mixture Loss ignores visibility and it becomes much harder to recognize repetitive objects.\n\n# References\n1. Toward better boundary preserved supervoxel segmentation for 3D point clouds\n2. Superpoint Network for Point Cloud Oversegmentation To the best of my knowledge, the paper is the first to tackle 3D object-centric scene decomposition (unsupervised object discovery). It is well written and reasonably extends SPAIR to 3D scenes with new challenges only in 3D cases. However, the baselines are not carefully chosen, and the scalability of the proposed SPAIR3D is questionable. Overall, I think the paper is slightly above the acceptance threshold.", "This paper proposes a VAE-based unsupervised generative model, to achieve 3D object-centric learning as well as 3D scene decomposition. The method divides a 3D scene into voxel grids and generates latent features to reconstruct an original point cloud. A chamfer Mixture loss is proposed to train the model.  Strengths：\n1. This paper proposes a novel Chamfer Mixture loss formulated in a probabilistic framework. \n2. The proposed method achieves astonishing performance comparable to a supervised baseline on two simple datasets.\n\nWeakness：\n1.\tThis paper is built on the SPAIR framework and focuses on point cloud data, which is somehow incremental.\n2.\tThere is no ablation study to validate the effectiveness of the proposed components and the loss. \n3.\tIt is hard to follow Sec. 3.2. The author may improve it and give more illustrations and examples.\n4.\tIt is unclear how the method can work and decompose a scene into different objects. I did not see how Chamfer Mixture loss can achieve this goal. More explanation should go here. \n The idea to decompose a scene in an unsupervised way is novel. However, the proposed method is mainly based on SPAIR and the only technical contribution seems to be Chamfer Mixture loss. It is unclear what is the advantage of this loss design over traditional chamfer distance and how it can help scene decomposition. Moreover, I did not see further analysis on different proposed components of the method and inspiring conclusion for the community. "], "review_score_variance": 0.24000000000000005, "summary": "This paper introduces a VAE-based generative model of 3D point-clouds inspired by SPAIR that can do unsupervised segmentation, named SPAIR3D. The model uses both global and local latent variables to encode global scene structure as well as individual objects.\n\nThe proposed model is relatively complex, but the presentation is overall clear. \n\nExperimental results on simple synthetic datasets look promising. However, one might argue that for these simple tasks a direct application of a simpler mixture of VAEs (such as IODINE) might be sufficient, so it would be informative to make a direct comparison between these methods and/or show results on a problem clearly out of the scope of these simpler methods (e.g. with high imbalance in the point clouds).", "paper_id": "iclr_2022_GiddFXGDmqp", "label": "train", "paper_acceptance": "Reject"}
{"source_documents": ["This paper demonstrates how time-constrained multi-robot task allocation (MRTA) problems can be modeled as a Markov Decision Process (MDP) over graphs, such that approximate solutions can be modeled as a policy using Reinforcement Learning (RL) methods. \n   Inspired by emerging approaches for learning to solve related combinatorial optimization (CO) problems such as multi-traveling salesman (mTSP) problems, a graph neural architecture is conceived in this paper to model the MRTA policy. The generalizability and scalability needs of the complex CO problem presented by MRTA are addressed by innovatively using the concept of Covariant Compositional Networks (CCN) to learn the local structures of graphs. The resulting learning architecture is called Covariant Attention-based Mechanism or CAM, which comprises: 1) an encoder: CCN-based embedding model to represent the task space as learnable feature vectors, 2) a decoder: an attention-based model to facilitate sequential decision outputs, and 3) context: to represent the state of the mission and the robots. To learn the feature vectors, a policy-gradient method is used. The CAM architecture is found to generally outperform a state-of-the-art encoder-decoder method that is purely based on Multi-head Attention (MHA) mechanism in terms of task completion and cost function, when applied to a class of MRTA problems with time deadlines, robot ferry range constraints, and multi-tour allowance. CAM also demonstrated significantly better scalability in terms of cost function over unseen scenarios with larger task/robot spaces than those used for training. Lastly, evidence regarding the unique potential of learning-based approaches in delivering highly time-efficient solutions is provided for a benchmark vehicle routing problem -- where solutions are achieved 100-1000 times faster compared to a non-learning baseline, and for a benchmark MRTA problem with time and capacity constraints -- where solutions for larger problems are achieved 10 times faster compared to non-learning baselines.", "The paper proposes a graph learning approach for solving the multi-robot task allocation (MRTA) problem. It frames the problem as a Markov Decision Process (MDP) and trains a policy with a graph neural network architecture using REINFORCE. Results show that the proposed approach scales better compared to a non-learning baseline and is more accurate than a multi-headed attention (MHA) approach. **Strengths**\n\nThe paper tackles the important problem of MRTA that is typically a computationally expensive optimization problem. The proposed approach of learning heuristics to solve it quickly seems appealing. Since the optimization is over a graph, choosing a graph neural network architecture seems like a natural fit that scales for varying numbers of tasks and robots without retraining the model. The paper also presents a substantial evaluation comparing it to a SOTA non-learning baseline.\n\n**Weaknesses**\n\nThe main weakness of the paper is that it is unclear from the results if the CAM policy is learning something meaningful. Without clearly showing this, it is difficult to accept the paper at this time. \n\nLooking at Tables 1 and 2, it appears that even though CAM is faster than BiG-MRTA, the performance of the policy is substantially worse. Interestingly, this is especially pronounced when the robot to task ratios are low (i.e. 1:10). This suggests that the policy being learned is possibly myopic, i.e., robots greedily pick tasks that suffices when ratios are high (1:5 or higher). \n\nI would like to see a qualitative result showing the actions chosen by CAM vs BiG-MRTA, especially in the low robot to task ratio regimes. This would help convince the reader that the policy being learned is indeed meaningful.\n\n**Suggestions for improvement**\n\n*Overall story*\n\nThe paper prescribes a very specific architecture for learning policies that solve MRTA problems. However, it does not offer much insight into why this approach is preferred over alternatives. For instance, an ablation study can be provided to show the relative importance of different components -- why do we need the attention layer as opposed to a simpler aggregation step in GNN, rounds of message passing in the graph, etc. Additionally, for readers unfamiliar with MRTA problems, the paper appears difficult to follow. The paper would benefit from providing more insight into why one needs to apply learning for this problem, why GNN architecture is natural, why RL over other paradigms such as imitation learning of offline solvers.\n\n*Technical Points*\n\nThe paper assumes full observability, i.e., each robot has the full state of other robots. Practically, for real-world problems with communication bottlenecks, this seems unrealistic. It would be good to explain how this assumption can be relaxed for applications in practical settings. It was also unclear how the architecture scales to dynamically changing robots since the size of the context would vary, requiring retraining. Results in Section 5.2 claim that the same model scaled to a varying number of robots. It would be good to have a subsection in section 3 that explains how the varying context is handled. \n\nThe reward function defined seems very sparse, i.e., 0 for all states until all tasks are inactive. Historically, REINFORCE performs poorly in such settings, mostly doing random explorations till it sees high reward states enough times. It could be interesting to compare this against an approach that uses imitation learning to bootstrap RL. For instance, the results show that the non-learning baseline BiG-MRTA does quite well, outperforming the proposed approach on many trials. How well does this approach fair against a baseline that imitates the BiG-MRTA policy? How much does REINFORCE improve upon this policy by using this as a warm start?\n\nFinally, the visited tasks are masked after prediction. By doing this, the model has no idea that it should not put all probability mass on visited tasks. This may result in random tie breaks. How would the approach compare to a method that takes the visited tasks as input to the CAM model? \n\n*Formatting and style*\n\nAs presented, the paper appears dense and at times difficult to read. This is likely due to a lot of details pertaining to MRTA, architectural details, and result descriptions. These details can easily be moved to the appendix and the main body of the paper can focus on the higher-level interpretation of results (e.g. the proposed approach, though faster than big BiG-MRTA, actually performs poorer on rewards). I would also recommend minimizing the use of abbreviations or having a table of abbreviations for reference and using new line enumerations to further improve the readability of the paper. My overall recommendation is weak reject. While the paper tackles learning for a difficult optimization problem, it is not clear from the results whether it succeeded in learning something meaningful.", " Thank you for the detailed response. I appreciate the additional evaluation and incorporation of suggestions. While it would still be insightful to see a qualitative result showing the actions chosen by CAM vs BiG-MRTA, the addition of the random baseline seem to indicate that the policy is learning something meaningful. As a result, I have updated my rating to weak accept. ", " Mission completion time can be defined as the duration that all the available tasks have been visited by robots; in the presence of task deadlines (as is the case here), some tasks might expire as well over time (without ever being allocated to any robot), which is why “task completion rate” is considered to be a more apt representation of a performance in real-world applications such as disaster response. More importantly, note that for the MRTA problem being solved here, the composite cost or reward function includes both task completion rate (i.e., the fraction of tasks completed) to be maximized, and total distance traveled by robots, to be minimized. As a result, any learning or non-learning method acting on this cost function is not necessarily seeking to minimize mission completion time. Therefore, it is not meaningful or fair to report the mission completion time of the different methods for this study. ", " In many real-world applications, such as last-mile delivery, the full observability of tasks and robots in the time-scale of seconds is feasible [1]. The communication bottleneck is a key issue in swarm control algorithms when a high frequency of decision-making and data sharing is required. However, in our MRTA application, each robot is making a decision every few seconds or minutes. This means that one can use multi-hop communication or other long-range communication technology to aggregate information about tasks and other robots in a timely fashion [1, 2]. However, we do agree that the wider range of problems that can be solved by CAM does include some application instances (as mentioned above) where partial observability effects are significant. In such cases, the proposed CAM architecture can also be implemented to consider partial observability, where instead of operating over an MDP, the policy model will operate over a POMDP. For this purpose, the context portion of CAM needs to be updated by including the information of the neighbors (robots in the locality of the decision-making robot), and/or probabilistic predictions over the information of other peer robots that are out of range. However, including partial observability is out of scope for this paper.\n \n[1] Kagawa, T., Ono, F., Shan, L., Miura, R., Nakadai, K., Hoshiba, K., Kumon, M., Okuno, H. G., Kato, S., & Kojima, F. (2020). Multi-hop wireless command and telemetry communication system for remote operation of robots with extending operation area beyond line-of-sight using 920 MHz/169 MHz. Advanced Robotics. https://doi.org/10.1080/01691864.2020.1760934\n \n[2] Mehta, Vaibhav Kumar, and Filippo Arrichiello. \"Connectivity maintenance by robotic Mobile Ad-hoc NETwork.\" arXiv preprint arXiv:1312.2526 (2013).", " We thank the reviewer for appreciating the real-world applicability of the method. We would like to add that the CAM architecture is applicable to different MRTA and VRP problems, which themselves are representative of a wide range of multi-agent system problems (possibly generalizing to an even wider range of CO problems). Thus the contributions and capabilities of CAM are not necessarily application-specific. For demonstration, we are evidently limited to using a few different case studies such as the MRTA-flood response, the benchmark MRTA-TAPTC, and the benchmark CVRP problem, and this scope of numerical experiments is at par with other well-known recent papers in the area. \nIn addition, we also demonstrate how the MRTA problem can be formulated as an MDP over graphs, the design of the context portion could motivate the adoption of this formulation and associated GNN architecture in different MRTA and VRP type problems. In its current form, this approach is particularly suited for problems where time-critical feasible planning decisions are needed. Examples include disaster response and post-disruption reconfiguration of critical infrastructure networks (that can be modeled as multi-agent systems).\nIn terms of novelty and insights for the AI community, I would like to point out the following key observations and new knowledge contributed thereof:\n\n1) We are the first to explore that covariant compositional encoding of (task) graphs can provide better performance in learning to solve CO problems through RL, in comparison to the popular attention mechanism based encoding. The premise for this performance gain is the ability to better capture local structural information of the task graph; this characteristic is now discussed, with supporting illustration, in Appendix E2. While a rigorous theoretical analysis of when and how capturing local structural information (about node neighborhoods) helps policies perform better in providing CO solutions is not currently available, our empirical results provide significant evidence of its benefit over the attention mechanism across the MRTA and CVRP problems. \n\n2) We show the feasibility of extending multi-head attention mechanisms (MH-A), serving as a decoder, from single agent to multi-agent problems, by incorporating a specially designed “context” portion inside the graph neural net. The decoder is fed information both from the encoder and this context portion. This context portion represents the robot’s self and peers state information as a learnable feature vector as explained in Section 3.2. Note that Kool et al.’s work only demonstrates MH-A capability in single-agent problems. \n\n3) We show that this encoder-context-decoder architecture can produce policies that readily scale to problems that are larger in size than those used in training. This has tremendous implications in making such AI-based decision-making feasible on real-world problems. Many real-world problems will require such AI models to be trained over simulation or game environments (e..g., robotic simulators), where each episode has a significant run-time. Hence, training on larger problems might be computationally prohibitive even when significant offline computing resources are available, which is for example a well-known challenge in the multi-robot learning community. In such situations, the ability to train on smaller-sized problems, while still providing acceptable performance on larger problems could be critical to the adoption of AI-based decision-making.\n\n[1] Kool, W., Van Hoof, H., & Welling, M. (2019). Attention, learn to solve routing problems! 7th International Conference on Learning Representations, ICLR 2019.\n", " Kool et al. [1] adopt the transformer architecture, which is an attention-based encoder-decoder architecture and implemented in a variety of simple single-agent problems. This method performs poorly for more complex multi-agent problems involving additional constraints, as can be seen in our results from the MRTA problems (Tables 1-3). It’s also important to note that choice of REINFORCE as the RL training solver is quite common in the context of training GNNs with RL, and is in no way a contribution of Kool et al’s work. Given its simplicity, it’s often the first goto solver. \n \nRegarding the additional complexity or constraints in the MRTA problem: As stated in Section 1.1 in the original manuscript, for the studied SR-ST problem with “n” locations, ‘m’ robots, and assuming ‘h’ number of routes, the complexity for the exact integer (non)linear programming (ILP) is O(n^3m^2h^2 ). The problem can be linear or non-linear depending on the nature of the application-driven cost function. This computational complexity is more significant than that of classical VRP or TSP problems that have been studied by Kool et al. [1].\nAs a result, the cost of solving the problem online increases significantly with increasing number of tasks and robots, when using state-of-the-art non-learning based methods; to a point where such non-learning solutions (even with online MRTA methods) become prohibitive to be used (e.g., problems with 1000’s of tasks) when real-time decisions are desired. These characteristics are evident from our scalability analysis. This is also where the proposed learning based methods, CAM and AM shine (i.e., in terms of their online computing performance), and on top of that, CAM provides significantly better cost function values compared to AM in almost all scenarios that we studied across different numerical experiments. \nComing back to the question of novelty, there are three key contributions in this paper 1) Incorporating a new encoder, inspired by the Covariant Compositional Network (CCN), to increase the ability of the architecture to capture better local structural information of the nodes/tasks than an attention-based encoder (Kool et al. [1]); we are not aware of any other work besides our which has explored the capacity of CCN is helping solve combinatorial optimization (CO) problems of the type of TSP, VRP and MRTA, and hence the resulting findings clearly adds new knowledge to the emerging domain of “learning to solve CO problems”; 2) Introducing the context portion to capture the robots’ states in manner such that it remains agnostic to the number of robots, thereby allowing scaling to larger problems without network structural issues; and 3) Providing formulation of the MRTA problem as an MDP that can be solved in a decentralized and asynchronous manner. \n \n \n[1] Kool, W., Van Hoof, H., & Welling, M. (2019). Attention, learn to solve routing problems! 7th International Conference on Learning Representations, ICLR 2019.", " It is not clear to us what clarity is missing from the presentation of the results. Results are reported in terms of “cost function” associated with the respective problem (e.g., MRTA and CVRP) and the computing cost of evaluating decisions (the entire sequence of tasks). These metrics are quite standard in the MRTA, CVRP, and related multi-agent system literature, and is widely used across learning and non-learning paradigms. \nOne very common way of looking at generalizability is looking at the test performance of a policy over unseen scenarios, which is what we use here. Comparing training and test performance could also shed light on the architecture’s ability to generalize. Similarly, one way of looking at scalability is how the performance and computing cost changes as the size of the problem increase. Interestingly, here we study scalability on problem scenarios that are even larger than those scenarios used for training (in terms of # task and robots). While we agree that a single scalar measure each of generalizability and scalability (that does not depend on cross-method comparisons) will be helpful for the analyses of solution approaches in the multi-agent systems and CO community, development of such metrics is not within the intended aims of this paper.   \n", " This seems to be a misunderstanding possibly due to how the case study was worded in the original manuscript. This has now been fixed. Section 2.2 of the revised manuscript now clearly states that CAM and AM are being used here to solve the multi-UAV flood response problem including all of the constraints as described in Ghassemi and Chowdhury 2019, 2021, with the exception of only the UAV payload capacity constraints. To further clarify, constraints associated with inter-robot conflicts, robot ferry range, and task deadlines are all being accounted for here. ", " The term t is the time when an event occurs, i.e., when a robot reaches a location or completes its task. The index of the events is given by the subscript of t. For example, the time of the 2nd event is t_2. In the simulation, it is not possible to have conflicting decisions, as the sharing of information is almost instantaneous. However, in real-world settings, it is possible that two robots want to make decisions at the same time, which might cause them to visit the same location. This is very rare and there are various mitigations to address this issue. For example, while robots are moving toward their selected task locations, they can check if their decision is conflicting with another robot based on recent information. If there is conflict, the robot with the worst time can cancel its current task and select a new task. This has been clarified in the revised manuscript in Section 3.\n", " We have updated section 5.1 to clearly define generalizability and scalability as being analyzed in this paper. This changed portion is marked in blue font in the revised manuscript. \n", " While the policies learnt by CAM could be myopic to some extent, they donot necessarily simply provision greedy feasible decisions To clearly demonstrate that CAM and AM are learning meaningful policies, we added a randomized myopic baseline, called Feasibility-preserving Random-Walk (Feas-RND) [1], where each robot randomly chooses tasks from among feasible tasks. The results for Feas-RND have been added to tables 1,2 and 7, and with further discussion in Section 5.1. CAM performs clearly better than Feas-RND in terms of the cost function across all cases studied in our generalizability and scalability analysis. CAM’s superiority to a greedy randomized highly-myopic task selection approach (like Feas-RND)  is further evident from its significantly superior task completion rate across these cases, which is now summarized in Table 7 in Appendix E.1\n \n[1] Ghassemi, P., & Chowdhury, S. (2022). Multi-robot task allocation in disaster response: Addressing dynamic tasks with deadlines and robots with range and payload constraints. Robotics and Autonomous Systems. https://doi.org/10.1016/j.robot.2021.103905\n", " n the revised manuscript, in Appendix E2,  we discussed the effect and importance of each component of the proposed architecture using an ablation study. The paper has been revised to clearly show how each component contributes to the final performance.\nFor standard optimization methods, besides expensive computing time, there is a memory limitation. When the size of the MRTA problem is large, the amount of the required memory increases significantly. The learned model does not suffer from this limitation. In order to address this issue in the non-learning-based methods, there exist various works that propose heuristic-based methods to find approximated solutions in a timely manner [1]. One of these methods is EILS [2]. In this paper, as discussed in Section 5.2, EILS has been compared with CAM and AM. As shown in Tables 3 and 4, CAM and AM generate better or comparable solutions w.r.t. EILS for large problem sizes, while they are at least 10 times faster than EILS.\n       \n       \n[1] Mosteo, Alejandro R. and Luis Montano. “A survey of multi-robot task allocation.” (2010).\n\n[2] Mitiche, H., Boughaci, D., & Gini, M. (2019). Iterated local search for time-extended multi-robot task allocation with spatio-temporal and capacity constraints. Journal of Intelligent Systems. https://doi.org/10.1515/jisys-2018-0267\n", " We have added the following text to Section 3.1 and highlighted in blue.\n\n\t\t“It should be noted that the encoding mechanism here, can also be extended for a probabilistic scenario, for example, when the deadline  follows a probabilistic distribution.”", " This sentence has been restated as below and highlighted in blue color.\n\n\t“The MRTA problem has a set of nodes/vertices V and a set of edges E that connect the vertices to each other, which can be represented as a complete graph G = (V, E).”\n", " The size of the figures has been increased for better readability. The font size of the tables has also been increased.\n", " We have removed the highlight color from tables 3, 9, 11, and 12,  and have highlighted the best result in each case in bold font.", " As per the suggestion, we have made the topline for tables 1,2, and 5 as bold for better readability.", " For qualitative evaluation, we have performed an ablation study (in Appendix E2), to understand the importance of the CCN based encoding and the MHA-based decoding. For the encoder, the CCN based encoding was disabled in the encoder and was replaced with a simple feedforward network encoding, with the decoder being the same. For the decoder, the MHA-based decoding was disabled for the decoder and was replaced with a simple feedforward network and a softmax layer, with the encoder not changed.\nIn both cases, there was a significant decrease in the performance (table 8) for all the scenarios, with the maximum dip in the completion rate being 19.8% and 13.4% for the first and the second case, respectively. \n\nCompiling the results from the first case of the ablation study for the encoder and with the comparison with AM, we posit that the CCN based encoding, which is able to aggregate local node neighborhoods while remaining agnostic to node ordering, aided in better policies.\n", " Limitation: This work is implemented for a fixed number of nodes but can be easily extended for cases where nodes are determined dynamically. The impact of the learning algorithm parameters such as the learning rate, training frequency or training batch size, etc. is not analyzed. Parametric analysis of the learning algorithm, as well as the implementation of more recent state-of-the-art RL solver(e.g., PPO), can be considered as other directions of future work with CAM. The current learning framework for CAM has been implemented with a greedy approach for decision-making. The performance can be improved by adopting an epsilon greedy approach. We have included the limitations of our work in Appendix H of the revised manuscript.\n\nEase of use: CAM model can be implemented for a wide variety of multi-agent task allocation problems, by making the necessary changes in the encoder and the context portion. CAM can also be implemented on single-agent problems similar to [1].\n\n[1] Kool, W., Van Hoof, H., & Welling, M. (2019). Attention, learn to solve routing problems! 7th International Conference on Learning Representations, ICLR 2019.", " We appreciate the thoroughness of the review process and thank the reviewers for their time and guidance. As per the recommendation of the reviewers, we have added more results, on the importance of different components of CAM using an ablation study, as well as for qualitative analysis, by comparison with a randomized myopic decision-making strategy called Feas-RND. The updates are highlighted in blue-colored font in the revised manuscript. We are posting a version of the revised manuscript now (November 18), that includes all revisions that are currently marked in our response below. This revised manuscript will get replaced with further updated versions as we continue to address further comments from the reviewers  (if any)  over the next few days.", " It seems that our descriptions in the original paper had left opportunities for further clarity. We revised the paper to address these gaps. Specifically, in Section 1.1, we discuss the main motivation to use a learning-based method for solving MRTA problems. One of the key advantages of learning-based methods over non-learning-based methods is their low computational time for generating solutions for large problems during operation. Our results in Tables 3-5 support this claim. It is possible that the learning-based method might even provide better cost function (e.g., task completion rate) performance when problems present additional complexities such as non-linearities and mixed-integer decision spaces, which derail state-of-the-art online MRTA methods. However, this is not explicitly studied here, as the flood response, benchmark MRTA and CVRP problems we use mostly boil down to large integer linear (or mildly non-linear) programming problems\n\nThe main design choices of our architecture are for the encoder and the decoder. The importance of a CCN based encoder is evident by comparing the performance with the AM method (that is partly derived from Kool et al. ) , which has an attention-based encoder. As per the suggestion of the reviewer, we have included the results of our ablation study in appendix E2, showing the relative importance of the CCN-based encoder and the MHA-based decoder.\n\nIn Section 1.1, we now discuss why graph neural networks (GNN) work well as policy models for combinatorial optimization problems (including MRTA). \n\nImitation learning provides a great opportunity to speed up learning by utilizing expert demonstration (e.g., from a sparse set of optimal solutions given by offline solvers). As a matter of fact that’s an ongoing portion of the current sponsored project under which this research has been performed. There is indeed an opportunity to bootstrap labels from say BiG-MRTA or even optimal ILP solutions (at least for small problems), and construct a hybrid imitation learning process that minimizes deviations from expert policies (over sparse set of scenarios) while further generalizing across a wider range of scenarios in training. Frameworks such as GAIL [1] can be extended to work with graph neural nets to implement this process. However, exploring such a hybrid imitation learning is not within the scope of this paper, but is planned as future work under our ongoing research project. More importantly, the current RL method can be readily extended to such a hybrid imitation learning setting while continuing to use the same encoder-decoder architecture (as in CAM) which is the main contribution of this paper.\n\n[1] Ho, J., & Ermon, S. (2016). Generative adversarial imitation learning. Advances in Neural Information Processing Systems.\n", " Connectivity: In many real-world applications, such as last-mile delivery, the full observability of tasks and robots in the time-scale of seconds is feasible, as noted in various articles [1]. The communication bottleneck is a key issue in swarm control algorithms when a high frequency of decision-making and data sharing is required. However, in our MRTA application, each robot is making a decision every few seconds or minutes. This means that you can use multi-hop communication or other long-range communication technology to aggregate information about tasks and other robots [1, 2]. \n\nPartial observability: The CAM architecture can also be implemented for partial observability. This can be achieved by modifying our context portion of CAM, by including just the information of the peer robots with which the robot taking the action can communicate at that time step. However, including partial observability is out of scope for this paper.\n\nVarying number of robots: The context portion of CAM has been designed such that it is agnostic to the number of robots. For example, the context portion for the MRTA problem contains the five following components 1) Current time,2) Current location of the robot taking, 3) Available range for the robot making a decision, 4) Current destination of the peer robots,  5) Available range for the peer robots. The current state of the robot taking decision (which 2 and 3) undergoes a linear transformation to produce a single feature vector. Similarly, the states of the robots also undergo a linear transformation, and the resultant feature vectors are aggregated to be represented as a single feature vector (as shown in figure 2 of the manuscript). This aggregation operation makes the CAM model agnostic to the number of robots. Due to space constraints in the original manuscript, this discussion has been added in Appendix D1, in the revised manuscript (highlighted in blue font).\n\n \n[1] Kagawa, T., Ono, F., Shan, L., Miura, R., Nakadai, K., Hoshiba, K., Kumon, M., Okuno, H. G., Kato, S., & Kojima, F. (2020). Multi-hop wireless command and telemetry communication system for remote operation of robots with extending operation area beyond line-of-sight using 920 MHz/169 MHz. Advanced Robotics. https://doi.org/10.1080/01691864.2020.1760934\n\n\n[2] Mehta, Vaibhav Kumar, and Filippo Arrichiello. \"Connectivity maintenance by robotic Mobile Ad-hoc NETwork.\" arXiv preprint arXiv:1312.2526 (2013).\n", "  We thank the reviewer for the suggestion. In fact, this is also one of the future directions of our research. Unfortunately, we will not be able to include the imitation learning part, since it is beyond the scope of this paper, and would be challenging to include given the space limitations. Please refer to our earlier response w.r.t. How a hybrid imitation learning approach could further improve the performance of graph learning in solving such problems.", " The approach where masking is disabled is worth exploring. Removing masks increases the training time. During actual implementation masking of visited and infeasible tasks was observed to usually result in better decision-making than when masking is disabled.", " We have moved the section “Computing time (Training and Execution)” (previously Section 5.1)  to Appendix D5.1, as well as the section “Design of Experiments & Learning Procedures” (previously Section 4.1) to Appendix D3. We have also added a table for abbreviations in Appendix I (Table 16)", "This paper proposed a neural architecture for learning to solve multi-robot task allocation (MRTA) problems. The MRTA problem is modeled as a MDP, and then the so-called covariant attention-based neural architecture (CAM) is proposed. The main paper contribution is the CAM architecture.\n\nCase studies are presented in which the proposed CAM is compared with other learning based and non-learning based methods. In the reported experiments CAM obtained smaller errors (average cost) and smaller processing time.\n 1. The paper is well written and well organized. The references are appropriate and the problem being addressed is very well explained.\n\n2. One of the paper contributions is the modeling of the MRTA problem as a MDP over graphs. This formulation is important because it allows to propose the covariant attention-based neural architecture (CAM) to learn MRTA problems.\n\n3. The CAM architecture is the main paper contribution. The CAM is basically an encoder-decoder architecture, it uses attention mechanisms in the encoder and in the decoder, it uses information of other agents (context), and it codifies spatial information using a Graph Neural Network. The author put nicely together all these different elements in the CAM, which is able learn appropriately MRTA problems.\n\n4. The reported results are convincing. Case studies are presented in which the proposed CAM is compared with other learning based and non-learning based methods. In the reported experiments CAM obtained smaller errors (average cost ) and smaller processing time. CAM scales well with the number of tasks and the number of robots.\n\n5. It could be good that authors could explain about the limitations of CAM. It can really be used in any CAM problem? Is it  easy to use? Is tit easy to model any CAM problem and to put as required by the CAM?\n This is a novel paper. The proposed covariant attention-based neural architecture (CAM) is a novel architecture as well as the modeling of MRTA problems as MPDs. Moreover, the use of the CAM architecture allows solving MRTA problems in a better way than using tradition methods. MRTA scales well with the number of robots/agents and with the number of tasks. ", "This paper considers the multi-robot task allocation problems. To address the limitations of existing studies, such as real-world constraints, larger-sized problems and generalizations, this paper proposed a learning architecture, Covariant Attention-based Mechanism. They further conduct adequate evaluations and the results have shown great improvements over the state-of-the-art methods.\n\n This paper considers a very real-world problem, and there are many details in the context. The reviewer is not very familiar with this sub-area. As an application paper, it might be acceptable that the proposed method is a combination of some commonly used architectures or algorithms, such as multi-head attention, encoder-decoder and RL algorithms. In general, the technical novelty is not enough, although the empirical results are significant. Specifically, the reviewer is not sure what insights can this paper bring to AI community.  An application paper with adequate evaluations.\n", "This paper proposes a new method, including neural network architecture, for solving time-constrained multi-robot task allocation (MRTA) problems. The proposed approach models the target problem as a Markov Decision Process (MDP) over graphs and use Reinforcement Learning (RL) methods to solve the problem.\nThe proposed learning architecture is called Covariant Attention-based Mechanism (CAM). \nThe architecture is shown to have better performance than an existing state-of-the-art encoder-decoder method regarding task completion, cost function, and scalability. Though the performance is still lower than non-learning-based baseline methods, i.e., BiG-MRTA, the computational cost is significantly smaller than the baselines.\n The strength of the paper is that it proposed a new and effective method for MRTA problems. To interpret the task as an MDP is not new. However, the architecture based on the multi-head attention-based encoder-decoder network is interesting. \nThe weakness of the paper is about the generality of the theory and the evaluation. In contrast with the general discussion and argumentation in the Introduction, the proposed method contains many specific formulation and network architectures (e.g., equations (1) and (2), and network architecture shown in Figures). How much generality does the proposed framework have? Which part actually did contribute to the performance? Ablation studies are expected to clarify these points. The evaluation was conducted in terms of generalizability, scalability, completion rate, and computation time. However, apparently, computation time and quality of solution have a trade-off relationship. The discussion or fair evaluation about the trade-off should be mentioned. For example, in a standard optimization problem, we can get a little worse solution by limiting the computational time (i.e., terminating the iterative algorithm). It is clearly shown that the proposed method is better in computation time. However, the performance considering the trade-off should be fairly discussed.  \n\n\n<Minor comments>\n1. Deterministic assumption:\nThey assume the dynamics are deterministic. However, their theory is based on MDP. Therefore, the approach seems to be naturally applied to a probabilistic environment as well. I suggest the authors mention this point.\n\n2. The first sentence of 2.1 \nThe sentence starting with \"The MRTA problem can…\" may be inaccurate. (A graph itself is not a \"problem.\")\n\n3. Too small figures and tables.\nMany figures (e.g., 1) and tables (e.g., 3 and 4) are too small to read. Please make them larger and improve the readability. \n\n4. Highlight color\nTable 3 and some tables in Appendix have a green background as a highlight. If you use the dark colors (e.g., green, blue and purple) as \"highlight,\" the readability becomes significantly worse.\nPlease use other styles (e.g., underline or bold style).\n\n5. Topline\nIn Table 1, BiG-MRTA is shown as a topline. It's better to use a different style that allows readers to easily distinguish the topline from baselines. For example, you can use a double line between BiG-MRTA and AM. \nAlso, it helps readers grasp the information to give underline or bold to the best value. \n\n6. Qualitative evaluation\nOnly quantitative results are shown. Providing qualitative evaluations may help readers understand the characteristic of the proposed methods.\n\n\n This paper proposes a new learning architecture which is called Covariant Attention-based Mechanism (CAM), to solve time-constrained multi-robot task allocation (MRTA) problems using a learning-based approach. The method works in an appropriate manner, and empirical results show the advantage of the method. Also, the approach itself is based on a modern approach and is worth studying. \nAs a whole, the paper is a good paper involving meaningful new information. \n", "This paper introduces a deep graph policy learning method that chooses tasks for each individual robot in a swarm thus addressing the problem of single-task robot and single-robot task (SR-ST) multi-robot task allocation (MRTA). The proposed method is based on the work by Kool et al (2019) with the main theoretical extensions on (1) adding constrains to the optimization objective of MRTA and (2) improving the encoder. Strengths:\n\n+ The idea of using learning methods to solve a SR-ST MRTA problem is interesting. \n\n+ Discussion of the technical approach is clear.\n\nWeaknesses:\n\n- The theoretical novelty is not high. The decoder and the training algorithm REINFORCE are similar or identical to the method by Kool et al (2019). The main novelty is to add constraints to the optimization objective of MRTA. However, it is not clear what new challenges are caused by adding the constraints? Theoretically, why does these constrains make the optimization problem more challenging to solve?\n\n- The paper states that \"this MRTA problem is adopted from Ghassemi et al (2019) with the modification of removing payload\". However, the optimization problem introduced in Ghassemi et al (2019) includes other constraints that are ignored by the paper. Other than payload, why other constraints are removed?\n\n- What is the meaning of t? The paper explains that \"the transition is an event-based trigger\", so it seems that t means the index of events (e.g., in Figure 1). In this case, when an event happens and all robots choose their tasks, how to guarantee that no multi-robots select the same task?\n\n- The terms generalizability and scalability are used throughout the paper. But they are not clearly defined, and in some places, they are used interchangeably, e.g., \"generalizing to problem scenarios that are larger in size\".\n\n- The experimental results are not clearly presented, especially the evaluation metrics. Besides the issue of clearly defining generalizability and scalability, can the authors provide the single value metric to quantify generalizability and scalability?\n\n- What are the task completion time of each approach for the testing scenarios in Table 1 and Table 2?\n\n- Without a centralized system, assuming each robot knows the information from all other robots in the swarm is not practical for real-world swarm applications.  \n\n- Minor: The variable t_i is used for both deadline and event/timestep index.\n Although the idea of using learning to address MRTA problems is interesting, the paper is preliminary and will need significant improvements on novelty justification, terminology definition, and experimental result presentation. "], "review_score_variance": 2.6399999999999997, "summary": "The paper considers the problem of solving time-constrained multi-robot task allocation (MRTA) problems. Formulating the problem as a Markov decision process (MDP), the paper proposes Covariant Attention-based Mechanism (CAM), a graph neural network-based policy that can be trained to solve MRTA problems via standard RL methods. The encoder adapts the covariant compositional network to improve generalizability, while the decoder extends a recent combinatorial optimization architecture to the multi-agent optimization domain. Experimental results demonstrate that CAM outperforms an encoder-decoder baseline in terms of task completion, generalizability, and scalability, while also providing greater computational efficiency than non-learning baselines.\n\nThe paper considers an important topic---multi-agent task allocation is an interesting and challenging combinatorial optimization problem. The proposed CAM architecture adapts existing components in an interesting way and seems sensible for the MRTA domain. The reviewers initially raised concerns regarding the conclusions that can be drawn from the experimental evaluation, the significance of the algorithmic contributions, as well as the motivation for the proposed approach. The authors made a concerted effort to address these concerns through the addition of new experimental evaluations (e.g., comparisons to a myopic baseline and ablation studies), updates to the text, and detailed responses to each reviewer. Unfortunately, only one reviewer responded and updated their review (increasing their score). In light of this, the AC also reviewed the paper. The AC agrees with the strengths identified by the reviewers (including those noted above) and with the contributions provided by the additional evaluations. However, the paper remains unnecessarily dense, while at the same time not being self-contained (e.g., the new experimental results are relegated to the appendix rather than appearing in the main text). The paper would also benefit from a more concise motivation for learning-based solutions to MRTA and a clearer discussion of the paper's contributions.", "paper_id": "iclr_2022_kSqyNY_QrD9", "label": "train", "paper_acceptance": "Reject"}
{"source_documents": ["Understanding how grid cells perform path integration calculations remains a fundamental problem. In this paper, we conduct theoretical analysis of a general representation model of path integration by grid cells, where the 2D self-position is encoded as a higher dimensional vector, and the 2D self-motion is represented by a general transformation of the vector. We identify two conditions on the transformation. One is a group representation condition that is necessary for path integration. The other is an isotropic scaling condition that ensures locally conformal embedding, so that the error in the vector representation translates conformally to the error in the 2D self-position. Then we investigate the simplest transformation, i.e., the linear transformation, uncover its explicit algebraic and geometric structure as matrix Lie group of rotation, and explore the connection between the isotropic scaling condition and a special class of hexagon grid patterns. Finally, with our optimization-based approach, we manage to learn hexagon grid patterns that share similar properties of the grid cells in the rodent brain. The learned model is capable of accurate long distance path integration. Code is available at https://github.com/ruiqigao/grid-cell-path.\n", " **Following your suggestion on adding experiments on applications**, we conduct the following two experiments and have obtained initial results. The first experiment is to integrate our grid cells model with egocentric vision. The second experiment is on path planning. The two experiments further illustrate the usefulness of our model, in addition to the path integration experiments in our paper. The following are details of the additional experiments. Thank you for your time and consideration. \n\n**(1) Integrating egocentric vision.**\n\nWhen the agent moves in darkness, it can infer its self-position by integrating self-motion, as illustrated by our experiments on path integration. If there is visual input, the agent can infer its self-position (as well as head direction) from the visual image alone. We extend our grid cells model to study this problem of egocentric vision, which is important in computer vision. \n\nSpecifically, suppose the agent navigates in a 3D scene such as a room, and the height of the eye (or camera) remains fixed. Suppose at 2D self-position $x$ and with head direction $\\theta$, the agent sees an image ${\\rm I}$, which is called a posed image. We use the vector representation $v(x)$ in our original grid cells model to represent the 2D self-position $x$, and use another vector representation $h(\\theta)$ to represent the head direction $\\theta$. If the agent changes its head direction from $\\theta$ to $\\theta + \\Delta \\theta$, $h(\\theta)$ is transformed to\n\n$h(\\theta + \\Delta \\theta) = \\exp(C\\Delta\\theta)  h(\\theta)$.\n\nWe assume that there are $K$ modules or blocks in $h(\\theta)$ and $C$ is skew-symmetric. This is similar to the transformation of $v(x)$ in our grid cells model. \n\n$(x, \\theta)$ is called the pose of the camera (or eye), and we call $(v(x), h(\\theta))$ the pose representation. \n\nTo associate the pose representation $(v(x), h(\\theta))$ with the posed image ${\\rm I}$, we use a vector representation $c$ to represent the 3D scene which is shared across different posed images of the same scene, and we learn a generator network $G_\\beta$ that maps $c$ and $(v(x), h(\\theta))$ to the posed image ${\\rm I}$:\n\n${\\rm I} = G_\\beta(c, v(x), h(\\theta))$, \n\nwhere the generator $G_\\beta$ is parametrized by a multi-layer deconvolutional neural network with parameters $\\beta$. \n\nGiven the above assumptions, we introduce two extra loss terms in addition to the loss function described in Section 5 (Eqn 16-18):\n\n$L_3 = \\sum_{k=1}^K \\mathbb{E}_{\\theta, \\Delta \\theta} ||h_k(\\theta + \\Delta \\theta) - \\exp(C_k \\Delta \\theta)h_k(\\theta)||^2$. \n\n$L_4 = \\mathbb{E} ||{\\rm I} – G_\\beta(c, v(x), h(\\theta))||^2$. \n\n$L_3$ is to model the head rotation, and $L_4$ is to model the generation of the posed image. \n\nDuring training, we alternatively update $(G_\\beta, c)$ and $(v(x), B(\\theta), u(x’), h(\\theta), C)$ by gradient descent on the overall loss function that is a linear combination of $L_0$, $L_1$ and $L_2$ in our paper, as well as $L_3$ and $L_4$ introduced above. \n\nThe learned model enables two useful applications: \n\n**(a) Novel view synthesis**. Given an unseen pose $(x, \\theta)$, the model can predict the corresponding posed image by $G_\\beta(c, v(x), h(\\theta))$.\n\n**(b) Inference of pose**, i.e., self-position $x$ and head direction $\\theta$, from posed image ${\\rm I}$ alone. Specifically, after training the model, we can learn an additional inference network $F_\\xi$ that maps an observed posed image ${\\rm I}$ to its pose representation $v(x)$ and $h(\\theta)$. The inference network is learned by minimizing the $\\ell_2$ distance between the predicted and true pose representations: $\\mathbb{E}||(v(x), h(\\theta)) – F_\\xi({\\rm I})||^2$. Then given an unseen posed image ${\\rm I}$, we can infer the pose by $\\arg \\min_{x, \\theta}||(v(x), h(\\theta)) – F_\\xi({\\rm I})||^2$. In this task, $F_\\xi(I)$ is the estimate of $(v(x), h(\\theta))$, and it's likely that this estimate contains error. This error will translate to the error in the estimated $(x, \\theta)$. Thus our theoretical analysis of error translation in the paper is highly relevant, and the isotropic scaling condition is motivated by the analysis of error translation.\n\nWe conduct experiments on a dataset generated by the Gibson Environment [1], which provides tools for rendering images of different poses in 3D rooms. Specifically, we select 20 areas of size 2mx2m from different rooms and render about 28k 64x64 RGB posed images for each area. The camera height is fixed and the camera can only rotate horizontally. The scene representation vector $c$ is of 512 dimensions. Both $v(x)$ and $h(\\theta)$ are of $192$ dimensions, partitioned into $K=16$ modules. \n\nHexagon patterns still emerge in the learned $v(x)$ (avg. gridness score 0.71). For novel view synthesis, we evaluate the performance on 374k testing posed images. The resulting peak signal-to-noise ratio (PSNR) between synthesized images and ground truth images is 23.53, indicating that the model can generate reasonable unseen posed images. \n\nFor inference of pose (self-position $x = (x_1, x_2)$ and head direction $\\theta$), we evaluate the performance on the same 374k testing posed images. The results are summarized below.\n\n|       | $x_1$   | $x_2$   | $\\theta$       |\n|-------|---------|---------|----------------|\n| Error | 0.0225m | 0.0230m | 1.37$^{\\circ}$ |\n\nWe will include the results, examples of synthesized posed images and patterns of learned $v(x)$ in the revision. \n\n\n**(2) Path planning.**\n\nOur grid cells model can be applied to path planning. Specifically, according to [2], the adjacency kernel can be modeled as \n\n$ A_\\gamma(x, x') = \\mathbb{E} \\left[ \\sum_{t=0}^{\\infty} \\gamma^t 1(x_t = x') | x_0 = x)\\right] = \\langle v(x), u_\\gamma(x')\\rangle$, \n\nwhere $\\gamma$ is the discount factor that controls the temporal and spatial scales, $\\mathbb{E}$ is with respect to a random walk exploration policy and $1(\\cdot)$ is the indicator function. For random walk in open field, $A_\\gamma(x, x') \\propto \\exp(-|x-x'|^2/2\\sigma_{\\gamma}^2)$, where $\\sigma_{\\gamma}^2$ depends on $\\gamma$. \n\nTo enable path planning, we need kernels of both big and small spatial scales to account for long and short distance planning respectively. To this end, we discretize $\\gamma$ into a finite list of scales, and learn a list of corresponding $u_\\gamma(x’)$ together with $v(x)$ and $B(\\theta)$ using the loss function in Section 5 (Eqn. 16-18). \n\nWith the learned model, we propose the following method for path planning. Let $\\hat{x}$ be the target or destination. Let $x^{t}$ be the current position in the path planning process, encoded by $v(x^{t})$, the agent plans the next displacement by\n\n$\\Delta x^{t+1} = \\arg \\max_{\\Delta x } \\langle M(\\Delta x) v(x^{t}), u_\\gamma(\\hat{x})\\rangle$,  --- (*)\n\nand then $x^{t+1} = x^{t} + \\Delta x^{t+1}$. $M(\\Delta x) = \\exp(B(\\theta) \\Delta r)$, where $\\Delta x = (\\Delta r \\cos \\theta, \\Delta r \\sin \\theta)$. The idea is that we plan the next step to maximally increase the adjacency to the target: $A_\\gamma(x^{t}+\\Delta x, \\hat{x}) = \\langle v(x^{t}+\\Delta x), u_\\gamma(\\hat{x})\\rangle = \\langle M(\\Delta x) v(x^{t}), u_\\gamma(\\hat{x})\\rangle$. $\\Delta x$ is chosen from all the allowed displacements for a single step, and $\\gamma$ is selected as the smallest one that satisfies $\\max_{\\Delta x} \\langle M(\\Delta x)v(x^t), u_\\gamma(\\hat{x}) \\rangle > 0.2$. \n\nWe test path planning in the open field environment. The model is first learned using a single-scale kernel function $A_\\gamma(x, x’) = \\exp(-|x-x'|^2/2\\sigma_{\\gamma}^2)$ where $\\sigma_\\gamma = 0.07$. Then we assume a list of three scales: $\\sigma_\\gamma = [0.07, 0.14, 0.28]$ and learn the corresponding list of $u_\\gamma(x’)$. The pool of allowed displacements for a single step is defined as:  $dr$ can be 1 or 2 grids, while $\\theta$ can be chosen from 200 discretized angles over $[0, 2\\pi]$. Our experimental results show that the agent is able to plan straight path to the target in the open field environment. When $x^{t}$ is far from the target, kernel with large $\\sigma_\\gamma$ is chosen, and as $x^{t}$ approaches the target, the chosen kernel gradually switches to the one with small $\\sigma_\\gamma$. A planning episode is treated as a success if the distance between $x^{t}$ and target is smaller than $0.5$ grid within $40$ time steps. The agent achieves a success rate of 100% (tested for $10,000$ episodes). We will include the results and examples of planned paths in the revision. \n\nFor a field with obstacles or rewards, we can learn the deformed $A_\\gamma(x, x’)$ and $(v(x), u_\\gamma(x’))$ by temporal difference learning with a random walk exploration policy as suggested in [2]. After learning $A_\\gamma(x, x’)$ and $(v(x), u_\\gamma(x’))$, we can continue to use equation (*) for path planning. We shall further study it in future work.  \n\n**Summary**\n\nWe believe that the above two experiments are substantial additions to the existing experiments in our paper, and they are highly relevant to navigation. \n\nThank you again for your consideration. \n\n\n\n[1] Fei Xia, Amir R Zamir, Zhiyang He, Alexander Sax, Jitendra Malik, and Silvio Savarese. Gibson env: Real-world perception for embodied agents. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9068–9079, 2018. \n\n[2] Kimberly L Stachenfeld, Matthew M Botvinick, and Samuel J Gershman. The hippocampus as a predictive map. Nature neuroscience, 20(11):1643, 2017.\n", " Thank you for your further comments, and for your judgement that our paper can be weakly accepted. We will continue to improve our paper based on your criticisms. \n\nThe main objective of our work is to understand how path integration can be accomplished by the grid cells system, and our experiments show that the learned model is capable of accurate path integration even in the presence of noises. We will try our best to add experiments to further illustrate useful applications of our method.  \n\nAgain, we thank you for your valuable comments.  ", " Thanks for your reply.\n\nMy concerns on (1) and (5) are resolved. The authors admitted (4).  However, my concerns on (2)(4) still exist.\n\nI was not saying Figure 7 is v(x). I am not denying normative models. I just think that the usefulness of this optimization is not convincing. This is different from [3] in which the objective is navigation, and the hexagon grid patterns are just by-products. However, it seems that the only objective in this paper is to generate the hexagon grid patterns. If the authors believe that it can be applied to other useful applications, experimental results are needed.\n\nI will not feel uncomfortable if this paper is accepted, however, I **strongly disagree** with that this paper can be accepted as \"10: Top 5% of accepted NeurIPS papers, seminal paper\". It can be weakly accepted.\n", " Thank you for the detailed review and positive feedback. Also thank you for your positive evaluation of the presentation and mathematical soundness of our paper. \n\nBelow we address specific points.\n\n**Q: Transformation F are intimately related to “flow” and such connection should be mentioned.**\n\nA: Thank you for this insightful point! We will include a discussion about flow in the revision. \n\n**Q: Why does the angle not depend on positional differential $\\delta x$?**\n\nA: That’s a good question. When doing the Taylor expansion, we treat $v(x + \\delta x) = F(v(x), \\delta r, \\theta)$ as a function of a single variable $\\delta r$ (which is infinitesimal), while treating $\\theta$ as fixed. We shall make this point more explicit in revision as you suggested. \n\n**Q: One could easily conceive of a formulation for more general Euclidean domains, like R^3.**\n\nA: That’s a great suggestion! Indeed we are planning to apply our model to the 3D environment to study 3D grid cells such as those in bats.\n\n**Q: One of the motivations of the proposed framework is that it allows for more general group transformations. This should be shown empirically as a proof of concept.**\n\nA: Following your advice, we tested our model with a nonlinear transformation model:\n\n$$F(v(x), \\Delta r, \\theta) = {\\rm ReLU}(\\exp(B(\\theta) \\Delta r) v(x)).$$\n\nInterestingly, regular hexagon patterns also emerge (average gridness score 0.83, percentage of grid cells 70.21%). We will include the results in the revised manuscript. \n\n**Q: I would like to see comparisons of path integration experiments to recurrent [3] and PCA based [33] models in Figure 6.**\n\nA: Following your advice, we compare with models of [3] (LSTM) and [33] (RNN) using the code released by [33]. To make the results fully comparable, we re-train and test their models using trajectories simulated in our environment, which is slightly different from their original environments in terms of area size and distribution of velocity.  We summarize the path integration performances at different time steps in the following table. All results are computed over the same 1,000 testing trajectories. \n\n| Time step          | 100                      | 200                     | 300                     | 400                     | 500                     | Avg                     |\n|--------------------|--------------------------|-------------------------|-------------------------|-------------------------|-------------------------|-------------------------|\n| LSTM               | 0.062 $\\pm$ .095         | 0.138 $\\pm$ .155        | 0.176 $\\pm$ .157        | 0.189 $\\pm$ .167        | 0.241 $\\pm$ .177        | 0.138 $\\pm$ .151        |\n| RNN                | 0.045 $\\pm$ .025         | 0.085 $\\pm$ .047        | 0.123 $\\pm$ .063        | 0.165 $\\pm$ .079        | 0.200 $\\pm$ .103        | 0.105 $\\pm$ .082        |\n| Ours w/o re-encode | 0.027 $\\pm$ .018         | 0.037 $\\pm$ .022        | 0.046 $\\pm$ .025        | 0.051 $\\pm$ .027        | 0.055 $\\pm$ .028        | 0.038 $\\pm$ .027        |\n| Ours w/ re-encode  |  $7.59e^{-5}$ $\\pm$ .001 | $7.59e^{-5}$ $\\pm$ .001 | $1.01e^{-4}$ $\\pm$ .002 | $1.27e^{-4}$ $\\pm$ .002 | $1.77e^{-4}$ $\\pm$ .002 | $9.69e^{-5}$ $\\pm$ .002 |\n\nWe will include the above table in the revised manuscript. \n\n**Q: I believe that the condition of F(v, 0, Phi) = v (l. 101) is central to the proposed framework and should be stated as a part of \"Condition 1\" (l. 82).**\n\nA: Thanks for the insightful and important point! You are absolutely right. We will revise Condition 1 to include that equation as you advised. \n\n**Q: The embeddings $v(x)$ lie on the Lie group manifold characterized by rotation matrices … did you find that this effect is relevant in practice?**\n\nA: Thanks for the interesting and insightful question. About the phenomenon you mentioned, we have not encountered it in our experiments. One possible explanation is as follows:  let $v(x)$ be d-dimensional representation with constant $||v(x)||$. Then $(v(x), \\forall x)$ forms a 2D manifold on the $(d-1)$ sphere. However, when the agent moves on a straight line segment in the 2D Euclidean space, $v(x)$ does not necessarily move on a great circle or geodesic on the $(d-1)$ sphere. Conversely, a geodesic path on the $(d-1)$ sphere does not necessarily belong to the 2D manifold $(v(x), \\forall x)$. Thus the edges of a triangle on the $(d-1)$ sphere with 90 degree angles do not necessarily belong to the 2D manifold either. \n\n**Summary**\n\nWe will improve and revise our manuscript and include the new results we obtained by following your insightful suggestions. \n", " Thank you for your review and valuable comments. Below we address specific questions. \n \n**Q: About orthogonal assumption in the proof of Theorem 3.**\n \nA: We wish to clarify a factual misunderstanding about orthogonality. The orthogonality between the basis functions $(v_i(x), i=1,..., d)$ in Section 4 and the orthogonality in the proof of Theorem 3 are two different things.\n\nFor the proof of Theorem 3, in Theorem 1, we have proved that the 2D local neighborhood around a self-position $x$ in the 2D physical space is embedded conformally as a local 2D plane around $v(x)$ in the $d$-dimensional neural space. For any 2D plane in the d-dimensional space, it is an **intrinsic property** that there exists an orthogonal basis $(v_1, v_2)$ to span the plane, which is not an explicit assumption that we make. In the proof of theorem 3, we use this property to show that $\\mathbb{E}||\\delta v||^2 = 2\\tau^2$, and the orthogonal basis $(v_1, v_2)$, which always exists, has nothing to do with the representation we propose to learn. \n \nIn contrast, the PCA-based basis expansion model (Section 4) assumes that the basis functions $v(x) = (v_i(x), i=1,…,d)^\\top$ (which are $d$ functions of $x$) are orthogonal basis functions for expanding $A(x, x’)$ (which is function of $x$ for each $x’$). This is a strong explicit assumption added on the learned representation $v(x)$. We do not make such an explicit orthogonal assumption.\n\n**Q: Figure 7 in appendix.**\n\nA: We wish to make a clarification. Figure 7 in supplementary is about sine/cosine tunings of $B(\\theta)$ over direction $\\theta$, which confirms our Theorem 1. It is not about sine/cosine tunings of $v(x)$, which consists of 2D response maps shown in Figure 3. \n \n **Q: Connection to References [a, b]**\n \nA: Thank you for bringing up these references. Ref [a] (Burgess, Barry, O'keefe, Hippocampus, 2007) describes an oscillatory interference model of the grid cell formation.  Part of Ref [b] (Fuhs & Touretzky, 2006) presents a descriptive model of grid cell responses (their Eq. 11) by summing up three cosine functions with an orientation offset of 60 deg, which is similar to Solstad et al (Hippocampus, 2006) for modeling the transformation from grid cells to place cells. Refs [a,b]  provide valuable initial modeling insights on how grid response patterns could be described quantitatively, and how the grid response patterns might be generated mechanistically via either interference of oscillatory patterns or attractor-based mechanisms. \n\nAs we will elaborate in more detail in response to the next question, our model represents a different type of models compared to models in Refs [a,b]. Our model can be thought of as a normative model, which starts from first principles to provide the rationale behind the grid responses, as Reviewer Wn1K pointed out.  We consider these different types of models all have their values in understanding the grid cells and the brain's spatial navigation system. We will add a discussion on this point in the revised manuscript. \n\n**Q: The purpose of optimization if predefined cosine functions can generate hexagon pattern.**\n\nA: While descriptive models (like References [a, b]) use predefined cosine functions to characterize hexagon patterns of grid cells and path integration, they do not explain where the cosine functions come from. In contrast, our method can be considered a normative model where we seek a deeper understanding and explanation of the emergence of hexagon patterns in grid cells. To this end, we only recruit generic vectors and matrices in our model and identify two minimally simple conditions on the transformation of path integration. Results obtained by our numerical optimization agree with various neuroscience observations. \n\nOur optimization-based approach follows the recent line of research pioneered by [3, 4] which studies grid cells by machine learning models. Using generic vectors and matrices, our method has the advantage that it can be potentially applied to more general situations where it is difficult to predefine functions for neuronal activities. For example, [1, 2] indicate that the patterns of grid cells would deform due to irregular geometry or the presence of rewards or obstacles. In such cases, we may first learn the deformed kernel functions of place cells ($A(x, x’)$) using empirical trajectories of the agent as in [2], which then leads to the update of grid cells $v(x)$ in our model, enabling us to study the deformed grid cells. Another general situation is to learn grid cells in three-dimensional space, as suggested by Reviewer Lump, which may have implications for studying the navigation system in animals such as bats. Our modeling scheme may also be generalized to represent poses and their continuous transformations in general, e.g., the poses of arms of the agent, the poses of faces (or other objects) in a 3D visual scene. We plan to investigate these problems in future work. \n \nThe reviewer also mentioned that \"I highly suspect that the three conditions introduced in this paper will result in the cosine functions\". This is an interesting question. It is mathematically highly non-trivial to obtain the general closed-form solutions to our model (i.e., equations 15, 16, 17), and the solutions can be more complex than the superposition of three cosine waves in References [a, b]. Following the suggestion of Reviewer Lump, we have also experimented with a nonlinear transformation model, where a ReLU activation is included:\n\n$$F(v(x), \\Delta r, \\theta) = {\\rm ReLU}(\\exp(B(\\theta) \\Delta r) v(x)).$$\n\nWe are still able to learn hexagon patterns using numerical optimization (average gridness score 0.83, percentage of grid cells 70.21%). The learned response maps have regions with effectively zero responses, suggesting that the solutions are not simple cosine waves. In general, our framework can lead to richer consequences and can account for more general situations than cosine functions. \n\nFinally, if one could indeed show a mathematical connection between our assumptions and the cosine functions under certain conditions, that would be an interesting result as well, because it provides a reason why cosine functions should be favored. \n\n**Q: About linear model / introduced formulation and hexagon grid patterns.**\n \nA: We can show that, if the response maps of each module have hexagon patterns and are shifted versions of each other, then they can satisfy the basis expansion model, the transformation model, and the isotropic scaling condition approximately. We thus far rely on numerical optimization to show that the converse is true, i.e., the optimization of our loss function (equations 15, 16, 17) leads to such response maps. Relying on numerical optimization is a practice shared by other optimization-based methods [3, 4, 5, 6]. We will continue to push the theoretical analysis and we will revise the title of Section 3.3 by following your advice. \n \n**Q: how to derive the third term from the second term in Eq (9)**\n \nA: It is a property or one definition of the matrix exponential, which generalizes the exponential of real numbers. See Property 4 in [7].\n\n**Q: why isotropic scaling.**\n\nA: We justify isotropic scaling by error analysis in Theorem 3 in the main text and Proposition 1 in supplementary. Theorem 1 shows that isotropic scaling leads to locally conformal embedding. These results provide strong rationales for isotropic scaling. \n\n**Summary**\n\nWith the above technical discussions, we wish to be allowed to engage in a more general discussion about descriptive vs normative models because this seems your main concern with our contribution. Great examples of descriptive models include Kepler's ellipses for planets and de Broglie's sinusoidal or periodic waves for electrons. No doubt they are revealing discoveries and profound insights, but it is still worthwhile to pursue normative models such as Newtonian mechanics and Schrodinger equation. By no means we are comparing our humble attempt to these monumental masterpieces, all we are trying to say is that studying normative models is worthwhile as they may provide deeper explanations and may be more generally applicable.\n \nWe will revise and improve our paper to address your criticisms. We hope our paper will be interesting to the NeurIPS community. Thank you for your valuable comments and we respectfully request you to reconsider our paper in view of our reply. \n\n \n\n[1] Butler, William N., Kiah Hardcastle, and Lisa M. Giocomo. \"Remembered reward locations restructure entorhinal spatial maps.\" Science (2019).\n\n[2] Stachenfeld, Kimberly L., Matthew M. Botvinick, and Samuel J. Gershman. \"The hippocampus as a predictive map.\" Nature neuroscience (2017).\n\n[3] Banino, Andrea, et al. \"Vector-based navigation using grid-like representations in artificial agents.\" Nature (2018).\n\n[4] Cueva, Christopher J., and Xue-Xin Wei. \"Emergence of grid-like representations by training recurrent neural networks to perform spatial localization.\" ICLR (2018).\n\n[5] Sorscher, Ben, et al. \"A unified theory for the origin of grid cells through the lens of pattern formation.\" NeurIPS (2019).\n\n[6] Cueva, Christopher J., et al. \"Emergence of functional and structural properties of the head direction system by optimization of recurrent neural networks.\" ICLR (2019).\n\n[7] Salman, Mohammed Abdullah Saleh, and Dr VC Borkar. \"Exponential Matrix and Their Properties.\" International Journal of Scientific and Innovative Mathematical Research (IJSIMR) (2016).", " Thank you for your very positive evaluation. We are profoundly grateful that you share our excitement about this work. \n\n**About first principles.**\n\nYou are absolutely right that we seek to understand grid cells from first principles. Thank you for your precise and deeply insightful summary of our work and contribution. Also thank you for pointing out that our work is mathematically grounded, and that our paper is of interest to the NeurIPS and computational neuroscience communities. \n\n**Robustness to noise.**\n\nYes, robustness to noise justifies isotropic scaling, which leads to conformal embedding, and which appears to underly hexagon grid patterns. \n\nThank you again for your deep understanding of our work!\n", "This paper focuses on the find that how the grid cells perform path integration. Speciafically, this paper introduces the isotropic scaling condition to produce the hexagon firing pattern for grid cells. The optimization experiments show that the proposed formulation of place and grid cells demonstrated this.  Although I appreciated that the authors provide an interesting formulation for the relationship of place and grid cells, I have the following concerns:\n\n1.\tThe authors claim that they don’t make any orthogonality assumption and the isotropic scaling guarantees the l_2 error in L122. However, in the proof of Theorem 3 of this error bound, explicit orthogonal assumptions are made. I expect the authors to provide, in the rebuttal, a more rigorous proof for this error bound without any orthogonal assumptions.\n\n2.\tMany literatures have shown that cos/sin functions can produce hexagon patterns, e.g., [a, b]. Can you provide more connections to those results, because I highly suspect that the three conditions introduced in this paper will result in the cosine functions (Maybe the formulation (e.g., the isotropic scaling) in this paper is mathematically equivalent to the cosine functions?), especially after seeing the Fig 7 in Appendix. If this conjecture is correct, then I see no contribution for this paper, since we can simply use the predefined functions as in [a] to do both path integration and generate hexagon. Then what’s the purpose for the optimization?\n3.\tThe authors didn’t show that the linear model with isotropic condition has a hexagon grid pattern in the proof, thus the tittle of Sec 3.3 is misleading, “hexagon grid pattern” in the section title should be removed. \n4.\tTheoretic guarantee for generating the hexagon pattern by the introduced formulation will strengthen this paper a lot.\n5.\tIt’s not clear how to derive the third item from the second item in Eq (9).\n\n[a] Burgess N, Barry C, O'keefe J. An oscillatory interference model of grid cell firing. Hippocampus. 2007 Sep;17(9):801-12.\n\n[b] Fuhs MC, Touretzky DS. A spin glass model of path integration in rat medial entorhinal cortex. Journal of Neuroscience. 2006 Apr 19;26(16):4266-76.\n\n It seems that the only contribution is to introduce the isotropic scaling to generate the hexagon pattern during path integration. However, why should we do this? What ‘s the necessity to connect hexagon pattern and path integration via optimization, if predefined cosine functions can generate hexagon pattern very well?", "The paper derives a model of grid cells from first principles, starting with the basic assumption that position is represented as a high-D vector and that it is updated as a function of direction and speed.  The authors stipulate an isotropic scaling condition in order to make the representation robust to neural noise.  The elements of the resulting high-D embedding resemble grid cells, and importantly, the ability for error correction during path integration.\n  I find this to be a super interesting and exciting paper.  There are by now many papers that claim to show how grid cells emerge as a result of some kind of learning rule, but in my view this is the most insightful analysis I've seen to date.  It is a sensible and mathematically grounded approach.  Although they show how the grid cells emerge from learning, the resulting solution corroborates the theory - and so we understand why this is happening.  An important part of the story is robustness to noise, which is clearly linked to the isotropic condition and hence hexagonal grids.  This is high impact work that I believe will of interest to both the NeurIPS and computational neuroscience communities.\n\n\n yes", "The paper introduces a general framework for modeling 2D navigation via grid cells. The main idea is to embed a 2D position x into a higher-dimensional positional encoding v(x) and model 2D translations via group transformations in this embedding space. A specific case are linear transformations via rotation matrices that act on the embedding v(x). Under this assumption, it can be shown that hexagonal patterns which are characteristic for neural grid cells naturally emerge as an optimal encoding.   1. Presentation: According to the submission history, the ICML AC had concerns about the exposition and presentation of the paper. The presentation of the paper in its current form is very clear. I find the structure of the methods part adequate (Sec. 2 - Sec. 5) and easy to follow. \n\n2. Quality of theoretical contribution/mathematical validity: Overall, the theory sections are mathematically sound and the stated assumptions are reasonable (l. 82, l. 107), save for a number of minor flaws. It should be straightforward to address these issues in a minor revision:\n- The defined set of transformations F are intimately related to the standard mathematic concept of a \"flow\". Curiously, the authors do not mention this connection. This would also provide a stronger justification for Condition 1 (l. 82).\n- Why does the angle Phi not depend on positional differential dx. In Eq. (5), the expansion of dv would envolve both dr and dPhi. If this is an implicit requirement, it should be stated as an explicit assumption.\n- What is the motivation for restricting the approach to 2D environments? One could easily conceive of a formulation for more general Euclidean domains, like R^3. Most of the theory should be analogous. \n\n3. Results:\n- It is fascinating that the hexagonal patterns emerge from the optimization framework. It's also a strong justification for the validity of the proposed method and assumptions. Furthermore, this effect is validated quantitatively in Table 1.\n- It is a little disappointing that all evaluations focus on linear transformation models. One of the motivations of the proposed framework is that it allows for more general group transformations. This should be shown empirically as a proof of concept.\n- The path integration experiments lack baseline comparisons which makes it hard to put these results into context. I would like to see comparisons to recurrent [3] and PCA based [33] models in Figure 6.\n- The presented ablation study (l. 289) is useful to assess under which circumstances the hexagonal patterns emerge.\n\nMinor remarks:\n- I believe that the condition of F(v, 0, Phi) = v (l. 101) is central to the proposed framework and should be stated as a part of \"Condition 1\" (l. 82).\n- The embeddings v(x) lie on the Lie group manifold characterized by rotation matrices. This means that they are contained in an elliptic space with positive curvature. This seems counterintuitive, since the goal is to model 2D trajectory prediction in Euclidean space. E.g. there might be group transformations, such that 3 consecutive steps with 90 degree turns between them yield a closed loop. Is this a phenomenon you encountered or did you find that this effect is relevant in practice? There is a small discussion on limitations in Sec. 8 but no dedicated section or paragraph."], "review_score_variance": 4.222222222222222, "summary": "The reviewers are overall positive. The presented approach is mathematically sound and shows that grid cells can emerge from an optimization framework with minimal assumptions. The main criticism raised is whether the approach is useful beyond already existing models. The authors should clarify potential applications more explicitly in the revision, as well as include the additional experiments they cited in the rebuttal.\n", "paper_id": "nips_2021_kaIcRYq-NpG", "label": "val", "paper_acceptance": "accept"}
{"source_documents": ["The problem of accelerating drug discovery relies heavily on automatic tools to optimize precursor molecules to afford them with better biochemical properties. Our work in this paper substantially extends prior state-of-the-art on graph-to-graph translation methods for molecular optimization. In particular, we realize coherent multi-resolution representations by interweaving the encoding of substructure components with the atom-level encoding of the original molecular graph. Moreover, our graph decoder is fully autoregressive, and interleaves each step of adding a new substructure with the process of resolving its attachment to the emerging molecule. We evaluate our model on multiple molecular optimization tasks and show that our model significantly outperforms previous state-of-the-art baselines.", "Thank you for your insightful comments. We would like to first clarify the difference between our method and previous junction tree approach:\n\nJunction tree method of [Jin et al. 2019]:\n - Two independently operating encoders, one for the junction tree, the other for the original graph\n - Decoding is a strictly two-stage process (latent vectors -> junction tree -> graph) where the decoded junction tree is not affected by how the substructures are attached together\n - The graph decoder operates locally and predicts attachments between connected substructures in the junction tree independently during training.\n\nThe proposed approach:\n - Our encoder is a unified hierarchical message passing network where lower levels directly impact higher level (substructure) representations.\n - Previous attachment choices directly guide which substructures are/can be added to the expanding molecular structure.\n - Our hierarchical decoder unravels substructure choices together with their attachments in an autoregressive manner.\n\n\nQ1: What’s the novelty / contribution of our approach?\nOur approach seeks to address two key limitations of the junction tree method [Jin et al. 2019], which is illustrated in Figure 1 in the paper (page 2):\n - Their decoding is a strictly two-stage process. In the first stage, substructures are chosen without regard to how they can be attached to each other in the second stage. Therefore, it can result in invalid junction trees that cannot be realized into any molecule (see Figure 1a).\n - Their local graph decoder can lead to inconsistent substructure attachments (see Figure 1b).\n\nThe first problem is addressed by our hierarchical decoding process, where the predicted attachments are fed into decoder message passing network to guide substructure prediction. We solve the second problem by using an autoregressive decoder where previous attachment choices directly impact later substructure and attachment predictions.\n\nQ2: What’s the merit of autoregressive decoder?\nAutoregressive decoding prevents the model from predicting inconsistent substructure attachments (as illustrated by Figure 1b in the paper). As shown in the experiment, our autoregressive decoder indeed outperforms JTNN (e.g., 85.9% vs 77.8% on the DRD2 task).\n\nQ3: What does \"coherent multi-resolution representations\" mean?\n“Multi-resolution representation” refers to the substructure and atom embeddings. They together represent molecules at multiple levels. We used the word “coherent” because our substructure and atom encodings are learned by one hierarchical MPN instead of two separate MPNs as in the junction tree method.", "Thank you for your insightful comments. We want to first explain the motivation of our approach. The proposed hierarchical architecture seeks to address two key limitations of the junction tree method [Jin et al. 2019], which is illustrated in Figure 1 in the paper (page 2):\n - Their decoding is a strictly two-stage process (latent vectors -> junction tree -> graph). In the first stage, substructures are chosen without regard to how they can be attached to each other in the second stage. Therefore, it can result in invalid junction trees that cannot be realized into any molecule (see Figure 1a).\n - Their local graph decoder can lead to inconsistent substructure attachments (see Figure 1b).\n\nThe first problem is addressed by our hierarchical decoding process, where the predicted attachments are fed into decoder message passing network to guide substructure prediction. We solve the second problem by using an autoregressive decoder where previous attachment choices directly impact later substructure and attachment predictions.\n\nSome clarifications:\n - The encoder is the hierarchical message passing network that outputs substructure and atom vectors (not MLP). MLP is the variational inference module that learns the latent vector z, which is in addition to the message passing network.\n - The model achieves pretty large improvements on some tasks. For example, on the DRD2 task our model shows large improvement over previous SOTA (77.8% -> 85.9%).\n\nQ1: How are the substructures generated?\nSubstructures are automatically extracted from the molecules in the training set, in order to ensure structural coverage. For a given molecule, we extract its (smallest) rings and bonds as substructures and add them to the vocabulary. This procedure is purely data-driven. \nIndeed, the substructure vocabulary provides a lot of inductive bias for the algorithm and optimizing the vocabulary for downstream task is an interesting future work.\n\nQ2: Variational decoding is not well motivated. Why not using a stochastic decoding procedure?\nWe used variational decoding for two reasons:\n - All the prior work (Seq2Seq and JTNN) used variational decoding. Therefore we adopted the same strategy to establish a direct comparison.\n - Recent work has shown that variational decoding can generate more diverse outputs than stochastic decoding (e.g., in image translation [Zhu et al., 2017] and machine translation [Shen et al., 2019]). The reason is that stochastic decoding tends to learn small, local variations (e.g., replacing single atoms), while variational decoding captures diversity beyond local variations. To show this, we trained our model without variational inference and used stochastic decoding at test time. On the logP (sim $\\geq$ 0.6) dataset, the performance drops from 2.49 to 2.06 and diversity drops from 0.381 to 0.342. On the logP (sim $\\geq$ 0.4) dataset, the performance drops from 3.98 to 3.72 and diversity drops from 0.564 to 0.502. \n\nQ3: Why not use a Transformer instead of an LSTM or GRU?\nWe used LSTM / GRU because message passing networks (MPN) are standard choices for molecules and many previous works build upon MPNs (with various parameterizations). We agree that transformer is a promising architecture for graphs (especially if further tailored to graphs) but the gains are unclear at this point. \n\nQ4: Topological Prediction: the attention is over $c_{X}^{S}$ but the text claims it should be over $c_{X}^{G}$?\nWe apologize for the confusion. This is a typo and it should be $c_{X}^{S}$. The typo is now fixed.\n\nQ5: Attachment Layer MPN: the A_i seem to be a tuple $(S_i, {v_j})$. The set of attaching atoms is limited to 2 right?\nThe set of attaching atoms can be more than 2 because two rings can have three or more overlapping atoms.\n\nQ6: Since tree decompositions are not unique, does this work use different tree decompositions and DFS traversals as data augmentations?\nWe didn’t use different tree decompositions / DFS traversals for data augmentation because none of the baselines used any data augmentation strategies. \n\nQ7: Table 2b: What is a \"two-layer\" and \"one-layer\" encoder? \nTwo-layer encoder means the top substructure layer MPN is removed. One-layer encoder means the attachment layer MPN is also removed. \n\nQ8: Ablation studies, number of parameters.\nFor ablation studies, all models have a similar number of parameters. For both datasets, all the model parameters are between 6M to 6.2M. \n\nReferences\nZhu et al. \"Toward multimodal image-to-image translation.\" Advances in Neural Information Processing Systems. 2017.\nShen et al. \"Mixture Models for Diverse Machine Translation: Tricks of the Trade.\" International Conference on Machine Learning. 2019.", "Thank you for your insightful comments. We have fixed the typo you pointed out (and some others).\n\nQ1: In the training, the authors apply teacher forcing to the generation process with depth-first order. Why do you use depth-first order instead of other orders?\nOur hierarchical decoding process leverages the fact that graphs are generated in a depth-first order, especially topological prediction step. To use other orders such as breadth-first order, the graph decoding process needs to be modified accordingly. We chose depth-first order in order to make a fair comparison with JTNN, which also uses depth-first order.", "This paper developed a hierarchical graph-to-graph translation model to generate molecular graphs using chemical substructures as building blocks. In contrast to previous work, the proposed model is fully autoregressive and learns coherent multi-resolution representations. The experimental results show that the proposed method outperforms previous models.\n\nA few comments: \n\n1.The novelty\n- The method seems to be almost the same as the previous junction tree based formulation.  The paper includes a straightforward hierarchical extension and provides limited novelty with respect to deep learning.  \n- Can the method be used for other types of graph generation? \n\n2. Some minor wording issues\n- For instance, in the abstract, \" In particular, we realize coherent multi-resolution representations ..\" What does this mean? \n\n3. The main claim : \" ... our graph decoder is fully autoregressive..\"  why is this a merit? \n\n4.  The paper provided results from multiple molecular optimization tasks. The results and analysis seem comprehensive. The model was shown to significantly outperform baseline methods in discovering molecules with desired properties. The model runs faster during decoding and can perform conditional translation. \n ", "The authors present a heirarchical graph-to-graph translation method for generating novel organic molecules.\nWorking from the model of Jin et al. (2019), the authors introduce a three step heirarchy - the model first determines where a substructure should be generated, what is the substructure, then the attachments to the existing molecule.\nAll steps of this uses embeddings generated from a message passing network - these embeddings are input into a few bilinear attention layers to obtain the heirarchical generation scheme.\nThe model is trained with molecular pairs (X, Y), and a VAE loss - a hidden z vector controls the way to modify X to improve its properties.\nThe encoder is just a MLP over the difference between sum of embeddings at a atom level and at the substructure level.\nThe model is evaluated on accuracy and diversity, in both conditional and unconditional settings.\nThe experiments show a small improvement over previous SOTA algorithms.\n\nThis is a borderline paper, and I'm leaning towards a weak reject, because I don't believe the model is well motivated enough:\n- Sec 3.1 it's unclear how the substructures are generated - they provide a lot of inductive bias for the algorithm. \n  Are they automatically generated or built from a database of substructures?\n- Variational decoding does not seem well motivated enough - would a stochastic decoding procedure not work as well as having a latent vector that essentially adds noise to the training?\n- The experiments seem interesting and comprehensive - it seems that the model learns to exploit the biases and increase logP, as well as showing the ability to conditionally turn off DRD2-active properties of the molecules.\n\nSome questions:\n- Why not use a Transformer instead of an LSTM or GRU? The cell naturally acts over sets of neighbors and transformers are a natural model to tackle this problem.\n- Sec 3.1 Topological Prediction, the attention is over c_{X}^{S} but the text claims it should be over c_{X}^{G}? Is ^G the attention substructure?\n- Sec 3.1 Attachment Layer MPN: the A_i seem to be a tuple (S_i, {v_j}). The set of attaching atoms is limited to 2 right? It might be more clear to simply enumerate them here if so.\n- Sec 3.1 Substructure Tree: Since tree decompositions are not unique, does this work use the different tree decompositions and DFS traversals as data augmentations?\n- Table 2b: What is a \"two-layer\" and \"one layer\" encoder? Is it the size of the MLP or the removal of the attachment MPNs?\n- Ablation study: Since the Attachment Layer has all the substructure information, this ablation should ideally make sure the models all have a similar number of parameters, and the decrease in performance isn't due to the decrease in parameters.\n\nNits:\n- Sec 3.1 \"bi-linear\" should not have a dash, bilinear is one word.\n", "This paper proposed a hierarchical graph-to-graph translation method to modify compounds to improve the biochemical properties. The authors proposed to generate the new molecular in a autoregressive manner. To improve the performance of the model, the input molecular is encoded into different resolutions including atom, attachment, and substructure layer. The paper is well written and the figures in the paper also enable the paper easy to read. In the experiments, the authors compare the proposed method with serval state-of-the-art methods. The results well analyzed and the ablation study is provided. Overall, this is a good paper considering its technical contribution and writing.\n\nHowever, there are some small issues should be addressed:\n\n1. There are some typos in the paper. For example, in the topological prediction section in page 3,  \"the hidden representation of $S_k$ learned be the decoder \" -> learned be encoder.\n\n2. In the training, the authors apply teacher forcing to the generation process with depth-first order. Why do you use depth-first order not any other orders?  \n"], "review_score_variance": 2.0, "summary": "Two reviewers are negative on this paper while the other reviewer is slightly positive. Overall, the paper does not make the bar of ICLR. A reject is recommended.", "paper_id": "iclr_2020_rJeeKTNKDB", "label": "train", "paper_acceptance": "reject"}
{"source_documents": ["Many cooperative multiagent reinforcement learning environments provide agents with a sparse team-based reward as well as a dense agent-specific reward that incentivizes learning basic skills. Training policies solely on the team-based reward is often difficult due to its sparsity. Also, relying solely on the agent-specific reward is sub-optimal because it usually does not capture the team coordination objective. A common approach is to use reward shaping to construct a proxy reward by combining the individual rewards. However, this requires manual tuning for each environment. We introduce Multiagent Evolutionary Reinforcement Learning (MERL), a split-level training platform that handles the two objectives separately through two optimization processes. An evolutionary algorithm maximizes the sparse team-based objective through neuroevolution on a population of teams. Concurrently, a gradient-based optimizer trains policies to only maximize the dense agent-specific rewards. The gradient-based policies are periodically added to the evolutionary population as a way of information transfer between the two optimization processes. This enables the evolutionary algorithm to use skills learned via the agent-specific rewards toward optimizing the global objective. Results demonstrate that MERL significantly outperforms state-of-the-art methods such as MADDPG on a number of difficult coordination benchmarks. ", "This paper proposes an integration of neuroevolution and gradient-based learning for reinforcement learning applications. The evolutionary algorithm focuses on sparse reward and multiagent/team optimization, while the gradient-based learning is used to inject selectively improved genotypes in the population.\nThis work addresses a very hot topic, i.e. the integration of NE and DRL, and the proposed method offers the positive side of both without introducing major downsides. The presented results come from a relatively simple but useful multiagent benchmark which has broad adoption. The paper is well written, presents several contributions that can be extended and ported to other work, and the results are statistically significant.\n\nThere is one notable piece missing which forces me to bridle my enthusiasm: a discussion of the genotype and of its interpretation into the network phenotype. The form taken by the actual agent is not explicitly stated; following the adoption of TD3 I would expect a policy and two critics, for a grand total of three neural networks, but this remains unverified. And if each agent is composed of three neural networks, and each individual represents a team, does this mean that each genotype is a concatenation of three (flattened) weight matrices per each agent in the team? What is the actual genotype size? It sounds huge, I would expect to be at least several hundred weights; but then this would clash with the proposed minuscule population size of 10 (recent deep neuroevolution work from Uber uses populations THREE orders of magnitude larger). Has the population size been proportionated to the genotype dimensionality? Would it be possible to reference the widely adopted defaults of industry standard CMA-ES? Speaking of algorithms, where is the chosen EA implementation discussed? The overview seems to describe a textbook genetic algorithm, but that has been overtaken as state-of-the-art since decades, constituting a poor match for TD3.\n\nOmitting such a chapter severely limits not only the reproducibility of the work but its full understanding. For example, does the EA have sufficient population size to contribute significantly to the process, or is it just performing as a fancy version of Random Weight Guessing? Could you actually quickly run RWG with direct policy search (rather than random action selection) to establish the effective complexity of the task? My final rating after rebuttal will vary wildly depending on the ability to cover such an important piece of information. \n\nA few minor points, because I think that the paper appearance deserves to match the quality of the content:\n- The images are consistently too small and hard to read. I understand the need to fit in the page limit by the deadline, but for the camera ready version it will be necessary to trim the text and rescale all images.\n- The text is well written but often slowing down the pace for no added value, such as by dedicating a whole page to discussing a series of previously published environments.\n- The hyperparameters of the evolutionary algorithm look completely unoptimized. I would expect a definite improvement in performance with minimal tuning.\n- The \"standard neuroevolutionary algorithm\" from 2006 presented as baseline has not been state-of-the-art for over a decade. I would understand its usage as a baseline if that is indeed the underlying evolutionary setup, but otherwise I see no use for such a baseline.\n\n-----------------------------------------------------------------------------------------------\n# Update following the rebuttal phase\n-----------------------------------------------------------------------------------------------\n\nThank you for your work and for the extended experimentation. I am confident the quality of the work is overall increased.\n\nThe core research question behind my original doubt however remains unaddressed: does the EC part of the algorithm sensibly support the gradient-descent part, or is the algorithm basically behaving as a (noisy) multi-agent TD3?\nSuch a contribution by itself would be undoubtedly important. Submitting it as a principled unification of EC and DL however would be more than a simple misnomer: it could mislead further research in what is an extremely promising area.\n\nThe scientific approach to clarify this point would be to design an experiment showcasing the performance of MARL using a range of sensible population sizes. To understand what \"sensible\" means in this context, I refer to a classic:\nhttp://www.cmap.polytechnique.fr/~nikolaus.hansen/cec2005ipopcmaes.pdf\nA lower bound for the population size with simple / unimodal fitness functions would be $4+floor(3*log(10'000)) = 31$. With such a complex, multimodal fitness though, no contribution from the EA can be expected (based on common practice in the EC field) without at least doubling or tripling that number. The upper bound does not need to be as high as with the recent Uber AI work (10k), but certainly showing the performance with a population of a few hundreds would be the minimum necessary to support your claim. A population size of 10 represents a proper lower bound for a genotype of up to 10 parameters; it is by no means within a reasonable range with your dimensionality of 10'000 parameters, and no researcher with experience in EC would expect anything but noise from such results -- with non-decreasing performance uniquely due to elitism.\nThe new runs in Appendice C only vary the population size for the ES algorithm, proposed as a baseline. No performance of MARL using a sensible population size is presented.\n\nThe fundamental claim is thereby unsustainable by current results. The idea is extremely intriguing and very promising, easily leading to supportive enthusiasm; it is my personal belief however that accepting this work in such a premature stage (and with an incorrect claim) could stunt further research in this direction.\n\n[By the way, the reference Python CMA-ES implementation runs with tens of thousands of parameters and a population size of 60 in a few seconds per generation on a recent laptop: the claim of performance limitations as an excuse for not investigating a core claim suggests that more work would be better invested prior to acceptance.]\n", "This paper proposes an algorithm to learn coordination strategies for multi-agent reinforcement learning. It combines gradient-based optimization (Actor-critic) with Neuroevolution (genetic algorithms style). Specifically, Actor-critic is used to train an ensemble of agents (referred to as “team”) using a manually designed agent-specific reward. Coordination within a team is then learned with Neuroevolution. The overall design accommodates sharing of data between Actor-critic and Neuroevolution, and migration of policies. Evaluation is done using the multi-particle environments (Lowe et. al. 2017) and a Rover domain task.\n\n\nI have the following questions:\n\n1.\tComparison with PBT-MARL (Liu et al, 2019): PBT-MARL also proposed using gradient-methods (Retrace-SVG0) for learning with dense, shaped (local) rewards, and then using Neuroevolution to optimize the agents for coordination. I don’t think the description in Section 2 characterizes PBT-MARL well enough – reading that gives the impression that it only evolves the scalarization coefficients. PBT-MARL combines rewards with different discount factors (yielding it much more representation power than simple scalarization), and the discount factors are also evolved. Furthermore, the agent network weights are evolved based on team-reward, to learn coordination strategies. \n\nAt a qualitative level, this paper seems to be using a similar approach, albeit the specifics of Neuroevolution and policy-gradients are different. I would like the authors to shed light on the scenarios where they argue their method holds inherent advantage(s) compared to PBT-MARL.\n\n2.\tIf I understand correctly, the individual agents in the team trained with DDPG would converge to similar policies – this is because each individual is trained with the same (agent-specific) reward, all agents in team use the same shared critic Q, and there is no flow of team from Neuroevolution to DDPG phase. This in itself is not a problem, because MADDPG should do the same if all agents are trained with the same team-reward function. The issue is that there are crucial differences in the architectures -- while the MADDPG paper had a separate Q network and policy network for each agent, MERL shares policy parameters (lower layers) between agents and uses a single, shared Q network. Have the authors done ablations with more aligned architectures, so that the improvements due to the main algorithmic contributions can be clearer?  \n\n3.\tThe notation defined in the background section is “s” for completed state (all agents) and “o” for individual observations. In the for-loop in Algorithm 1, are correct variables being used at all places, e.g. for pi, Q? In other words, which functions depend on the complete state of all agents, and which are decentralized? Additionally, should lines 23/24 be inside the for-loop?\n\n4.\tExperiments – In section 4, could the authors provide the values of N, L, K used in different environments, as applicable? The MADDPG paper claims good performance for multi-particle environments, which contradicts Figure 4 and 5. For example, MADDPG claims about 16 touches per episode with 30% faster prey, but Figure 4 has it converging to about 5. This makes me wonder if the parameters (N, L, K) are different in the two evaluations. Also, physical-deception task performance is reported in success% in the MADDPG paper, but the authors use a different distance metric. A standardized way of comparing performance would help the community. \n\n5.\tIn MADDPG paper, an ensemble-based version is reported to perform much better. Since MERL is an ensemble method, is that not a more direct comparison?\n\nMinor points:\n\n1.\tIn environments (expect Rover), did the authors observe any benefits from adding the agent-specific reward to supplement the team-rewards (i.e. mixed reward setting) for the baselines?\n\n2.\tIn Figure 8, why is the right-most POI lit when the red trajectory is far away from it? If the authors could provide a video of the MERL-trained policy for this domain, it’d be really cool.\n\n\n\n----------------------Post-rebuttal update----------------------\n\n\nI am satisfied with the author response and changes to the paper. I have increased my rating accordingly.", "This paper proposes to use a two-level optimization process to solve the challenge of optimizing the team reward and the agent's reward simultaneously, which are often not aligned. It applies the evolutionary algorithm to optimize the sparse team reward, while using RL (TD3) to optimize the agent's dense reward. In this way, there is no need to combine these two rewards into a scalar that often requires extensive manual tuning.\n\nI vote for accepting this paper, because it tackles a practical problem in multi-agent learning. The presentation is clear, the algorithm is simple and sensible, the evaluation is thorough, and the results are better than the state-of-the-art.\n\nThe only question that I have is the sharing of replay-buffer for the same agent in different teams (Figure 2). For example, since the second agents in team1 and in team2 might learn to serve different roles in the task and may have completely different policies. I am not sure what is the purpose of this sharing. Considering the two extreme cases of replay buffer sharing, we could share all the data in a single replay buffer, or we could keep a separate replay buffer for each individual agent in each team, the paper chose the compromise between these two extremes. I wonder whether there is any theoretical or practical reasons to make this design choice. Is it important? I hope that the paper could have a deeper discussion if it is an important design decision.\n\n----------------------Update after rebuttal----------------------\n\nThanks for the detailed response and the additional experiments. The response addressed my questions. Thus I will keep my original recommendation of acceptance.", "We thank all the three reviewers for their in-depth analysis and questions on our paper. In our rebuttal below, we have addressed each reviewer's comments and questions. \n\nSeveral of the responses required us to run additional experiments.  We have updated the manuscript with the results from these experiments. We added them to the Appendix section to highlight them and differentiate them from the existing plots in the original manuscript. We will integrate these results back into the main body of the paper in the camera-ready version.\n\nAdditionally, we have updated our anonymized Github repo (https://anonymous.4open.science/r/1590ffb0-aa6b-4838-9d59-ae20cdd8df11/) with all of the additional code that were used to generate the new results. These are available in the folder called \"new_experiments\". The repo also has a folder called \"videos\" containing a set of animations that demonstrate the different policies learnt by MERL vs MADDPG. \n\nSpecifically, the additional experiments we did are:\n1. Ran EA for several different population sizes and compared them to MERL to address Reviewer 1's questions about the role of population sizes (Appendix C). This experiment demonstrated that MERL significantly outperforms purely evolutionary approaches for the several different population sizes explored. \n\n2. Ran a version of ES (Evolutionary Strategies) as described in the Open AI Paper (https://arxiv.org/abs/1703.03864) to address Reviewer 1's question on more modern EA benchmarks. For this experiment, we investigated the role of population size (Appendix D.1) as well as hyper-parameter tuning (Appendix D.2). \n\n3. Implemented two versions of RWG in response to Reviewer 1's suggestion. As we report below, RWG was unable to learn a policy even when trained up to 100M time steps. \n\n4. Ran an experiment on the Predator-Prey benchmark showing the difference in performance between MADDPG for a setting with 3 preys vs 1 prey (Appendix E). This experiment was to address Reviewer 2's questions on apparent discrepancies in MADDPG's performance as reported in their paper vs ours. Based on this experiment (still training), it appears that the gap might be due to our use of 1 prey vs MADDPG's use of 3 preys (although they do not report this clearly in their paper).\n\n5. Following reviewer 3's suggestion, we created an animation showing the trajectories of different agents as they team up to solve the Rover domain problem for a coupling of 3. The animation is rather rudimentary but clearly demonstrates MERL's well-coordinated strategies that successfully cover 3 out of 4 PoIs after 2M time-steps of training - while MADDPG is unable to form a coherent strategy for the same amount of training samples. ", "Thank you for your insightful feedback.\n\nWe use a direct encoding setup where the genotype encodes the weights of the policy network. Each agent has one actor-critic set-up (specifically, one actor and two critics) that learns using policy gradients and, separately, an evolutionary population of k policy networks. The evolutionary population does not have any critic networks. During migration, the gradient-based policy is copied into the evolutionary population replacing one of the k policy networks there. Since neuroevolution does not use a critic, the critics are never migrated. \n\nThe number of parameters varies by task but are in general within the range of tens of thousands for the policy. \n\nAs the reviewer pointed out, a population size of 10 is tiny compared to the Uber AI papers. By itself, they are ill-equipped to train tens of thousands of policy parameters from scratch. This is where the policy migration from the policy gradient optimizer to the evolutionary population becomes crucial and is a critical contribution of this paper. We use the gradient-based learners to selectively inject improved genotypes into the evolutionary population. As the EA population acquires these “locally-trained” weights periodically, evolution can bootstrap its search using them. Thus the EA’s search space - and the required population size - is reduced greatly compared to methods that rely exclusively on evolution to train all of its weights. \n\nFurther, EA uses the migrated networks as building blocks to select for alignment with the team objective - e.g., rovers picking POIs to go to that best maximize the global reward even if it is not the closest one (essential to team formation and spreading behavior). This mechanism allows us to achieve state-of-the-art performance without relying on a large population that is typical of purely evolutionary approaches.\n\nHowever, we acknowledge that increasing the population size would assuredly help learning (as corroborated in the Uber AI papers). However, this would cause the method to be extremely sample-expensive. For instance, for a rollout episode of 500 steps, one generation of evolution with a population size of 10 and 100 would cost 5,000 and 50,000 samples, respectively. This would be the difference between running 200 and 20 generations of evolution with a 2-million sample budget (in the case of the rover-domain). A key motivation for our paper is to learn coordination policies while also being overall sample-efficient. This is different from the focus on wall-clock time (leveraging EA/ES's parallelizability) in most contemporary approaches.\n\nWe performed an additional experiment to evaluate the efficacy of different population sizes from 10-1,000 for the rover domain with a coupling factor of 3. All results were averaged over 5 runs. We added this result to Appendix C in our updated manuscript.\n\nWe found the best EA performance at K=100 reaching ~0.3 in 100-million time steps. Compare this to MERL which reaches a performance of ~0.48 in only 2 million time steps. This demonstrates the efficacy of the guided evolution approach in our paper over purely evolutionary approaches. \n\nAs the reviewer stated, we used a very simple genetic algorithm as our global optimizer without any parameter tuning. Tuning these parameters can only improve MERL’s performance. However, the key message in the paper is that MERL allows ease of design and does not need carefully tuned parameters.\n\nAs proposed by the reviewer, we explored additional baselines. Since our parameter space was in the order of tens of thousands, CMA-ES was infeasible to run within the rebuttal period. Thus we chose Evolutionary-Strategies (ES) which has been successfully used in the recent Open AI work. \n\nWe ran comparisons in the rover domain with a coupling factor of 3. All results were averaged over 5 runs.  The ES result is shown in Appendix D in our updated manuscript. \n\nIn Appendix D.1, we vary the ES population size from 100-10,000. The top performance is ~0.1 at 100 million steps while MERL achieves ~0.48 in 2 million time steps. \n\nApart from the population size, a key hyperparameter for ES is the variance of the perturbation factor (sigma). We run a parameter sweep for sigma and report results in Appendix D.2 - and did not find any major observable improvement. \n\nFurther, we implemented RWG with a direct policy search using normal and uniform distribution to initialize the guesses for neural network weights. With 100 million samples, RWG led to a performance of ~0.009 and ~0.007 corresponding to normal and uniform weight initialization schemes, respectively. In comparison, MERL converged to 0.48 with a 2-million sample budget. The failure of RWG to learn can be attributed to the sparsity of the reward distribution - where 3 agents need to independently convene to a POI for a reward. \n\nWe concede the points about writing style and formatting and will incorporate these suggestions in the final manuscript. \n", "Thank you for your insightful feedback.\n\nThis is a fair point. In the current setup for MERL, we constrain the n-th agents in each team to perform the same role as we share the replay buffer among them. As the reviewer stated, this is a middle ground between using a single buffer for all agents and a replay buffer for each agent in each team. \n\nIn our observation, using a single buffer for all agents in every team leads to homogenization of the agents as all of them will lean towards the same behavior. On the other extreme case, each agent in each team having its own buffer greatly increases the memory and computational cost of learning while also curtailing information sharing across teams. Sharing the buffer for the n-th agent across all teams was the middle ground that led to good diversity (among team members) while remaining computationally and memory-wise tractable. ", "Thank you for your insightful feedback.\n\n--->> \"PBT-MARL combines rewards with different discount factors (yielding it much more representation power than simple scalarization), and the discount factors are also evolved.\"\n\nThis is a very good point. Since PBT-MARL also evolves the discount rates associated with each reward and their mixing coefficients, they do have more representation power than the underlying simple linear mixing function. However, this setup still relies on the design of a mixing function to tackle the sparse team-reward. This is an important point of distinction with MERL that affects ease and flexibility of design as we further explain below.\n\n--->> \"Furthermore, the agent network weights are evolved based on team-reward, to learn coordination strategies.\"\n\nIn PBT-MARL, evolution only inherits policies (copies weights between agents) and does not evolve them directly (Algorithm 5 in Appendix B.5). Mutation and crossover only apply to the hyper-parameters (mixing coefficients, discount factor, etc) across agents and not to the weights themselves. \n\nThis means that all the weight updates can only come from the underlying policy gradient algorithm (SVG0). This makes PBT-MARL’s performance entirely dependent on the policy gradient learner. Since SVG0 does not directly optimize the team-reward and only optimizes the mixture of agent-specific rewards, the emergence of coordination strategies strongly relies on the existence and discovery of a good mixing function. \n\nIn contrast, MERL allows evolution to mutate/crossover the weights of the policy allowing it to directly search for coordination strategies that best maximize the team-reward. This is irrespective of whether a good mixing function exists - the split-level optimization of MERL alleviates the need to construct one. \n\nFor illustration, consider the extreme scenario where the agent-specific rewards (shaping rewards) are entirely devoid of any useful information in optimizing the team-reward. In this scenario, MERL would automatically ignore the policy-gradient migrated policies and default to an EA to optimize the team-reward - thus allowing it to learn a usable policy. \n\nIn this scenario, no choice of hyperparameters, discount factors or mixing coefficients would be able to align the information-absent local reward (shaping functions) towards optimizing the team-reward for SVG0 to use. In turn, since weight updates can only come from SVG0, PBT-MARL would not be able to learn a team strategy at all. \n\n--->> \"The issue is that there are crucial differences in the architectures -- while the MADDPG paper had a separate Q network and policy network for each agent, MERL shares policy parameters (lower layers) between agents and uses a single, shared Q network. Have the authors done ablations with more aligned architectures, so that the improvements due to the main algorithmic contributions can be clearer?\"\n\nWe hypothesized that since the agents are homogeneous in their sensors and actuators, the perception and control modalities would be similar and perhaps would not need to be learned independently by each agent. This led to our design of sharing the policy parameters in the lower layers across all agents in a team. It is important to note that the MADDPG and MATD3 policies in our paper also use this parameter-sharing architecture. Thus all baselines use identical topologies in order to isolate the performance differences coming purely from the algorithmic differences.\n\nMADDPG implements separate but centralized critics in order to tackle non-stationarity. In contrast, MERL’s global optimizer (neuroevolution) is immune to non-stationarity as it directly evaluates the joint team performance independently for each rollout. Thus we designed MERL’s policy gradient algorithms with a shared and decentralized critic which is more compute and memory efficient. \n\nHowever, as suggested by the reviewer, we are implementing a version of MERL with separate but centralized critics as in MADDPG and will update the manuscript when the experiment completes. Since the centralized critic has access to more information, we expect this to only further improve MERL’s performance (at the cost of additional memory and compute) - and hence, not change the key conclusions of the paper.\n\n--->> \"Notation errors\"\n\nMERL is entirely decentralized, both during training and execution. All π and Q in MERL uses the observations o and never the complete state (s). We acknowledge our inconsistent use of s, o in the background and algorithm section which caused this confusion. We have updated the manuscript to remedy this confusion. \n\nLine 23 (soft update for target Q) should be inside the inner for-loop as we do a soft update after each gradient step. However, Line 24 is an error and should be outside the inner for-loop as migration happens every generation. We updated the manuscript with these corrections.", "--->> \"Parameter values of N, L, K and comparisons with the MA-DDPG paper results\"\n\nFor the rover-domain, N = 2*coupling so that there were enough agents to form two concurrent teams. L = 0 and K = 4 POIs. \n\nFor the multiagent-envs, we inherited the values of N, L, K from the multiagent-env codebase that came with the MADDPG paper: https://github.com/openai/multiagent-particle-envs/tree/master/multiagent/scenarios. \n\nUpon a second review of the MADDPG paper, we realize that some of the default values in the codebase are different from those reported in the MADDPG paper. \n\nFor example, predator-prey has L=2 in their codebase - which is also what we used for our paper. However, the results in their paper use L=3 (Table #3 in Appendix). \n\nSimilarly, the number of preys we used for our benchmark is 1 - consistent with their codebase. Their paper does not reveal how many preys were used for their benchmark resulting in the 16 touches per episode - they simply mention 3 agents without clarifying if these are predator or prey agents. Since they report ~3x the number of touches (16 vs 5), a strong possibility is that they meant 3 agents of each type.  \n\nWe are performing one experiment that uses 3 predators and 3 preys for the predator-prey benchmark in the MADDPG setting (specifically, with MATD3 since TD3 is an improvement over DDPG). We do observe a significantly increased number of touches per episode although it is in the early stage of training. At the 4.3M samples stage, the 3-prey setting achieves about ~3x the number of touches as the 1-prey setting. Thus, it is conceivable that at ~10M samples (the convergence time for the results in our paper), the 3-prey setting will converge closer to 16 touches compared to 5 touches for the 1-prey setting. We report the latest available results in Appendix E in our revised manuscript. \n\nHaving said that, the relative performance should not be affected for the results reported in our paper as all compared baselines were trained and tested in the same environment (i.e. 1 prey). \n\n--->> \"In MADDPG paper, an ensemble-based version is reported to perform much better. Since MERL is an ensemble method, is that not a more direct comparison?\"\n\nMADDPG-ensemble maintains multiple sub-policies for each agent. Each sub-policy also has its own individual buffer and learns independently from the other policies. \n\nWhile MERL does use a population of policies for each agent, they compete against each other and are constantly mixed using crossover-operations. Each agent (n'th team member) in MERL also maintains the same replay buffer and only has one policy/critic that uses this buffer to learn. Thus, MERL does not really use an ensembling method in the way MADDPG-ensemble does.\n\nThus, comparing MERL to MADDPG-ensemble might not be the most direct comparison. In order to level the playing field for MERL, one would need to extend each agent in MERL to use an ensemble similar to MADDPG-ensemble. We expect MERL to also gain performance from such ensembling. We defer this to future work as it does not change the central message of the paper.\n\n--->> \"In environments (expect Rover), did the authors observe any benefits from adding the agent-specific reward to supplement the team-rewards (i.e. mixed reward setting) for the baselines?\"\n\nThe environments other than Rover already provide mixed rewards as a baseline implementation for MADDPG and MATD3. We did not change these settings - thus the results reported for these environments only use the baseline mixed rewards. \n\nFor neuroevolution, the results reported use only a team reward. However, we also tested this with added agent-specific rewards and observed consistently worse results. This was not reported in the paper in the interest of keeping the plots less cluttered and because we separately studied the impact of different mixing modes in the context of MADDPG and MATD3.\n\n--->> \"In Figure 8, why is the right-most POI lit when the red trajectory is far away from it? If the authors could provide a video of the MERL-trained policy for this domain, it’d be really cool.\"\n\nThe POI has an activation distance of 3 units around itself. If n rovers converge within this distance concurrently, they can activate the POI where n = coupling factor. The activation distance was not depicted in the visualization. In that specific figure, the red trajectory actually comes inside the required activation distance and helps satisfy the coupling-3 requirement. We will update the visualization to make this clearer. We also updated the anonymous github repo linked in the paper with videos demonstrating the different trajectories. "], "review_score_variance": 8.666666666666666, "summary": "This work has a lot of promise; however, the author response was not sufficient to address the concerns expressed by reviewer 1, leading to an aggregate rating that is just not sufficient to justify an acceptance recommendation. The AC recommends rejection.", "paper_id": "iclr_2020_rkxtNaNKwr", "label": "train", "paper_acceptance": "reject"}
{"source_documents": ["Training recurrent neural networks (RNNs) on long sequence tasks is plagued with difficulties arising from the exponential explosion or vanishing of signals as they propagate forward or backward through the network. Many techniques have been proposed to ameliorate these issues, including various algorithmic and architectural modifications. Two of the most successful RNN architectures, the LSTM and the GRU, do exhibit modest improvements over vanilla RNN cells, but they still suffer from instabilities when trained on very long sequences. In this work, we develop a mean field theory of signal propagation in LSTMs and GRUs that enables us to calculate the time scales for signal propagation as well as the spectral properties of the state-to-state Jacobians. By optimizing these quantities in terms of the initialization hyperparameters, we derive a novel initialization scheme that eliminates or reduces training instabilities. We demonstrate the efficacy of our initialization scheme on multiple sequence tasks, on which it enables successful training while a standard initialization either fails completely or is orders of magnitude slower. We also observe a beneficial effect on generalization performance using this new initialization.", "This paper touches the signal processing/long term propagation problem in gated recurrent neural networks from the mean field theory. The paper starts from a dynamic system view of the recurrent neural networks and calculates the time scale of converging to the fixed point. In order to avoid the system to converge to the fixed point, the authors utilize some initialization strategy to keep the time scale to infinity. The authors also relate the time scale to state-to-state Jacobians. \n\nThe paper is interesting but more details could be added to both theories and experiments. Given all those extra details, I can increase my scores.\n\nFor the theory:\n1. It is unclear how you go from equation (7) to (8). References or more explanations need to be added.\n2. It is unclear how the initializations in E.4 satisfies the criteria you define in the paper. More explanations can be added.\n3. This mean field approximation is still far away from practice. It is hard to believe the input in real life is Gaussian distributed vectors (sec 4.2). What will happen if the input distributions are not Gaussian? This should be discussed.\n4. This initialization only helps at the beginning of the training. What will happen if we do one backpropagation? This should be addressed.\n\nFor the experiments:\n1. The authors did not state the some of the experiment details in the papers, like what optimizer, regularization, learning rate.... To make better assessment of the experiments, those details should be added. Do you train/tune all the different initializations in the same way?\n2. I cannot find the description of Figure 1 anywhere in the paper. It is hard to believe LSTM did poorly on sequential MNIST unless giving more details since LSTM has been proved to perform okay on sequential MNIST in a bunch of papers[1]. \n3. What is the meaning of 112 dimension in 5.3? Does that mean you only choose the first 4 rows of MNIST images?\n4. Comparison over random seeds should be honestly justified for all the experiments.\n\nMinors:\n1. You have one missing \\Sigma_z in equation (4a).\n2. \\mu_s^2 in equation (4b) should be (\\mu_s^t)^2\n\nReferences:\n[1] Arjovsky, Martin, Amar Shah, and Yoshua Bengio. \"Unitary evolution recurrent neural networks.\" International Conference on Machine Learning. 2016.\n\n-------------\nI change my scores to weak reject . I agree with Reviewer 2 that the paper provide some insight from Physics and can be an interesting contribution to the community. However, I think all of the reviewers. including myself, find the paper hard to read for the general machine learning audience. And even though the authors mention that they will fix the text in the future, they do not change any text of the paper. I think writing is also important besides presenting interesting research ideas. Overall, I think the paper will be benefited from resubmission.", "The aim of this paper is to suggest randomized initializations for the various weights of a recurrent neural network (GRUs and various LSTMs are covered), such that training these networks gets to a successful start, when the model is trained on long sequences. Instead of being heuristic, their approach follows first principles of analyzing signal propagation through time, using ideas from statistical thermodynamics (mean field approximations). Some experiments, on toy datasets, validate their approach.\n\nI am quite intrigued by this paper. It is using interesting theory, shapes it to a practically highly relevant and difficult applied problem, and in the end comes up with a computable criterion of how to choose hyperparameters (means and variances of Gaussians to sample initial weights from). While the results in practice are still not too convincing, I am strongly in favour of giving this approach the benefit of doubt, as it could lead to practically very useful downstream work.\n\nThe main direction of improvement for this paper (given that experiments are what they are -- somewhat limited to toy situations right now) is to better explain the methodology to researchers not familiar with mean field methods. Most importantly, it is not explained in the main text how hyperparameters are really chosen in the end. Looking at Appendix E, I find some pretty basic choices, and no other alternatives considered. It is not explained why these choices satisfy the theory, why they'd be the only ones, etc. This creates a disconnect between the very nice (and seemingly useful) theory and its implications (they are not really well spelled out).\n\nHere is what I understood (and I am not specifically an expert on stat mech). The authors assume that the dimension of latent states (N) grows large. They assume that weights are sampled independently, and identical distributed in groups k (different cell types, weight vs bias), and that inputs are correlated with each other in each dimension. Based on these assumption, they follow Gaussians statistics through a number of time steps. In the limit, one gets a deterministic dynamical system, and as t -> infty, this may converge to a fixed point. In a very nice argument (which they could explain better), they state that such rapid convergence is bad news, because then information cannot spread across long time scales, so one has to find hyperparameters for which the system behaves \"critically\". A second arguments tries to keep gradient sizes (under MF assumptions) of O(1), so neither -> 0, not -> infty, which is again some \"critical\" range. Under their assumption, these critical conditions can be computed depending on the hyperparameters.\n\nUnfortunately, this is where the paper somewhat stops, it does not give specific methods for finding hyperpars that satisfy the criteria, at least not in the sense of characterising the whole space of such hyperpars (instead, in Appendix E, they just state some few settings that do). As a direction for future work, this would be very important. Another side question is whether for what the authors call \"trainability\", the only point that matters is whether for the initial weights, signals can spread and gradients are O(1). It is certainly necessary, I see that.\n\nDetailed comments:\n- Please fix Table 1, the expressions seem broken. What does \"r2\" mean in the GRU column?\n- At least for me, (1a) to (1c) really was too short. At least in the Appendix, please do explain how this gives GRU and LSTM\n- Please explain the untied weight assumption somewhere. s^t is a map of s^(t-1) and W_k, so how can W_k be independent\n   of all s^t? What are you really assuming here?\n- It took some repeated reading until I understood why the expressions in (2a) to (4b) do not depend on i, j, a, b (except\n  whether a = b or a != b). Explain that properly\n- The core of the whole approach seems to be first half of page 5. This seems like a very nice argument, but hard to understand. Try making it more crisp. I kind of get the rough idea why fast convergence over t would be bad, but would total divergence over t not also be bad?\n- In (12a-c), do you mean \"equal\" or \"approximately equal\"?\n- In 4.4: \"This motivates the general form of the initializations used in the experiments\": You have to make this more explicit. Why are your choices the only ones? Could there not be other choices satisfying (12a-c) approx, and be better?\n- Value of Sigma_z = 1: This seems odd to me, then your covariances are degenerate (rank 1 instead of 2). Please explain\n- Standard LSTM harder than GRU or peephole LSTM: Again, this sounds real interesting, but I did not get it from the explanation\n- I did not understand Figure 2. How are Theta_0, Theta_1 chosen?\n- As said above, the experiments are interesting, but somewhat artificial. Please do at least comment on real-world applications, and whether (and how) the ideas here would apply\n- Discussion: \"there is no clear principled way...\": Well, but practitioners need something. I'd disagree, at least one could attempt to navigate this space by global optimization techniques...\n\n\nADDITIONAL COMMENT:\n\nI tried to append the following as comment, but the (pretty broken) system would not let me, insisting that \"reader is not valid\" (???). Anyway, here it is. I hope I am allowed to add to my own review.\n\nI've seen the argument in reviews that assumptions made by this paper about independencies between weights and inner states are wrong, and therefore conclusions are not valid.\n\nFirst, such assumptions are indeed pretty common in such statistical mech analyses of learning methods. Second, you have to distinguish between weights after (random) initialization and after training. Of course, LSTM represents long term dependencies after training, but initialization is a different story.\n\nIf I was the AC for this paper, I'd ask somebody with at least some background in statistical mech to provide some additional opinions, as the reviewers (including myself) are not fully qualified.\n", "The authors propose a mean-field analysis of recurrent networks in this paper. I have a few concerns about this paper:\n\n(1) The most serious concern about their analysis comes from their assumption. They assume the weight W is independent on the state s_t (Page 4, Lines 5-6). The recursive structure is the most complicated part of the recurrent networks, and also its major difference from feedforward networks. In current networks, the hidden states become (or even heavily) dependent on the weight due to recursion.\n\nWhen making such an assumption, the recurrent networks just become similar to feedforward networks. The authors' claim that \"the untied weights assumption actually has long history of yielding correct prediction\" is not ungrounded and questionable.\n\n(2) The paper is not well written. Some assumptions are not explicitly stated. They are placed in the text without any highlight. Some theoretical statements are claimed without any rigorous proof. A few approximations are applied without clearly explaining about the resulting approximation errors. This is not acceptable, especially when the authors claim they are developing a \"THEORY\".\n\n(3) The experiments only consider the MNIST and CIFAR10 datasets. These datasets are mainly used for evaluating feedforward-type convolutional neural networks. Even though the authors might like their experiments, for the sake of the main stream users of recurrent networks. They should at least include experiments in conventional sequential prediction problems, e.g., speech, time series, machine translations.\n\n(4) Compared with other state of the art methods, their experimental results on CIFAR10 is too weak. I cannot believe such weak results can be used to make meaningful justifications.\n\n\n\n\n\n\n\n\n"], "review_score_variance": 8.666666666666666, "summary": "Using ideas from mean-field theory and statistical mechanics, this paper derives a principled way to analyze signal propagation through gated recurrent networks.  This analysis then allows for the development of a novel initialization scheme capable of mitigating subsequent training instabilities.  In the end, while reviewers appreciated some of the analytical insights provided, two still voted for rejection while one chose accept after the rebuttal and discussion period.  And as AC for this paper, I did not find sufficient evidence to overturn the reviewer majority for two primary reasons.\n\nFirst, the paper claims to demonstrate the efficacy of the proposed initialization scheme on multiple sequence tasks, but the presented experiments do not really involve representative testing scenarios as pointed out by reviewers.  Given that this is not a purely theoretical paper, but rather one suggesting practically-relevant initializations for RNNs, it seems important to actually demonstrate this on sequence data people in the community actually care about.  In fact, even the reviewer who voted for acceptance conceded that the presented results were not too convincing (basically limited to toy situations involving Cifar10 and MNIST data).\n\nSecondly, all reviewers found parts of the paper difficult to digest, and while a future revision has been promised to provide clarity, no text was actually changed making updated evaluations problematic.  Note that the rebuttal mentions that the paper is written in a style that is common in the physics literature, and this appears to be a large part of the problem.  ICLR is an ML conference and in this respect, to the extent possible it is important to frame relevant papers in an accessible way such that a broader segment of this community can benefit from the key message.  At the very least, this will ensure that the reviewer pool is more equipped to properly appreciate the contribution.  My own view is that this work can be reframed in such a way that it could be successfully submitted to another ML conference in the future.", "paper_id": "iclr_2020_S1g490VKvB", "label": "train", "paper_acceptance": "reject"}
