{"source_documents": ["While numerous effective decentralized algorithms have been proposed with theoretical guarantees and empirical successes, the performance limits in decentralized optimization, especially the influence of network topology and its associated weight matrix on the optimal convergence rate, have not been fully understood. While Lu and Sa have recently provided an optimal rate for non-convex stochastic decentralized optimization using weight matrices associated with linear graphs, the optimal rate with general weight matrices remains unclear. \n\nThis paper revisits non-convex stochastic decentralized optimization and establishes an optimal convergence rate with general weight matrices. In addition, we also establish the first optimal rate when non-convex loss functions further satisfy the Polyak-Lojasiewicz (PL) condition. Following existing lines of analysis in literature cannot achieve these results. Instead, we leverage the Ring-Lattice graph to admit general weight matrices while maintaining the optimal relation between the graph diameter and weight matrix connectivity. Lastly, we develop a new decentralized algorithm to attain the above two optimal rates up to logarithm factors. ", " \\\nDear Reviewer o2Rv, \n\n\\\nThanks very much for all the valuable comments, helpful discussions, and useful suggestions during the rebuttal, with which our paper has been significantly improved. We really appreciate your time and efforts! \n\n\\\nBest,\\\nAuthors", " Thanks to the authors for the new version of the paper!\n\nI have no more questions left. \n\nThis is a good paper with one interesting result and minor additional results. I don't consider it a bad thing, to me a conference paper is one idea around which the paper is based, the other results should complement it.\n\nAt this point I would like to discuss with fellow reviewers how they think the new graph idea is interesting enough to be accepted. \nI give 4->5 (can change it in discussion with fellow reviewers) and am ready to move on to a discussion with fellow reviewers.", " \\\nDear Reviewer,\n\n\\\nThank you very much for the very helpful discussion with us. Your comments have significantly improved the quality of our paper. Does our revision and response resolve your concerns? We are happy to make other revisions if you request.\n\n\\\nBest,\\\nAuthors", " \\\nWe thank the reviewer again for the valuable discussion. Your comments made great sense to us. **We have revised the paper accordingly and uploaded it to the system**. All important revisions are highlighted in blue. \n\n\\\nBelow are the response to your comments.\n\n\\\n**1. Nearly-optimal**\n\n\\\nThe two arguments by the reviewer are solid. We have changed the word ''optimal'' to ''nearly-optimal'' in the paper. In addition, we add a new Remark 6 in the paper to clarify this limitation: \n\n>  The rate (10) matches with the lower bound (8) up to logarithm factors. Furthermore, we remark that the gradient similarity assumption  is not required to obtain the lower bound in Theorem 2. Due to these two restrictions, MG-DSGD is a nearly-optimal (not fully-optimal) algorithm. \n\n\\\nHowever, we would like to emphasize that, in terms of the reviewer's criterion, DeTAG is not a fully-optimal algorithm either. It involves logarithm terms in the upper bound, and also uses an additional gradient similarity assumption at $x\\_0=0$ (see eqn. (6) in its latest arxiv version), though weaker than ours, to establish its upper bound. To our knowledge, eqn. (6) is not justified and thus not involved (in terms of the pre-specified parameter $\\zeta\\_0$) in its lower bound construction.\n\n\\\n**2. Useful literature**\n\n\\\nWe thank the reviewer for providing these useful literature. After checking these literature, we agree that our paper shares the same gist as in [R1, R2]: gradient accumulation and multiple gossip. We have acknowledged that in various places in the paper. For example:\n\n> We proved that the above two optimal complexities can be nearly-attained ... by simply integrating multiple gossip communication [38,R1] and gradient accumulation [39, 55, R1]. (Lines 83 - 85)\n\n> Inspired by the algorithm development in [R1, 39], we add two components to DSGD: gradient accumulation and multiple gossip. (Lines 215)\n\n>  This paper finds in MG-DSGD that the multiple gossip technique can significantly reduce the influence of data heterogeneity .... Similar observations also appeared in [R1] albeit in the strongly-convex scenario. (Lines 222-224)\n\n> Our analysis techniques relate to the classic SGD analysis but with inaccurate oracles in the non-convex case [R3]. (Line 233)\n\n\\\nWhile our paper shares the same gist as [R1], the algorithm development as well as analysis is still different. For example, [R1] utilizes an **increasingly large mini-batch** of data per iteration in its algorithm construction. In Theorem 3.1 in [R1] (arxiv version), the batch-size $r = O(1/\\epsilon)$ where $\\epsilon$ is the desired accuracy. When $\\epsilon$ is small, the batch-size is very large. This implementation can be impractical due to massive memory cost. In contrast, MG-DSGD can utilize constant (independent of iteration or desired accuracy) batch-size per iteration to achieve any desired accuracy $\\epsilon$. On the other hand, [R1] establishes theories for strongly-convex scenario only.\n\n\\\n**3. Multiple gossip**\n\n\\\nWe agree that multistep gossip protocol works like a centralized protocol with inexactness. Since we use a fixed round of gossips per iteration, the MG-DSGD is just an approximate of the centralized SGD, and it will not converge to the centralized SGD. For this reason, there is a difference on the heterogeneity assumption between MG-DSGD and CSGD. \n\n\\\nThe data heterogeneity can be regarded as a quantity to control the inexactness. When data heterogeneity $b^2$ is large (i.e., each local function is very different from each other), we have to use more gossip steps to make MG-DSDG perform similarly to centralized SGD. Theoretically speaking, the number of gossip steps can only be determined when $b^2$ is given, see Eq. (72) in Appendix.  We conjecture this assumption can be removed (or alleviated) by utilizing an increasing number of gossips (as well as mini-batch size) per iteration (so that it converges to centralized SGD). \n\n\\\n**4. Constants $L$ and $\\mu$**\n\n\\\nWe have clarified constants $L$ and $\\mu$ in Tables 1 and  2 ([R1] is also added as a baseline), and Theorems 2-5. In the non-convex scenario, MG-DSGD can match with the lower bound even in terms of $L$. In the PL scenario, MG-DSGD cannot match with the lower bound in $L$ and $\\mu$ due to lacking effective acceleration techniques. We added Remark 7 to acknowledge it. Another possible reason is the established lower bound in PL condition is not tight in terms of $L$ and $\\mu$.\n\n\\\n**5. Summary**\n\n\\\nWe thank the reviewer for the very useful comments and suggestions. We are happy to make other changes if the reviewer requests. \n\n\\\n**6. References**\n\n\\\n[R1] Rogozin et al. An Accelerated Method For Decentralized Distributed Stochastic Optimization Over Time-Varying Graphs\n\n[R2] Rogozin et al. TOWARDS ACCELERATED RATES FOR DISTRIBUTED OPTIMIZATION OVER TIME-VARYING NETWORKS\n\n[R3] Dvurechensky et al. Gradient Method With Inexact Oracle for Composite Non-Convex Optimization", " Thanks very much! Looks interesting!", " Thanks to the authors for the response!\n\n1) The new graph is certainly an interesting contribution. The authors confirmed it again.\n\n2) I understand all the authors' arguments about the optimal algorithm, but I still think this contribution is minor and obvious.\n\nÐ°) I don't think the authors' algorithms are fully optimal for two reasons. \n\nThe upper bounds are obtained for a different class of problems! In the lower estimates, the homogeneity (see line 239) of the data is not assumed. **This is important to emphasize in the work.** (The authors can do it right now and upload the revision).\n\nThere is an additional logarithmic factor in the upper bounds. At first glance this does not matter, but for several years there was a battle in top conferences over optimal decentralized algorithms in the convex case. And just the essence of this battle was an extra logarithmic factor.\n\nb) The technique is not new, I found a work that does the same things in the convex case. Moreover, I found SGD analysis with inaccuracy in the nonconvex case. This is very easy to combine.\n\nRogozin et al. An Accelerated Method For Decentralized Distributed Stochastic Optimization Over Time-Varying Graphs\n\nRogozin et al. TOWARDS ACCELERATED RATES FOR DISTRIBUTED OPTIMIZATION OVER TIME-VARYING NETWORKS\n\nDvurechensky et al. Gradient Method With Inexact Oracle for Composite Non-Convex Optimization\n\nc) Multistep gossip protocol works like a centralized protocol with inexactness. There is no function heterogeneity in the estimates for centralized SGD. Therefore, the heterogeneity factor does not appear in the paper under review either. For me the conclusion about *reducing the influence of data heterogeneity* was clear and obvious. It also looks strange given that homogeneity is assumed (line 239).\n\n3) **It is important to reflect $L$ and $\\mu$ in the Table and Theorems of the main part!** (The authors can do it right now and upload the revision). Right now it looks like cheating.\n\nAt this point, I don't want to change the score until the authors correct the places that I think are important.", " Thank the authors for the clarification! I recommend to explicitly claim you are using the same setting, either in your final conference paper or in your arxiv version.\n\nI have changed the score to 7.", " \\\nThanks very much for the valuable suggestion. We will clarify the reason to use the worst weight matrix in the very beginning of the paper to avoid confusion.\n\n\\\nAs to the reviewer's comments on [33], we believe the setting in [33] is the same as ours. In sec. 4.2 of [33] (the latest arxiv version), the following metric is stated:\n\n\\\n$\\inf\\_{A\\in{\\mathcal{A}\\_{B\\\\,, \\\\,W}}}\\sup\\_{f\\in \\mathcal{F}_{\\Delta,\\\\,L}}\\sup\\_{O\\in \\mathcal{O}\\_{\\sigma^2}}\\sup\\_{G\\in \\mathcal{G}\\_{n,\\\\,D}}\\text{complexity}(A, f, O, G)$\n\n\\\nwhere we use \"complexity\" to denote the technical measure in sec. 3.4, [33], which is equivalent to convergence rate. It is worth noting that the class $\\mathcal{A}\\_{B\\\\,, \\\\,W}$ contains all algorithms using a given weight matrix $W$ and mini-batch $B$. For an algorithm $A \\in \\mathcal{A}\\_{B\\\\,, \\\\,W}$, there is no flexibility in the choice of $W$ and $B$. In other words, $\\inf\\_{A\\in{\\mathcal{A}\\_{B\\\\,, \\\\,W}}}$ is not equivalent to $\\inf\\_{A \\in \\mathcal{A}\\_{B\\\\,, \\\\,W}}\\inf\\_{W \\in \\mathcal{W}\\_n}$ in [33].  In fact, the dependence of matrix class $\\mathcal{W}$ is missing in the above metric. After carefully checking the proof details, we believe a correct interpretation of the lower bound in [33] should be \n\n\\\n$\\inf\\_{A\\in{\\mathcal{A}\\_{B\\\\,, \\\\,W}}}\\\\;{\\sup\\_{W\\in\\mathcal{W}\\_n}}\\sup\\_{f\\in \\mathcal{F}_{\\Delta,\\\\,L}}\\sup\\_{O\\in \\mathcal{O}\\_{\\sigma^2}}\\sup\\_{G\\in \\mathcal{G}\\_{n,\\\\,D}}\\text{complexity}(A, f, O, G)$\n\n\\\nThere are two evidences. First, Corollary 1 in [33] is stated as follows: \n\n\n> \"For every $\\Delta>0$, $L>0$, $n\\in\\\\{2,\\,3,\\,4,\\dots\\\\}$, $\\sigma>0$, and $B\\in\\mathbb{N}$, there exists ${\\text{a loss function\n}f\\in\\mathcal{F}\\_{\\Delta,L}}$, ${\\text{a set of underlying oracles }O\\in\\mathcal{O}\\_{\\sigma^2}}$, ${\\text{a gossip matrix }W\\in\\mathcal{W}\\_n\\text{ with second largest eigenvalue being }\\lambda = \\cos(\\pi/n)}$, and ${\\text{a graph }G\\in\\mathcal{G}\\_{n,\\,D}}$ such that ${\\text{no matter what}A\\in\\mathcal{A}\\_{B\\\\,, \\\\,W}}$  is used, $T(A, f, O, G)$ will always be lower bounded by $\\dots$.\n\nIn this statement, the four classes $\\mathcal{F}\\_{\\Delta,L}$, $\\mathcal{O}\\_{\\sigma^2}$, $\\mathcal{W}\\_n$, $\\mathcal{G}\\_{n,\\,D}$ are stated similarly, which indicates the same role (supremum) they play in the result. Otherwise, the weight matrix $W$ will be stated oppositely to indicate the infimum role it plays. \n\n\n\\\nSecond, if the lower bound in [33] is established for the optimal weight matrix $W$, the argument in [33] that \"In Section 6, we propose DeTAG, a practical algorithm that achieves the lower bound with only a logarithm gap ...\" (see the contribution summary in Sec. 1) is not valid. It is because the DeTAG algorithm can use an arbitrary weight matrix (with certain second largest eigenvalue) to achieve that lower bound, not necessarily the optimal one. \nOnly when the lower bound in [33] is established for the worst weight matrix, can the claim that \"DeTAG achieves the lower bound with arbitrary $W$\" makes sense.\n\n\\\nIn other words, if the lower bound is interpreted as the reviewer previously suggested, there should be an explicit procedure of using/finding the optimal matrix in a so-called \"optimal\" algorithm. However, there is no such procedure in DeTAG.\n\n\\\nWe hope these explanation can clarify the reviewer's confusion on the setting in [33]. We are happy to address any further comments or questions.", " I would like to thank the authors for the replies.\n\nThe authors claim that \"[33] constructs the worst network topology (and hence the worst weight matrix) over which an algorithm can achieve its fastest convergence.\" However, in [33], the authors consider \\inf_{A \\in A_{B,W}} where W is the weight matrix and \\sup_{G \\in G_{n,D}} where G_{n,D} is the topology class. Then the bound is on the worst topology in the class but the best possible W. Please correct me if I misunderstand anything. \n\nThe authors summarize that the scope of this paper is \"if we are considering optimality over the entire class of loss functions, gradient oracles, and weight matrices, it is common to construct the worst (or hardest) loss functions, gradient oracles, and weight matrices over which an algorithm can achieve its fastest convergence.\" This is very good and should be emphasized from the very beginning. The current paper gives me an impression that the contribution lies in extending \\beta from one value in [33] to a range. However, as mentioned above, the settings of this paper and [33] are slightly different.\n\nI am considering increasing the score to 7.", " \\\nWe thank the reviewer for bringing up this interesting discussion on time-varying topologies. Our thoughts can be briefly summarized as follows. \n\n- Optimal convergence rate for the family of time-varying weight matrices is worse than that for the family of static weight matrices.\n\n- Some special time-varying weight matrices (not the entire time-varying family) can endow decentralized algorithms with better convergence rate than static weight matrices.\n\n\\\nBelow are the detailed discussions.\n\n\\\n**1. Optimal rate for the entire family of time-varying weight matrices**\n\n\\\nTime-varying weight matrices are typically defined as matrices that can vary with time. Static weight matrices are generally regarded as a **subset** of time-varying weight matrices. Recall the optimal convergence rate for static weight matrices is defined as (see Eq. 6) $\\inf\\_{A \\in \\mathcal{A}} \\sup\\_{W \\in \\mathcal{W}\\_{\\mathrm{static}}} \\mathbb{E}\\Vert \\nabla f(A, W)\\Vert^2$ (we omit the function and gradient oracle classes for simplicity). Similarly, the optimal convergence rate for time-varying weight matrices is $\\inf\\_{A \\in \\mathcal{A}} \\sup\\_{W \\in \\mathcal{W}\\_{\\mathrm{dynamic}}} \\mathbb{E}\\Vert \\nabla f(A, W)\\Vert^2$. Since $\\mathcal{W}\\_{\\mathrm{static}} \\subseteq  \\mathcal{W}\\_{\\mathrm{dynamic}}$,  we can easily derive that \n\n\\\n$\\inf\\_{A \\in \\mathcal{A}} \\sup\\_{W \\in \\mathcal{W}\\_{\\mathrm{dynamic}}} \\mathbb{E}\\Vert \\nabla f(A, W)\\Vert^2 \\ge \\inf\\_{A \\in \\mathcal{A}} \\sup\\_{W \\in \\mathcal{W}\\_{\\mathrm{static}}} \\mathbb{E}\\Vert \\nabla f(A, W)\\Vert^2$\n\n\\\nSince a smaller rate is faster, we thus conclude that the optimal convergence rate for time-varying weight matrices is **worse** than that for static time-varying weight matrices. \n\n\\\nThe above conclusion can be illustrated by results in existing literature. We take the deterministic and strongly-convex scenario as an example. It is proved in [44] that the optimal convergence rate for static weight matrix is $\\Omega(\\exp(-\\sqrt{\\mu/L}\\sqrt{1-\\beta} T)$ while the optimal rate for time-varying weight matrix is given by [22] as $\\Omega(\\exp(-\\sqrt{\\mu/L}(1-\\beta) T)$ where $\\beta \\in (0,1)$ is the second largest eigenvalue of the weight matrix. Apparently, the optimal rate for time-varying weight matrix is worse than that for static weight matrix.    \n\n\\\n**2. Some special time-varying weight matrix can admit better convergence rate**\n\n\\\nIf we are not considering the entire family of the time-varying weight matrix, some single special weight matrices are identified in literature to endow decentralized algorithms with shorter transient iterations and hence faster convergence rate. In reference [59], the one-peer exponential graph is proposed to boost the performance of DSGD. The one-peer exponential graph is a time-varying weight matrix in which each node cycles through all its neighbors, communicating, only, to a single neighbor per iteration, see Figure 2 therein. This time-varying weight matrix is communication efficient (because each node only communicates to one neighbor per iteration), and it endows DSGD with rate ${O}(1/\\sqrt{nT} + n\\ln(n)/T)$. In contrast, the corresponding static weight matrix, i.e., the ring (in which each node also  communicates to one neighbor per iteration), has a much slower rate at ${O}(1/\\sqrt{nT} + n^3/T)$.  \n\n\\\n**3. Future work**\n\n\\\nThe results on optimal rates over time-varying matrices are still very limited in literature. For example, existing results mainly focus on deterministic scenario. Inspired by the reviewer's questions, we will study the optimal convergence rate in the stochastic setting with time-varying networks in the future.\n\n\\\n**4. References**\n\n\\\n[22] Dmitry Kovalev, et.al.,  Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks, NeurIPS 2021.\n\n[44] Kevin Scaman, et. al. Optimal algorithms for smooth and strongly convex distributed optimization in networks. ICML 2017\n\n[59] Bicheng Ying et.al. Exponential graph is provably efficient for decentralized deep training, NeurIPS 2021.\n\n\\\nWe are looking forward to further discussions from the reviewer, and more than happy to clarify any further comments or questions. ", " \\\nWe thank the reviewer for the valuable comments. We have attempted to address them as best as we can. We are glad to clarify any further comments or questions from the reviewer.\n\n\\\n**1. Main contributions**\n\nWe agree with the reviewer that some contributions are important while others may be minor. We would like to clarify on the main contributions of this paper.\n\n\\\n*[1.1. Ring-lattice graph]*. We thank the reviewer for the positive comments on the proposed ring-lattice graph. We believe ring-lattice graph makes an important contribution to a critical problem. Without the ring-lattice graph, the lower bound in existing literature only holds for a restrictive scenario in which $\\beta = \\cos(\\pi/n)$. \n\n\\\n*[1.2. MG-DSGD]*. We agree that the construction of MG-DSGD is not novel but a direct extension from DSGD. But we believe the insights and theoretical convergence rate brought by MG-DSGD are novel to decentralized optimization community. \n\n- As the reviewer said, MG-DSGD is very simple. It is such an obvious and straight-forward extension from DSGD and few researchers really pay attention to it. However, this paper finds that **it is the simple MG-DSGD that can achieve the optimal convergence rate without any advanced techniques** such as gradient tracking utilized in DeTAG [33]. \n\n- On the theory side, MG-DSGD achieves the same convergence rate as DeTAG but with a much simpler convergence analysis (much of the analysis can be adapted from the vanilla DSGD). On the implementation side, MG-DSGD gets rid of the gradient tracking step and hence can save half of the communication overhead and memory storage. **With optimal convergence rate, simpler analysis, faster communications, and cheaper memory costs**, we hope this paper can provide evidence that the DSGD family comes back with more competitive performances than recently-proposed more advanced algorithms such as D2, Exact-Diffusion, DSGT, and DeTAG. \n\n\n- While the construction of MG-DSGD is straight-forward, we believe **it is not obvious to feel the insight why DSGD has the potential to achieve the optimal convergence rate**; otherwise previous works such as [33] may not build optimal algorithms upon the complicated gradient tracking approach. It is long believed that, being sensitive to data heterogeneity, DSGD is inferior to data-heterogeneity-corrected algorithms such as D2, Exact-Diffusion, DSGT. However, this paper finds out that, **multiple-gossip can significantly reduce the influence of data heterogeneity**, and hence endows DSGD with the potential to achieve the optimal convergence rate. We believe it is another interesting and novel contribution. The intuition why multiple gossips can reduce data heterogeneity is discussed below. \n\n\\\nWe hope the reviewer may find the above two contributions (1.1 and 1.2) are valuable and non-trivial to the community.\n\n\n\\\n**2. Other minor contributions**\n\n\\\nThe other contributions claimed in the paper are on the lower bounds. These lower bounds are **new** because they are for stochastic non-convex setting and are established for a broader class of weight matrix with $\\beta \\in [0, \\cos(\\pi/n)]$. Moreover, the lower bound under PL conditions does not appear in any existing literature. However, we agree with the reviewer that these bounds are mainly established upon existing techniques in literature.  The main difference is the utilization of the results from Ring-lattice. Existence of these bounds can make the paper more complete, smooth and self-contained. If the reviewer has a severe concern on that, we will rephrase Theorems 2 and 3 as propositions and shorten their proofs to necessary length.\n\n \n\\\n**3. Intuition why multiple gossips can reduce data heterogeneity**\n\n\\\nThe intuition is based on a simple but easy-to-ignore fact: **the data heterogeneity term in the convergence rate of DSGD is associated with the second largest eigenvalue of the weight matrix**. More specifically, DSGD in the non-convex and smooth setting converges at rate $O(\\frac{\\sigma}{\\sqrt{nK}} + \\frac{\\beta^2 b^2}{(1-\\beta)^2 K \\sigma^2})$ (where $b^2$ is the data heterogeneity and $\\beta$ is the second largest eigenvalue. We omit irrelevant terms for clarify). Previous works typically ignore the influence of $\\beta$ in the numerator of the second term (see, e.g., Theorem 1 in [21]) since $\\beta$ is close to $1$ in general. When proper multiple gossips are used, the resulting eigenvalue $\\beta^2$ can be sufficiently small which corrects the data heterogeneity term. Please refer to Part II for more details. ", " \n\\\n**1. Lower bound.** \n\n\\\nThe proof of Thm. 2 is not much different from [Lu and De Sa, 38] except for the ring-lattice part. The existence of the complete proof is to make the paper more self-contained. We will rephrase Thm. 2 into a proposition and shorten the proof into necessary lengths in the revision.  \n\n\\\n**2. Insights on why MG-DSGD can handle data heterogeneity.** \n\n\\\nIt is an interesting and novel contribution to establish that the simple DSGD algorithm, with the help of multiple gossip and gradient accumulation, can significantly reduce the influence of data heterogeneity and achieve the optimal convergence rate. The main idea can be simplified as follows. We omit the computation details and irrelevant terms for clarity. \n\n- In Lemma 10 of the Appendix, we show that DSGD in the non-convex and smooth setting converges at rate $O(\\frac{\\sigma}{\\sqrt{nK}} + \\frac{\\beta^2 b^2}{(1-\\beta)^2 K \\sigma^2})$ (where we omit irrelevant terms for simplicity). It is observed that **data heterogeneity $b^2$ is associated with $\\beta^2$**. The influence of $\\beta$ on the numerator of the second term is often ignored in previous works since $\\beta$ is close to $1$ in general.  \n\n- Next, we set the rounds of multiple gossip relatively large so that the resulting $\\tilde{\\beta}^2$ can be sufficiently small. For example, we set the gossip round $R = \\ln(\\frac{b^2}{\\sigma^2})/\\sqrt{1-\\beta} = \\tilde{O}(1/\\sqrt{1-\\beta})$ (see Eq. 72) and hence achieve $\\tilde{\\beta}^2 = (1-\\sqrt{1-\\beta})^{2R} \\le \\exp(-2\\sqrt{1-\\beta}R) \\le \\sigma^2/b^2$ (see Eq. 73). This will lead to $\\tilde{\\beta}^2 b^2/\\sigma^2 = O(1)$ which significantly reduces the influence of data heterogeneity. \n\n- It is worth noting that MG-DSGD does not completely remove the influence of data heterogeneity. Since $R \\propto \\ln(b)$, the data heterogeneity only affects MG-DSGD as a small logarithm term and is hidden in the $\\tilde{O}(\\cdot)$ notation in Thms. 4 and 5.  \n\n\\\nThe above arguments are simplified to illustrate the main insight. The precise and more complicated proofs are in Appendix D.\n\n\n\\\n**3. Key difference between MG-DSGD and DSGD.**  \n\n\\\nThe proof of MG-DSGD is adapted from DSGD. However, MG-DSGD needs additional three steps to achieve the optimal convergence rate:\n- **Step 1**. Adjust the bounds of the vanilla DSGD (if exists) to a desired formulation, in which the influence of $\\beta$ on the data heterogeneity must be shown explicitly. (see Lemma 10 and 13 in Appendix).\n- **Step 2**. Choose a proper multiple-gossip round $R$ (cannot be too large or too small, very delicate) so that the influence of data heterogeneity can be significantly reduced. (see Eqs. 72-74, and Eqs. 101-103 in Appendix).\n- **Step 3**. With the help of multiple-gossip and gradient accumulation, we optimize the hyper-parameters inside the bound so that MG-DSGD achieve the optimal convergence rate. (see Thms. 4 and 5 in Appendix).\n\n\\\nIn fact, we **did not re-prove any exiting arguments** from vanilla DSGD. Useful lemmas from other literature are directly cited (see Lemmas 8, 9, 11 and 12. We made slight modifications in Lemma 12). Note that a proper convergence rate of vanilla DSGD under PL condition does not appear in literature to our knowledge (especially the one in which $\\beta$ is associated with data heterogeneity). We spent a few lines on its convergence rate in Lemma 13. \n\n\\\n**4. Explicit dependence on $L$ and $b$.**  \n\n\\\nThe dependence on $L$ (or $\\mu$) is explicitly shown in the bound Eqs. (75) and (104) in Appendix. Take the non-convex scenario as an example. MG-DSGD converges at rate $O( \\frac{\\sigma\\sqrt{\\Delta L}}{\\sqrt{nT}} + \\frac{L \\Delta  \\ln(b)}{T\\sqrt{1-\\beta}})$. In comparison, DeTAG converges at rate $O(\\frac{\\sigma\\sqrt{\\Delta L}}{\\sqrt{nT}} + \\frac{L \\Delta \\ln(b_0)}{T\\sqrt{1-\\beta}}) )$ where $b_0$ is the data heterogeneity at the initial iterate (which is smaller than $b$, see the definition in Lu and De Sa [38]). If we ignore the logarithm term, MG-DSGD converges as fast as DeTAG, and they achieve the optimal convergence rate.  We will make $L$ and $b$ explicit in the main paper during the revision.\n\n\\\nNote that DeTAG does not have a bound for the PL scenario. We find MG-DSGD maintains the same dependence on L as vanilla DSGD, but is much better in dependence on network topology $\\beta$ and data heterogeneity $b$. \n\n\\\n**5. Merit function.**\n\n\\\nFor the PL condition scenario, we do utilize the merit function $\\mathbb{E}[f(\\bar{x}^k) - f^\\star] + L \\mathbb{E}\\|x^k - \\bar{x}^k\\|^2$ to establish the bound (see Eq. (83)). However, we do not have a similar bound for the general non-convex scenario. As the reviewer said, the consensus error decays faster and it should not be too difficult to adjust the current analysis to the strong metric function. We will do the change in the revision. However, the current merit function is also standard in literature. Well known references DeTAG [38] and [25] all use the same merit function as us. \n  ", " \\\nMany thanks for the valuable comments! We have attempted to clarify all the questions as best as we can.\n\n\\\n**1. Main contributions**\n\n\\\nWe agree with the reviewer that some contributions are important while others may be minor. We would like to clarify on the main contributions of this paper. \n\n\\\n*[1.1. Ring-lattice graph]*. We thank the reviewer for his positive comments on the proposed ring-lattice graph. We believe ring-lattice graph makes a non-trivial contribution to an important and critical problem. \n\n- In distributed stochastic optimization (including decentralized scenario), the number of computing nodes $n$ is fixed. Only when $n$ is given can a distributed stochastic algorithm show the linear speedup rate $O(\\sigma/\\sqrt{nT})$. However, no mature techniques are available in existing literature to derive the influence of network topology on the optimal convergence rate in decentralized stochastic optimization in which the network size $n$ is fixed. It is a critical problem needs to be addressed. \n\n- The proposed ring-lattice graph is an effective tool to help address the problem. Before us, the best known result is for weight matrix with $\\beta = \\cos(\\pi/n)$. Our ring-lattice works for $\\beta \\in [0, \\cos(\\pi/n)]$, and it is **very close** to the ideal case that $\\beta \\in [0, 1]$. Note that $\\cos(\\pi/n) = 1 - \\Theta(\\frac{1}{n^2})$. When $n$ is large, the interval $[0, \\cos(\\pi/n)]$ approaches to $[0,1]$ quickly. Moreover, most weight matrices of interest have already been covered by the interval $[0, \\cos(\\pi/n)]$, please check Table 6 in Appendix.\n\n\\\n*[1.2. MG-DSGD]*. While the reviewer thinks MG-DSGD does not cause interest, we would like to share some different thoughts. \n\n- As the reviewer said, MG-DSGD is very simple. It is such an obvious and straight-forward extension from DSGD and few researchers really pay attention to it. However, this paper finds that it is the simple MG-DSGD that can **achieve the optimal convergence rate without any advanced techniques** such as gradient tracking utilized in DeTAG [33]. On the theory side, MG-DSGD achieves the same convergence rate as DeTAG but with a much simpler convergence analysis (much of the analysis can be adapted from the vanilla DSGD). On the implementation side, MG-DSGD gets rid of the gradient tracking step and hence can save half of the communication overhead and memory storage. **With optimal convergence rate, simpler analysis, faster communications, and cheaper memory costs**, we hope this paper can provide evidence that the DSGD family comes back with more competitive performances than recently-proposed  advanced algorithms such as D2, Exact-Diffusion, DSGT, and DeTAG. \n\n- While the construction of MG-DSGD is straight-forward, we believe **it is not obvious to feel the insight why DSGD has the potential to achieve the optimal convergence rate**; otherwise previous works such as [33] may not build optimal algorithms upon the complicated gradient tracking approach. It is long believed that, being sensitive to data heterogeneity, DSGD is inferior to data-heterogeneity-corrected algorithms such as D2, Exact-Diffusion, DSGT. However, this paper finds out that, **multiple-gossip can significantly reduces the influence of data heterogeneity**, and hence endows DSGD with the potential to achieve the optimal convergence rate. We believe it is another interesting and novel contribution, and the other two reviewers a2U2 and Xrfd are all curious about it. It is because the data heterogeneity term in DSGD is associated with the second largest eigenvalue of the weight matrix. When proper multiple gossips are used, the resulting eigenvalue can be sufficiently small which corrects the data heterogeneity term. Please check the response (Reviewer a2U2, Part II.4) for more details. \n\n\\\nWe hope the reviewer may find the above two contributions are valuable and non-trivial to the community. \n\n\n\\\n**2. Other minor contributions**\n\n\\\nThe other contributions claimed in the paper are on the lower bounds. These lower bounds are **new** because they are for stochastic non-convex setting and are established for a broader class of weight matrix with $\\beta \\in [0, \\cos(\\pi/n)]$. Moreover, the lower bound under PL conditions does not appear in any existing literature. However, we agree with the reviewer that these bounds are mainly established upon existing techniques in literature.  The main difference is the utilization of the results from Ring-lattice. Existence of these bounds can make the paper more complete, smooth and self-contained. If the reviewer has a severe concern on that, we will rephrase Theorems 2 and 3 as propositions and shorten their proofs to necessary length.\n\n \\\n**3. Constants $L$ and $\\mu$**\n\n\\\nAs the reviewer requested, we will explicitly list the constants $L$ and $\\mu$ in bounds shown in the main paper, not just in Appendix. We agree that the current bound cannot achieve $\\sqrt{L/\\mu}$ due to the lacking of accelerated tricks.", " \\\nWe thank the reviewer for sharing his precious experience. Our thoughts on this point are as follows\n\n\\\n**Gossip algorithms can save communications in large-scale GPU clusters both theoretically and practically**. Its theoretical communication advantage over Ring-Allreduce is clarified in Table 1 in [R1]. Its real single-round communication superiority to Ring-Allreduce in a 256 GPU cluster is listed in Table 17 in [R2]. A deep learning system built upon gossip algorithms can have a much higher throughput than that upon Ring-Allreduce, see Figure 12 in [R1] and the performance test in Github repos [R3] and [R4]. These evidence show that Gossip algorithms do have real values in deep learning. \n\n\\\n[R1] B. Ying, et. al., \"BlueFog: Make Decentralized Algorithms Practical for Optimization and Deep Learning\", arXiv: 2111.04287 \\\n[R2] Y. Chen, et. al. \"Accelerating Gossip SGD with Periodic Global Averaging\", ICML 2021 (arXiv: 2105.09080) \\\n[R3] BuGua. Github repo at https://github.com/BaguaSys/bagua \\\n[R4] BlueFog. Github repo at https://github.com/Bluefog-Lib/bluefog.\n\n\\\n**Gossip algorithms have triggered attentions in industry**.  With the justified value mentioned above, several big companies have conducted active research on gossip algorithms. For example, [R1] is conducted by researchers from Google and Alibaba, [R2] is by Alibaba, [R4] is by Kwai, and [R5] is by Meta. Several news [R6] from IBM also show that gossip algorithms can significantly accelerate deep training in large GPU clusters.  \n\n\\\n[R5] M. Assran, \"Stochastic gradient push for distributed deep learning\", ICML 2019. \\\n[R6] News: Deep learning training gets 10x performance improvement \n\n\\\n**However, we do agree with the reviewer that gossip algorithms progress slowly in deep learning applications.** Few deep learning users (except for those who conduct research on large-scale GPU clusters) use gossip algorithms in their experiments and products. Several fundamental reasons, in our opinion, are as follows.\n\n- *Gossip algorithms can save communication per round, but it may degrade the final test accuracy.*  We observe that massive deep learning users value the final test accuracy more than the training speed. Users are willing to wait for longer time to get a better accuracy. This phenomenon is more evident in academia where a top test accuracy is highly preferred in paper submissions. Moreover, when the scale of GPU cluster is small, the communication efficiency brought by Gossip is very minor. For these reasons, users with just a few GPUs have no motivations to use gossip training. \n\n- *Gossip algorithms are difficult to implement. There are no mature tools to integrate decentralized training into user's deep learning tasks in a painless, high-performance and stable manner.*  Gossip algorithms require peer-to-peer communication protocols between GPUs, and they also need to organize GPUs into various topologies such as ring, grid, or exponential graphs. These have brought significant challenges to the implementation. Fortunately, several research groups from the industry are building tools to support easier implementation for decentralized algorithms, see [R3] and [R4]. But they are not as mature as those tools for centralized training until now.\n\n- *There exist no unified gossip strategies that can extend all optimizers to decentralized versions.* As the reviewer said, ring-allreduce is easy to use. Whether we are using SGD, momentum SGD, ADAM, or other optimizers, implementing them with ring-allreduce is very straightforward and the convergence is the same as the single-node case. However, gossip strategies are not that easy to use. After one develops DSGD for SGD optimizer, it has to develop another specific decentralized algorithms for momentum SGD, or ADAM. Simply extending the gossip strategy in DSGD to mSGD or ADAM optimizer may result in significant performance degradation, see an example in [R7]. \n\n[R7] T. Lin, \"Quasi-global Momentum: Accelerating Decentralized Deep Learning on Heterogeneous Data\", ICML 2021.\n\n\\\n**Fairly speaking, there is a long way to go to push decentralized algorithms into popularity in industry.** But all the difficulty we summarized above that gossip algorithms are experiencing right now also **happens to other communication-saving approaches** such as compression, federated training approaches, and asynchronous algorithms. **They are not unique to gossips**. However, we humbly think this also brings chances for us researchers to make a difference in these fields. \n\n\\\nWe also agree with the reviewer that gossip algorithms have valuable applications in wireless sensor networks, or mobile networks. However, due to lacking experience in these areas, we cannot provide insightful comments on these applications. \n\n\\\nWe hope these discussions are useful to the reviewer, and we are looking forward to any further comments or questions if any. Thanks again for bringing up such an interesting discussion. ", " **Zero-respecting Policy.**  \n\n**1. Non-convex Part:** The lower bound is established with two constructed instances. In the argument with instance 1, zero-respecting policy is required by \"Lemma 2 of [33]\" (line 663. In Appendix the index appeared as [38] because we cited new papers in the later submitted appendix which caused index mismatch. It should be [33] by Lu and De Sa). For instance 2, zero-respecting policy is required by arguments in lines 679-682. We will clarify them in the revision. \n\n**2. Non-convex with PL Part:** The proof with instance 1 follows a hypothesis testing argument which gives an information-theoretic lower bound. The proof actually does not require zero-respecting policy. In other words, the term $\\Omega(\\frac{\\sigma^2}{\\mu nT})$ holds as a lower bound even for algorithms that do not obey zero-respecting policy. Therefore we did not mention zero-respecting policy there. For instance 2, zero-respecting policy guarantees the argument in lines 772-774. We will clarify them in the revision. \n\nWe thank the reviewer for checking the proof detail. We are glad to discuss more if needed.", " Many thanks for the valuable comments! We have attempted to clarify all the questions as best as we can.\n\n\\\nThe following discussion is to response your comments in Weakness 1, 2 and Question 1. \n\n\\\n**1. Optimal algorithms for a given class.** The reviewer might have some misunderstandings on the definition of the optimal algorithm for a given class. In this paper, we are trying to answer the following question.\n\\\n\\\n*Given a class of non-convex loss functions satisfying the L-smooth assumption (Eq. 2), a class of stochastic gradient oracles satisfying Eq. (4), and a class of network weight matrices with size $n\\times n$ and second largest eigenvalue $\\beta$ satisfying Eq.(5), what is the optimal algorithm and its convergence rate?*\n\n\\\nHow to characterize the optimality over a class of loss functions, gradient oracles, or weight matrices? This paper formulate it into a minimax problem listed in Eq. (6) or (7). Take the weight matrix as an example. To find a fastest algorithm over **the whole class** $W_{n,\\beta}$, i.e.,  all weight matrices with size $n\\times n$ and second largest eigenvalue $\\beta$, a standard way is to find an algorithm that achieves fastest convergence when the worst weight matrix belonging to $W_{n,\\beta}$ is given. This can be formally expressed as $\\inf_{A\\in \\mathcal{A}} \\sup_{W \\in \\mathcal{W}_{n,\\beta}}\\|\\nabla f(A, W)\\|$. \n\n\\\nThis minimax formulation follows the convention in existing literature. For example, to find the optimal convergence rate for a class of non-convex loss functions, the well-known reference [5] utilizes $\\inf_{A\\in \\mathcal{A}} \\sup_{f \\in \\mathcal{F}} T(A, f)$ (see Sec. 2.3 therein) to formulate the problem where $\\mathcal{F}$ is the class of the non-convex and smooth functions. \n\n\\\nWe agree that the worst weight matrix is not preferred in real specific implementation. However, the worst weight matrix is very useful to gauge how an algorithm performs over the examined class of weight matrices. In contrast, a good weight matrix cannot be used to validate the performance of the algorithm over the class of weight matrix. Even if some algorithm performs well with a specially good weight matrix, it may get degraded using another weight matrix belonging to the same class. \n\n\\\nIn summary, if we are considering optimality over the entire class of loss functions, gradient oracles, and weight matrices, it is common to construct the worst (or hardest) loss functions, gradient oracles, and weight matrices over which an algorithm can achieve its fastest convergence. \n\n\\\n**2. Optimal weight matrix for a given topology.** The reviewer asks an excellent question: *Given a network of $n$ nodes, what is the optimal weight matrix (and hence $\\beta$)?* This question is important but is not the focus of this paper. Reference [R1] is to solve this problem. Typically speaking, finding the optimal weight matrix is **decoupled from** the algorithm design. It can be formulated into an \n optimization problem in which weight matrix eigenvalue $\\beta$ is minimized given the network topology constraints. \n\n\\\n[R1] S. Boyd, P. Diaconis, L, Xiao, Fastest mixing Markov chain on a graph. 2004.\n\n\\\n**3. Results in [33].** To our knowledge, [33] is not ''finding an optimal algorithm with the best weight matrix given a network topology''. Similar to our setting, [33] is finding an optimal convergence complexity given a class of non-convex loss functions, gradient oracles, and networks with size $n$. To achieve it, [33] constructs the worst network topology (and hence the worst weight matrix) over which an algorithm can achieve its fastest convergence. This can be seen from their problem formulation $\\inf_{A \\in \\mathcal{A}} \\sup_{g \\in G_{n, \\Delta}}\\|\\nabla f(A,g)\\|$ in which $G_{n,\\Delta}$ is the class of networks with size $n$ and diameter $\\Delta$. However, the results in [33] only holds for weight matrices with $\\beta = \\cos(\\pi/n)$ which are mainly resulted from line graphs. \n\n\\\nIn fact, we are not aware of existing works that can find an *optimal* algorithm with the *best* weight matrix given a network topology. It is a co-design problem in which both the algorithm and the weight matrix are optimized. This co-design problem shall be formulated as $\\inf\\_{A\\in \\mathcal{A}\\_{W}} \\inf\\_{W \\in \\mathcal{W}\\_{n,\\beta}}\\|\\nabla f(A, W)\\|$ which does not appear in literature to our knowledge. We are only aware of work [R2] in which the optimal $W$ is found for a given **fixed** algorithm EXTRA and a class of networks. \n\n\\\n[R2] Y. Chow, W. Shi, T. Wu, and W. Yin, Expander Graph and Communication-Efficient Decentralized Optimization. 2016\n\n\\\nWe are looking forward to further discussions with the reviewer, and more than happy to clarify any further comments. \n", " \nThe following discussion is to response the reviewer's comments in Weakness 3, 4, 5 and Question 2.\n\n\\\n**1. DSGD.** It is known that the vanilla DSGD suffers from the data heterogeneity issue, i.e., the data heterogeneity will significantly slow down the algorithm's convergence, see the third line in Table 1. \n\n\\\n**2. DSGT.** The negative influence of data heterogeneity motivates us to develop advanced algorithms that can get rid of it in convergence rate. DSGT is among these algorithm. With the gradient tracking technique, DSGT has an improved convergence rate as shown in the fifth line in Table 1. The fundamental reason that DSGT can correct the data heterogeneity is to utilize the dynamic consensus averaging to track the globally averaged gradient. DSGT pays a cost to remove data heterogeneity: it incurs twice amount of the communication overheads as much as DSGD per iteration.  \n\n\\\n**3. DeTAG.** DeTAG is proposed in [33] to achieve the optimal convergence rate in decentralized stochastic optimization. DeTAG can be regarded as DSGT enhanced by multiple gossips per iteration. Built upon DSGT, DeTAG is also immune to data heterogeneity and is converging at optimal rate as shown in the sixth line in Table 1. However, similar to DSGT, **DeTAG \nalso incurs twice amount of the communication overheads as much as DSGD per iteration**. \n\n\\\n**4. MG-DSGD.** In this paper, we find that multiple gossip is a powerful tool to improve the performance of DSGD. Not only can it help improve the dependence on network topology, but also **it can significantly reduce the influence of data heterogeneity**. With this observation, MG-DSGD does not need the gradient tracking technique utilized in DeTAG any more, and hence **it saves significant communication overheads**. Meanwhile, it achieves the same convergence rate (up to logarithm terms) as DeTAG, see the last line in Table 1. Before this paper, it seems that multiple gossip is not well recognized to be effective to relieve the data heterogeneity issue. **It is somewhat surprising that the simple DSGD algorithm, with the help of multiple gossip and gradient accumulation, can easily achieve the optimal convergence rate**. No other advanced techniques such as gradient tracking, explicit bias-correction, or dual averaging are needed. \n\n\\\nThe main idea to utilize multiple gossips to solve the data heterogeneity issue is simplified as follows. We omit the computation details and irrelevant terms for clarity. \n\n- An important observation is that **a small second largest eigenvalue $\\beta$ can help relieve data heterogeneity in DSGD**. In Lemma 10 of the Appendix, we show that DSGD in the non-convex and smooth setting converges at rate $O(\\frac{\\sigma}{\\sqrt{nK}} + \\frac{\\beta^2 b^2}{(1-\\beta)^2 K \\sigma^2})$ (where we omit irrelevant terms for simplicity). It is observed that **data heterogeneity $b^2$ is associated with $\\beta^2$**. The influence of $\\beta$ on the numerator of the second term in the convergence rate is often ignored in literature since $\\beta$ is close to $1$ in general.  \n\n- Next, we set the rounds of multiple gossip relatively large so that the resulting $\\tilde{\\beta}^2$ can be sufficiently small. For example, we set the gossip round $R = \\ln(\\frac{b^2}{\\sigma^2})/\\sqrt{1-\\beta} = \\tilde{O}(1/\\sqrt{1-\\beta})$ (see Eq. 72) and hence achieve $\\tilde{\\beta}^2 = (1-\\sqrt{1-\\beta})^{2R} \\le \\exp(-2\\sqrt{1-\\beta}R) \\le \\sigma^2/b^2$ (see Eq. 73). This will lead to $\\tilde{\\beta}^2 b^2/\\sigma^2 = O(1)$ which significantly reduces the influence of data heterogeneity. \n\n- It is worth noting that MG-DSGD does not completely removes the influence of data heterogeneity. Since $R \\propto \\ln(b)$, the data heterogeneity only affects MG-DSGD as a logarithm term. In contrast, DeTAG and DSGT can completely remove data heterogeneity with the cost of expensive communication. \n\nThe above arguments are customized to illustrate the main insight. The precise and detailed proof shall be checked in Appendix D.\n\n\\\n**5. Typos.** We thank the reviewer for the careful check. We will correct them in the revision. \n\n\\\nWe hope the above explanation can help clarify the reviewer's confusion. We are looking forward to further discussions with the reviewer, and more than happy to clarify any further comments.", " This paper revisits non-convex stochastic decentralized optimization and extends existing convergence analysis with special weight matrices to establish an optimal convergence rate with general weight matrices. The algorithms proposed has a convergence rate that matches DeTAG's rate but avoids gradient tracking and saves half of the communication overheads per step. The paper studies decentralized optimization algorithm over general communication weight matrix, but the weight matrix has to be fixed over time, so it does not seem to apply to decentralized algorithms where the communication pattern is different in different steps.\n\nWhen the matrix is fixed, the paper proves the optimal convergence rate for nonconvex objectives (where the lower bound and upper bound match). Also an algorithm MG-DSGD is proposed to achieve that optimal convergence rate while being simpler and less communication costy than existing algorithms such as DeTAG. Is it possible for a time-varying communication pattern to improve the convergence? It will be nice to include the discussion if some conclusions can be drawn. N/A", " In this paper, the authors investigate the optimal convergence rate for smooth and nonconvex decentralized stochastic optimization. Specifically, given function class F_L, oracle class O_{\\sigma^2}, and weight matrix class W_{n,\\beta}, the authors establish a tight lower bound for any \\beta within (0,cos(\\pi/n)). An algorithm based on multiple-step gossip is also proposed.\n\nPost-rebuttal update: I have raised the score from 5 to 7.\n\n Strengths:\n1. A tight lower bound for any \\beta within (0,cos(\\pi/n)).\n2. An algorithm that matches the lower bound.\n\nWeaknesses:\n1. For the optimal rate of decentralized stochastic optimization algorithms, readers should be interested in the following question: âGiven a network topology, what are the best algorithm and its rate?â In [33], the optimal rate is in the sense of âgiven a line network of n nodes, finding an optimal algorithm with the best weight matrix (and hence \\beta).â It is limited to the line topology, but consistent to our intuition. In this paper, the optimal rate is in the sense of âgiven a network of n nodes, finding the worst topology and corresponding weight matrix whose connectivity measure is \\beta, and finding an optimal algorithm.â This is a little bit confusing because in most cases we do not prefer the worst weight matrix. Please clarify.\n2. Related to the above comment. From the very beginning the authors mention that âthis paper revisits non-convex stochastic decentralized optimization and establishes an optimal convergence rate with general weight matrices.â Weight matrix design should be a part of algorithm development. I cannot fully understand the necessity of finding the worst weight matrix.\n3. In the problem setup the authors talk about the zero-respecting policy, but do not mention it in the proof.\n4. âSurprisingly, we find in MG-DSGD that the multiple gossip technique can significantly reduce the influence of data heterogeneity, and the gradient tracking step can be saved to achieve the convergence optimality.â Why?\n5. Mistakes: The degree of a 10-node complete graph is 9, not 10. In Line 3 of Algorithm 2, z_i^{(r)} should be z_j^{(r)}.\n6. For these reasons, I recommend âborderline acceptâ and would like to see further clarifications from the authors.\n 1. For the optimal rate of decentralized stochastic optimization algorithms, readers should be interested in the following question: âGiven a network topology, what are the best algorithm and its rate?â In [33], the optimal rate is in the sense of âgiven a line network of n nodes, finding an optimal algorithm with the best weight matrix (and hence \\beta).â It is limited to the line topology, but consistent to our intuition. In this paper, the optimal rate is in the sense of âgiven a network of n nodes, finding the worst topology and corresponding weight matrix whose connectivity measure is \\beta, and finding an optimal algorithm.â This is a little bit confusing because in most cases we do not prefer the worst weight matrix. Please clarify.\n2. âSurprisingly, we find in MG-DSGD that the multiple gossip technique can significantly reduce the influence of data heterogeneity, and the gradient tracking step can be saved to achieve the convergence optimality.â Why?\n N/A.", " The paper considers decentralized stochastic non-convex optimization problems. The main innovation is the new structure of the connection graph, which can be used to revisiting the lower bounds. In a supplement, the authors apply this graph structure to obtain lower estimates in the non-convex case. Finally, the authors present an algorithm based on FastGossipAverage which achieves lower bounds.   **Strengths:**\n\n1) The new ring-based graph structure is interesting to me. Previous methods of deriving lower bounds consist in that we fix $\\beta$ (in the literature it is also $\\chi$), on the basis of this $\\beta$ a connection graph (typically a path) with some number of vertices $n$ is constructed. The new graph structure allows to fix not only $\\beta$ but also $n$. This can be important. \n\n2) The rest of the results, including lower bounds for non-convex problems (in the general case and in the PL case), the algorithm that achieves these lower bounds, and the experiments, complement the paper well.\n\n3) The article is quite well written and easy to follow. The literature review is satisfactorily done. \n\n**Weaknesses:**\n\n1) It is a pity that the new graph construction works only for $\\beta \\in [0; \\cos \\pi/n]$.\n\n2) Unfortunately, the rest of the results of the work, except for the construction of the graph are not particularly interesting. Most of them are obvious and represent a simple combination of existing works. Read more below.\n\n3) Lower bounds in the general non-convex case can be obtained by simply replacing the graph in the available results in the literature.\n\n4) Lower bounds in the PL case are actually made for the strongly convex case, and this also can be done by simply replacing the graph in the available results. I also do not like that in the main paper the estimates in the PL case does not show the dependence on the factor $L/\\mu$. It replaces by $C$. Most likely this is due to the fact that in the lower bounds $C = \\sqrt{L/\\mu}$, and in the upper estimates $C = L/\\mu$. This spoils the optimality of the algorithm, and perhaps the authors want to hide it.\n\n5) The algorithm, which is set as optimal, is simply an analysis of SGD with inexactness + gossip consensus. Such results are obvious and do not cause much interest.\n\n**Conclusion:**\n\nIn this paper the interesting thing is the construction of the new graph, with which one can get more accurate lower bounds. The rest of the facts (including experimental ones) complement the paper and make it more solid, but for me are minor in comparison with the new graph. I am hesitant to decide on acceptance and would like to discuss with fellow reviewers and AÐ¡ their impressions of the paper. I put a borderline reject, but I'm ready to easily change it after discussion. The question is about experiments. It is rather rhetorical and I am just interested in your opinion here. \n\nI sometimes have to work with the learning problems on decentralized architectures. Despite the fact that I have a quite good theoretical experience in gossip protocol, we never use it (neither with single step, nor with multi steps). It's easier to use tricky all-reduce procedures. For me gossip protocol is about simpler tasks and simpler computing devices (not powerful GPU), for example about signal processing and transmission. \n\nWhat do you think about it? No potential negative societal impact", " The paper study optimal convergence rates in  decentralized nonconvex (smooth) optimization and develops algorithms to achieve such lower complexity bounds up to log factor. More specifically the key contributions are:\n\n(i) Establishing optimal convergence rates for smooth, non convex stochastic optimization for  mesh networks compliant with gossip matrices whose connectivity measure is not $\\cos(\\pi/n)$, where $n$ is the number of agents. Example of such graphs are grids, hypercubes, toruses, etc. Previous literature considered lower complexity bound only for linear graphs. \nThe authors established lower complexity bounds for ring-lattice graphs, for connective values within $[0,cos(\\pi/n)]$; for large $n$ the interval spans [0,1].  A key enabler of such new results is a tight relationship between the connectivity of the graph and its diameter, a fact that was established before for linear graphs (meaning connectivity values equal to $\\cos(\\pi/n)$). \n\n(ii) By modifying properly the distributed SGD algorithm, the authors provide a solution method that achieve lower complexity bounds. Differently from the existing method, DeTAC, still achieving lower complexity bounds, the proposed algorithm does not require gradient tracking and hence save one communication (O(d)) per iteration. \n\n(iii) The authors extend the results above  to the case of nonconvex functions satisfying the PL condition. Strengths:\n The paper advances the state of the art on SDGD-like algorithms for smooth, nonconvex problems. The authors identified a gap in the literature (the lower complexity bound were established for a restricted class of gossip matrices and associated graphs) and provide a solution to it. The overall presentation is good and the paper is easy to read. The comparison with the state of the art is satisfactory (to my knowledge). \n\nWeaknesses: \nOn the technical side, it is not very clear which new technique has been developed in the proofs to derive some of the results. For instance, once the connection between the connectivity and the diameter of ring-lattice graphs is established, it seems that the proof of Th.2 follows the same path of that in [38]. Same comment apply to the convergence analysis of DSGD; except of a suitable choice of the learning rate, I see a fairly standard proof. Since the proposed MG-DSGD has the same structure of the vanilla DSGD (with a different gossip matrix and a gradient accumulation), same comment applies to its proof of convergence. I do not find the proof under PL particularly more difficult than under strong convexity, the functional relationship between the optimality gap and gradient steps is basically the same.\n\nI would not consider MG-DSGD a new algorithm: it is the DSGD with multiple consensus steps (accelerated) and batch gradients. Both features have been extensively used in the literature.  What is unclear is why the acceleration via multiple round of consensus copes with the data heterogeneity and allows one to get ride of the gradient tracking, which is notoriously known to be beneficial under data heterogeneity. \n\n  Is the proof of lower complexity bounds in Th. 2 significantly different from [38], once the connection between the connectivity and the diameter of ring-lattice graphs is established?\n\nThe convergence proof of DSGD has been already established in the literature , e.g. in [12, 25]. I think it would be useful if the authors can elaborate in the paper (and in their reply) on the key difference in their analysis, which lead to slightly different results. What was the key enabler for that?\n\nDo the author have some intuition why MG-DSGD can deal with data heterogeneity's efficient as gradient tracking methods? It would be good to provide some inside substantiated by some technical reasoning.  \n\nI would write the upper bounds making explicitly the dependence on L and b, to be consistent with the presentation of complexity bound in the literature. Is the dependence on these parameters of the same order of that in the literature?\n\nI would change the merit function using to measure stationarity: the current one does not capture consensus errors. I would include a consensus error term rather than considering only the gradient along the average. The average is representative of the local iterates only when the consensus error is sufficiently small. It is true however that the consensus error decays faster than the optimization one, but still I would consider a more comprehensive merit function to measure performance of the algorithm.  See my comments above under weaknesses."], "review_score_variance": 0.6875, "summary": "This paper presents some new results on near-optimum algorithms for distributed optimization, nearly matching lower bounds. Most of the reviewers are positive about the contributions of this work. However, one issue that came up is the assumption of bounded gradient dissimilarity, which is essentially a gap between upper and lower bounds. While I am recommending to accept this paper, I believe this gap should be more prominently discussed in the abstract and introduction. \n\n", "paper_id": "nips_2022_eHePKMLuNmy", "label": "train", "paper_acceptance": "Accept"}
{"source_documents": ["In this paper, we focus on effective learning over a collaborative research network involving multiple clients. Each client has its own sample population which may not be shared with other clients due to privacy concerns. The goal is to learn a model for each client, which behaves better than the one learned from its own data, through secure collaborations with other clients in the network. Due to the discrepancies of the sample distributions across different clients, it is not necessarily that collaborating with everyone will lead to the best local models. We propose a learning to collaborate framework, where each client can choose to collaborate with certain members in the network to achieve a ``collaboration equilibrium\", where smaller collaboration coalitions are formed within the network so that each client can obtain the model with the best utility. We propose the concept of benefit graph which describes how each client can benefit from collaborating with other clients and develop a Pareto optimization approach to obtain it. Finally the collaboration coalitions can be derived from it based on graph operations. Our framework provides a new way of setting up collaborations in a research network. Experiments on both synthetic and real world data sets are provided to demonstrate the effectiveness of our method.", " Thanks very much for your constructive comments on our work. We have tried our best to address the concerns. Is there any unclear point so that we should/could further clarify?", " Thanks very much for your constructive comments on our work. We have tried our best to address the concerns. Is there any unclear point so that we should/could further clarify?", " Thanks very much for your constructive comments on our work. We have tried our best to address the concerns. Is there any unclear point so that we should/could further clarify?", " * **Question: \"Although the definition of optimal collaborator set is intuitive I am not sure how this captures the negative transfer phenomenon the authors talked about in the introduction. Negative transfer should imply that whenever I add a (harmful) client, the utility of the local model always drops. I don't think definition (1b) captures it exactly.\"**,\n\n    **Answer:** 1). Definition 1(b) emphasizes that each client in the optimal collaborator set (OCS) is necessary. Because the utility will drop if any client is removed from OCS. \n\n    2). Definition 1(a) captures the negative transfer exactly by requiring a maximal utility in federated learning. As you mentioned, whenever I add a (harmful) client, the utility of the local model always drops, if we truly use this harmful client for training. However, if we try to learn the best model after we add a harmful client. The best model will not use the gradient information from this harmful client to keep its superiority. Meanwhile, our proposed framework in Sec 4.2 allows assigning a zero weight to this harmful client. The utility will not be a maximum if negative transfer happens. Therefore, our definition captures negative transfer by maximizing the utility of the local model, in federated learning setting.\n\n* **Question: \"How realistic is assumption 1 in practice? I understand that this assumption simplifies the iterative algorithm as you don't have to recompute the benefit graph after eliminating each coalition. But if this assumption fails, recomputing the benefit graph shouldn't be computationally hard.\"**,\n\n    **Answer:** 1). As we mentioned in the main text, Assumption 1 implies that for two clients $I^{i}$ and $I^{j}$, the impact of $I^{j}$ on $I^{i}$ will not reverse by other clients. In particular, they benefit each other means that the data distribution of the two clients share some common patterns which can be captured and utilized by the model. Meanwhile, these shared patterns between the two data distributions will not be affected by other clients. From our experiments, we found that a helpful client will not become a harmful client whether other clients join the collaboration or not. This verifies the rationality of Assumption 1.\n\n    2). As you mentioned, recomputing the benefit graph may not be computationally hard, and our proposed iterative algorithm does not require Assumption 1 to hold. All experiments are conducted without Assumption 1. For example, we re-build the benefit graph on eICU data set after eliminating the coalition {$I^{0}, I^{3}$} and {$I^{9}$}, the experimental results show that the benefit graph on {$I^{1}, I^{2}, I^{4}, I^{5}, I^{6}, I^{7}, I^{8}$} is still a whole SCC as presented in Figure 5.\n\n* **Question: \"In section 4.2, I didn't understand the particular modeling assumptions about the clients' utility functions. In particular, it seems that the goal is to find a hypothesis that is at the Pareto frontier. But why care about such a universal function if each agent wants to build their local model? Additionally, how do the agents determine their weights?\"**\n\n    **Answer:** 1). **\"why care about such a universal function,\"** In federated learning, we have no access to the raw data of other clients due to privacy concerns. The most classic and universal way to use the knowledge from other clients is to use the gradient information [1] of the objectives of other clients. Intuitively, caring about the utility of other clients means the learned local model borrows the knowledge in the data from other clients. A Pareto model which cares about all objectives means better utilization of the data from all clients. Because of the insufficient data in local clients, a learned model with high accuracy on its own data can have high variance. Therefore, higher performance on other clients may indicate a better generalization.\n\n    2). **\"how do the agents determine their weights,\"** We propose to use gradient descent to optimize the weights of all clients. In summary, we first learn the full Pareto Front using a Hypernetwork, which outputs a Pareto model according to the input weight vector. Then we optimize the weights of all clients by gradient descent to maximize the performance of the output Pareto model on the validation set. Detailed information about the implementation is in Appendix B.\n\n [1] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pp. 1273â1282. PMLR, 2017.", " * **5-Section 4.2 discusses how the benefit graph is obtained. It is not clear to me however, that the Pareto solution gives the actual benefit graph. I realize that the exhaustive search for the benefit graph would be infeasible. The issue is if this is an approximation of the benefit graph, then the error should be characterized and the algorithms and theorems in section 4.1 should be modified to reflect that they operate on a noisy estimate of the benefit graph.**\n\n    We would like to explain that 1). **the optimality of the obtained benefit graph is reflected in the optimality of the model learned based on the benefit graph.** In particular, if a model learned based on the benefit graph achieves a SOTA performance, this benefit graph is practical and meaningful. In our experiments, we first obtain the benefit graph using the proposed algorithm in Sec 4.2, then we re-learn an optimal model with the learned OCS encoded in the obtained benefit graph. From the experimental results, our method achieves SOTA performances on both synthetic and real-world datasets. This demonstrates that the obtained benefit graph is reasonable;\n \n    2). as you mentioned that the exhaustive search for the benefit graph would be infeasible. However, deriving a theoretical error may be impossible without an exhaustive search. Because without any priori assumption, the true benefit graph will be agnostic forever, unless we do an exhaustive search. Therefore, we obtained the true benefit graph by an exhaustive try in our synthetic data sets. For example, in the first experiment, we learned $2^{6}-1$ models for each client to obtain the true benefit graph. The results in Figure 4 show that our method in Sec 4.2 captures the true benefit graph;\n \n    3). in reality, obtaining the true benefit graph is intractable because of its exponential time complexity. To tackle this problem, we propose to evaluate the effectiveness of the benefit graph by observing the performance of the learned model based on the benefit graph. Experimental results in the main text verify that optimizing the weights of all clients can approach the true benefit graph.\n \n\n* **6-Unrelated to the model, but the number of clients in the experiments seems to be small (at most 9) even on the synthetic dataset.**\n\n    We would like to explain that, to verify that our method can approach the true benefit graph, we need to exhaustively try all subsets to construct the true benefit graph, although it has the exponential time complexity. For example, in the synthetic experiment on CIFAR10, we tried $2^{10} - 1$ different subsets to determine the true optimal collaborator set (OCS) for each client. The results in Figure 4 show that only when all clients join the collaboration will the models of all clients have the best performance. A larger client set, for example, 50 clients, requires us to try $50 * (2^{50} -1)$ models to obtain the true benefit graph, which may be unrealistic. Therefore, the number of clients is at most 10 in our synthetic experiments.", " We are very grateful to the reviewers for their insightful feedback and suggestions. Our responses to the main concerns are given to each reviewer separately. Moreover, we want to know whether there are **unresolved or new concerns** we need to clarify and we are very pleased to discuss them further, if any. \n\nThank you again!", " * for the weakness **My main concern about the proposed iterative algorithm is that it works only when assumption 1 holds and I believe this is not a realistic assumption in practice.** and  the first question **Regarding the example shown in figure 1, it is not clear that you will always be able to find an initial coalition from the graph. It was later clear that under assumption 1, this problem boils down to finding a strongly connected component but this was not clear in the introduction. In particular, I wonder how the iterative algorithm would start when assumption 1 fails.**\n\n    In addition to a detailed proof by contradiction in Response to Reviewer Psa6 (part 1), Reviewer eyZ6 also gives a more creative explanation: **Theorem 2: this claim is technically fine, but I think you still want to discuss why Algorithm 1 terminates, which isn't totally trivial (since very superficially it's possible that none of the components are stable so the algorithm gets stuck). Indeed it does terminate, because after the SCC decomposition the new graph (over SCCs) is acyclic, which means it can be topologically ordered, and there exists a component which doesn't have incoming edges from other components. That is a stable coalition that can be removed from C to make progress.**", " We would like to thank the reviewer for the valuable feedback. Below are our response to the comments.\n\n* to the comment in **Weakness**,\n\n    1). for our proposed algorithm when Assumption 1 does not hold, we clarify it carefully in the next key point;\n\n    2). for the concerns in subsection 4.2, our detailed clarification is in the following;\n\n    3). for the concerns about the negative transfer phenomenon, we agree with the reviewer that negative transfer can happen when using too much data from another client. However, federated learning does not allow sharing any part of data due to privacy concerns [1]. In other words, **collaboration in federated learning is binary (providing the statistical gradient information of all data, or does not providing anything), as stated in Official Review of Paper200 by Reviewer Mxha.** Under the constraint that only the overall gradient information can be shared, we capture negative transfer by defining maximal achievable utility. It learns the best model with the highest performance for each client. During training, it will automatically determine the optimal weights of other clients to avoid such negative transfer. More discussion about it is in the following.\n\n    4). for the concerns about cooperative game theory, we would like to explain that due to space limitations, we only discuss the most related work in our main text, and we will follow your suggestions to revise our paper. For a detailed discussion about the difference between cooperative game theory and our work, please refer to **Response to Reviewer yALe.**\n\n\n* **Question:** **\"Regarding the example shown in figure 1, it is not clear that you will always be able to find an initial coalition from the graph. It was later clear that under assumption 1, this problem boils down to finding a strongly connected component but this was not clear in the introduction. In particular, I wonder how the iterative algorithm would start when assumption 1 fails.\"**,\n\n    **Answer:** Our iterative algorithm is not affected by Assumption 1. Assumption 1 just guarantees the re-build benefit graph remains the same as the original graph. Whether Assumption 1 holds or not, there always exists one (or more) stable coalition given an arbitrary benefit graph. We can briefly prove it as follows. \n\n    1). From our proposed method, firstly, we search for all strongly connected components (SCC) { $C^{1}, C^{2},...,C^{k}$}. From Definition 4, these SCCs consist of a partition of all clients. For convenience, we group each SCC as a point in the benefit graph. \n\n    * (1). Suppose all SCCs are not stable coalitions, this means that each SCC $C^{i}$ cannot achieve its optimal performance without the collaboration with clients in other SCCs;\n \n    * (2). from (1), for each $C^{i}$, there exists at least an edge pointing to $C^{i}$ (since it needs other SCCs' help);\n\n    * (3). from graph theory, if for each node $C^{i}$, there is an edge pointing to $C^{i}$, then there exists a loop in this graph. \n\n    * (4). from (3), this loop means there is a larger SCC in the benefit graph, which contradicts the definition of SCC that SCC is maximal.\n\n    * So we prove that there always exists a $C^{i}$ that no edge points to, and such a SCC is a stable coalition.\n\n    In fact, the graph of SCCs is a directed acyclic graph and there always exists a node (SCC) that no edge points to (which is called \"head node\"). For example in Figure 1 (a), the graph of SCCs is {$I^{1}, I^{2}, I^{3} $} $\\rightarrow$  {$I^{4}$}  $\\rightarrow$ { $I^{5}, I^{6}$}, in which {$I^{1}, I^{2}, I^{3}$} is a stable coalition that no edge points to. \n\n    2). Assumption 1 cannot let a SCC be a stable coalition. It only guarantees that the re-build benefit graph of the remaining clients remains unchanged after we remove the stable coalitions. Assumption 1 does not boil down our problem to finding all SCCs. Because we prove that under Assumption 1, if a SCC in the original benefit graph is not a stable coalition, it will always be identified as a stable coalition along with more and more stable coalitions being removed in each iteration. \n \n    For example, {$I^{5}, I^{6} $} and {$I^{4} $} are SCCs but not stable coalitions in the original benefit graph in Figure 1. However, after the stable coalition {$I^{1}, I^{2}, I^{3}$} are removed, {$I^{4}$} is a stable coalition when the benefit graph of {$I^{4}, I^{5}, I^{6}$} remains unchanged. In a similar manner, {$I^{4}$} will be removed and {$I^{5}, I^{6}$} becomes a stable coalition when the benefit graph of {$I^{5}, I^{6}$} remains.\n\n[1] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pp. 1273â1282. PMLR, 2017.", " We would like to thank the reviewer for the valuable feedback. Below are our response to the comments.\n\n* **1-The authors mention that privacy concerns are the main reason why a client would not share his data. But I don't see how the privacy cost is being modeled in the problem. For example, the number of individuals the client has to share his data with.**\n\n     would like to explain that the privacy cost is considered in the manner of training models, as prior works in federated learning do [1]: \n\n    1). our work focus on learning a local model for each client in federated learning setting. Therefore, all clients will not share any data with others. Only gradient information is allowed to be shared in federated learning [1];\n\n    2). we propose a gradient-based framework in Sec 4.2. Different from traditional federated learning, we propose to share the gradient information only in a subset that is called **stable coalition**, which further preserves privacy compared with sharing the gradient information with all clients in federated learning.\n\n* **2-Following point 1: I don't think the paper mentions this, but is it not possible for clients to share portions of their datasets instead, perhaps the portions that lead to positive transfer. This would further complicate things and also make it more meaningful to consider the amount of lost privacy.**\n\n    As we stated above, for privacy-preserving, each client is not allowed to share any data with another client. We agree with the reviewer that the portions of the datasets may lead to positive transfer, and it is forbidden in federated learning. As you mentioned, considering the trade-off between the portions of data sharing and privacy-preserving may be a more meaningful research direction and this is worthy of further exploration.\n\n* **3-Similarly, the benefit graph does not include weights. But it seems plausible that a client would only benefit little from other datasets.**\n\n    1). As you mentioned, the benefit graph does not include weights. This is because it is hard to exactly quantify the benefit of one client to another, especially when the two clients are in different client sets. Therefore, we propose the definition **optimal collaborator set** (OCS) to represent the most helpful client set for a given target client.\n\n    2). We agree with the reviewer that a client would only benefit little from other datasets. In our framework, a client will collaborate with others even it benefits little. To address this problem, we can set a reasonable bound $\\epsilon$, and only when the benefit exceeds $\\epsilon$ can the collaboration happen.\n\n* **4-Assumption 1: is there a motivation behind this assumption? do we expect real instances to satisfy it or it is only introduced to make the algorithm less time consuming? Also given the benefit graph can we verify that the assumption holds?**\n\n    We would like to explain that this assumption is not just for simplifying our algorithm. \n\n    1). The motivation behind this assumption is that for two clients $I^{i}$ and $I^{j}$, the impact of $I^{j}$ on $I^{i}$ is not reversed by other clients. In particular, they benefit each other means that the data distribution of the two clients share some common patterns which can be captured and utilized by the model. Meanwhile, these shared patterns will not be affected by other clients.\n\n    2). Given the benefit graph, we can verify whether the assumption holds by comparing the full benefit graph and the benefit graph of each subset. However, the true benefit graph is agnostic and can only be approached by exhaustively trying all subsets. From our experiments, we found that a helpful client will not become a harmful client whether other clients join the collaboration or not. This verifies the rationality of Assumption 1;\n\n\n\n[1] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pp. 1273â1282. PMLR, 2017.", " We would like to thank the reviewer for the insightful and valuable feedback. Below are our response to the comments.\n\nTo the comments in **Detailed comments**,\n\n* **Problem setup, set of coalitions: since C^1, ... C^K partition I, isn't C^0 necessarily empty?**\n\n    We would like to thank the reviewer for pointing out this typo error. It should be that $S = $ {$C^{0}, C^{1},..., C^{k}$} such that $\\bigcup_{k=0}^{K} C^{k}=\\boldsymbol{I}$ as you understand.\n\n* **Axioms 1 and 2: these are conceptually quite similar to the notion of the core in cooperative game theory. The authors may want to discuss the relation between the two.**\n\n    As the reviewer mentioned, axioms 1 and 2 are conceptually similar to the notion of the core in cooperative game theory. However, there are significant differences between the two. In cooperative game theory, the payoff is transferable among players in the coalition, and there is a predefined payoff function on all coalitions. In federated learning, the \"payoff\" is defined as the maximum achievable utility (MAU) on all players rather than coalitions. It is fixed and agnostic. Detailed demonstration please refer to **Response to Reviewer yALe**.\n\n* **Theorem 2: this claim is technically fine, but I think you still want to discuss why Algorithm 1 terminates, which isn't totally trivial...**\n\n    We would like to thank the reviewer for the kind suggestion. As you mentioned, the new graph (over SCCs) is acyclic and there exists a component without incoming edges from other components. We also give detailed proof by contradiction. Detailed illustration can be found in **Response to Reviewer Psa6 (part 1)**.\n\n* **Definition 5: I'd say \"Pareto-efficient (or Pareto-optimal) solution\" instead of \"Pareto solution\"** and **Footnote 1: \"(for) more information,\"**,\n\n    We would like to thank you for pointing out these mistakes. We will revise our paper carefully following your suggestions.\n\n* **\"Learning a best model\" paragraph: what's a \"model\"? What's a \"Pareto model\"? From what I understand, a \"model\" is the same as a \"solution\" (which is a hypothesis), and a \"Pareto model\" is a solution or a hypothesis on the Pareto frontier. Is that right? In any case, it would help to clarify these terms and unify them if they are in fact the same thing.**\n\n    We would like to thank you for your helpful advice. As you understand, a Pareto model is a solution or a hypothesis on the Pareto Front. We will clarify these terms and unify them to facilitate the reader to understand.\n\n* **(Since I'm not familiar with the literature on federate learning, my evaluation regarding the novelty could be misled.)**\n\n    We would like to explain that we consider a more practical federated learning scenario. Detailed illustration about the difference between our work and prior work in federated learning is in **Response to Reviewer yALe.**", " We would like to thank the reviewer for the valuable feedbacks. Below are our response to the comments.\n\n* to the comment about **the difference between our work and cooperative game theory**, \n\n    1). **different definition:** cooperative game theory[1, 2, 3] requires a predefined payoff function $V(C)$ on all subsets $C \\in S$, so that it can obtain the payoff of each subset $V(C)$ directly. In federated learning, the payoff is the maximum achievable utility ($U(I^{i}, C)$) of each client in $I^{i} \\in C$, which is not the function of the subset $C$. What's more, $U(I^{i}, C)$ is agnostic and fixed given the client $I^{i}$, so we need to learn an optimal model to approximate $U(I^{i}, C)$. However, in cooperative game theory, the payoff is the function of the subset $C$. It is transferable among players in the subset, so it can allocate the payoff among players arbitrarily, as long as the sum of all the payoff is $V(C)$;\n\n    2). **different goal:** cooperative game theory [1, 2, 3] aims to find a reasonable allocation of the payoff for all players given the function $V$, which is called a \"core\". However, in federated learning, the payoff of each client (MAU) is not transferable, because it is the achievable highest performance of the learned model. Our work aims to learn the best model for each client, which may not be related to the payoff allocation;\n\n    3). **different approach:** in federated learning, there is no such predefined payoff function as in cooperative game theory. More importantly, the payoff of each client is fixed rather than transferable. Therefore, prior methods in cooperative game theory [1, 2, 3] for deriving a \"stable group formation\" cannot be used in our problem. Nevertheless, suppose we define the MAU of each player as the maximum achievable payoff in cooperative game theory. The iterative graph-based method we proposed can be directly used for identifying the coalition structure in cooperative game theory. **From the above analysis, our research extends prior work in cooperative game theory when the payoff of each coalition is not transferable among players.**\n\n    Since our work focuses on improving the performance of the local model in federated learning, we only present the most related work (federated learning, multi-task learning) in our main text. Following your suggestions, we will discuss the difference between our work and cooperative game theory in our final version.\n\n    **Additional information about this can be found in Official Review of Paper200 by Reviewer eyZ6.**\n\n* to the comment about **why the OCS needs to be learned**, \n\n    as we stated above, we define the payoff of each client in $C$ as the achievable highest performance (MAU), which is not predefined or even agnostic. We can only try to learn the best model to approximate the payoff. Since there is no such payoff function defined over the subset and transferability of the payoff, we cannot directly compute the OCS as cooperative game theory does. \n \n    The OCS is the necessary collaborator for achieving the highest accuracy. To determine the OCS, exhaustively choosing every subset to learn models can have exponential time complexity. To identify the OCS effectively and efficiently, we propose to learn the best model and optimize the collaborator set on the full Pareto Front in Sec 4.2.\n\n* to the comment about **the difference between our work and prior work in federated learning**,\n\n    1). **different setting**, our work considers a more practical scenario. Prior work in federated learning assumes all clients are willing to participate in collaboration, even if they may not gain benefits or even suffer losses. However, we consider that a client will refuse to join the collaboration to provide \"free lunch\" for other clients unless it benefits from the collaboration. \n\n    2). **different goal**, prior work in federated learning only cares about improving the utility for each client. It does not care about which clients are helpful/harmful. However, our work needs to identify which clients are necessary for achieving the maximum utility to achieve a collaboration equilibrium. Therefore, we propose to identify the OCS in addition to learning the best model.\n\n[1] Geometric Stable Roommates. Esther M. Arkin, Alon Efrat, Joseph S. B. Mitchell, Valentin Polishchuk, 2007.\n\n[2] Cooperative games with coalition structures.  R. J. Aumann, Jerusalem, and J. H. Dreze, Louvain, 1974.\n\n[3] Stable Coalition Structures. S. Hart, Tel Aviv, and M. Kurz, 1984.", "This paper considers the problem of federated learning where different clients/entities share their datasets with other clients in order to obtain a model that performs best for the local loss functions. Standard federated learning setting usually share all datasets together to obtain a central model and might not be the best choice for each client separately. The authors propose a notion of collaboration equilibrium where each client shares data with a subset of all the available clients. In particular, a coalition of agents belong to a collaboration equilibrium if each agent gets maximum benefit by collaborating with all the agents in the subset, and the subset is maximal.\n\nIn order to obtain such a collaboration equilibrium the authors propose an iterative algorithm which under certain assumptions, is equivalent to finding strongly connected components in the graph. Finding the collaboration equilibrium requires identifying the benefit graph among the client. Under a very specific model of agents' utility functions, a pareto optimization based algorithm is proposed to find the graph. Finally, though experiments, the authors show that finding collaboration equilibrium does provide improvement compared to standard federated learning based methods.\n Strengths:\n- The authors consider an interesting problem as negative transfer is a real concern in federated learning and building a local model to avoid this phenomenon seems like a good direction.\n- I like the notion of collaboration equilibrium where a group of agents share their data only within clients in a given coaltion.\n\nWeaknesses:\n- My main concern about the proposed iterative algorithm is that it works only when assumption 1 holds and I believe this is not a realistic assumption in practice.\n- Although the definition is proposed for a general utility model, the authors assume a particular utility model in subsection 4.2. I have some concerns about this choice which I mention below.\n- I don't think the proposed definition properly captures the negative transfer phenomenon we observe in federated learning. For example, negative transfer also happens when a client shares too much data from another client as opposed to a small amount of data.\n- This paper talks about collaboration equilibrium but such notions of collaboration have been studied in cooperative game theory, probably in different context. I was surprised to see that the related work section doesn't have any mention of related work from game theory literature.\n\nQuestions for the authors:\n- Regarding the example shown in figure 1, it is not clear that you will always be able to find an initial coalition from the graph. It was later clear that under assumption 1, this problem boils down to finding a strongly connected component but this was not clear in the introduction.\nIn particular, I wonder how the iterative algorithm would start when assumption 1 fails.\n\n- Although the definition of optimal collaborator set is intuitive I am not sure how this captures the negative transfer phenomenon the authors talked about in the introduction. Negative transfer should imply that whenever I add a (harmful) client, the utility of the local model always drops. I don't think definition (1b) captures it exactly.\n\n- How realistic is assumption 1 in practice? I understand that this assumption simplifies the iterative algorithm as you don't have to recompute the benefit graph after eliminating each coalition. But if this assumption fails, recomputing the benefit graph shouldn't be computationally hard.\n\n- In section 4.2, I didn't understand the particular modeling assumptions about the clients' utility functions. In particular, it seems that the goal is to find a hypothesis that is at the pareto frontier. But why care about such a universal function if each agent wants to build their own local model? Additionally, how do the agents determine their weights? I thought the authors consider an interesting problem in this paper. Negative transfer in federated learning is a challenging problem and if you can avoid this issue by building a local model, that would be great! However, there seems to be several issues with the proposed definition. Moreover, the methods work under certain assumptions and I am not sure the assumptions are realistic.", "The authors propose a model of collaboration to improve outcomes for any participating agent.   In their setting, the authors assume that every agent does not benefit from always collaborating with all other agents because of heterogeneity of the underlying data distributions. The main aspect of the proposed solution in the paper is the notion of maximum achievable utility (MAU) and optimal collaborator set (OCS) which each agent must derive.  These are well-studied principles in cooperative game theory and concepts like 'core' and 'stable coalition' are analogous to the definitions used in this work.  Similarly, the approach of using a 'benefit graph' to compute coalitions satisfying the proposed axioms also has an equivalent approaches.  See , for example, literature on \"stable group formation\" (Y. Bachrach, V. Syrgkanis, and M. Vojnovic, 2013; Arkin et. al., Geometric Stable Roommates, 2009; Aauman and Dreze, Cooperative games with coalition structures, 1974; Hart and Kurz, Stable Coalition Structures, 1982).\n\nFurther, the authors have not motivated clearly why this should be a learning problem and why it cannot be solved by using other techniques (example, in the literature mentioned above).  In its current form, I think the paper needs more work to distinguish itself from prior art and how it can use the federated learning framework to 'learn' the OCS instead of computing it directly. There is a lot of related work in the cooperative game theory and federated learning literature.  I think the authors need to do a much better comparison with the existing literature and propose why their work is different from it and carry out clear comparisons (in their experiments) to show the efficacy of their approach. ", "Given a network of clients each with his own private dataset, the locally learned model can be improved by obtaining data from other clients (assuming no domain mismatch). The paper models this problem by introducing the benefit graph which models how each client may benefit another. The concept of collaboration equilibrium is introduced and optimization algorithms to solve it are given. Some theoretical guarantees are shown along with experimental results.   I think the paper solves an interesting and important problem and that the model introduced is interesting and detailed. My main issue is that it does not appear that the introduced model captures the problem. Here are some points:\n\n1-The authors mention that privacy concerns are the main reason why a client would not share his data. But I don't see how the privacy cost is being modelled in the problem. For example, the number of individuals the client has to share his data with.\n\n2-Following point 1: I don't think the paper mentions this, but is it not possible for clients to share portions of their datasets instead, perhaps the portions that lead to positive transfer. This would further complicate things and also make it more meaningful to consider the amount of lost privacy. \n\n3-Similarly, the benefit graph does not include weights. But it seems plausible that a client would only benefit little from others datasets.\n\n4-Assumption 1: is there a motivation behind this assumption? do we expect real instances to satisfy it or it is only introduced to make the algorithm less time consuming? Also given the benefit graph can we verify that the assumption holds? \n\n5-Section 4.2 discusses how the benefit graph is obtained. It is not clear to me however, that the Pareto solution gives the actual benefit graph. I realize that the exhaustive search for the benefit graph would be infeasible. The issue is if this is an approximation of the benefit graph, then the error should be characterized and the algorithms and theorems in section 4.1 should be modified to reflect that they operate on a noisy estimate of the benefit graph. \n\n6-Unrelated to the model, but the number of clients in the experiments seems to be small (at most 9) even on the synthetic dataset.  The introduced model does not seem to be complicated enough to capture the real details of the problem. Further, the algorithms and guarantees introduced do not seem to be rigorously justified. ", "The paper considers the problem of agents sharing training data to improve the accuracy of the model obtained on their own population.  The high-level goal is to find \"stable\" collaboration patterns where no agents want to deviate (e.g., stop sharing or form their own groups of sharing).  The authors first consider an abstract formulation where each agent has a utility function over all sets of other agents to collaborate with.  Assuming that one can find the most beneficial set of collaborators for each agent, the authors present an efficient algorithm to divide agents into groups that form a stable collaboration pattern (aka a collaboration equilibrium).  Since the problem of finding this optimal set of collaborators for each agent is nontrivial in general, the authors come back to the setting of sharing training data, where they propose a theoretically principled approach to build the benefit graph (which encodes most beneficial collaborators) by optimizing on the Pareto frontier of hypotheses / models of accuracy of all agents.  The authors then evaluate their approach on synthetic and real data, and compare that against several benchmark methods for personalized federated learning.  Empirical results suggest that the collaboration equilibrium behaves roughly as one would expect.  Also, the model found by optimizing on the Pareto frontier appears to achieve remarkable performance, often comparable to or better than the best benchmark.  The accuracy at collaboration equilibria is somewhat worse, which is natural given that there might be a \"price of stability\". ### Strengths\n\nThe notion of collaboration equilibria appears natural, and the algorithm for computing such equilibria insightful.  Together with the SPO part, this provides a quite complete solution for personalized federated learning problems, and in particular, the equilibrium solutions take into consideration the incentives of self-interested agents, which is of potential practical importance.  The experiments appear to support the main claims of the paper.\n\n\n### Weaknesses\n\nSome parts of the overall approach lacks theoretical foundations (although they make sense).  The writing could be improved, e.g., by unifying terminologies and better connecting different parts of the paper.  Also, (this is not necessarily a weakness, but) I'm not familiar with the literature on federated learning, so I can't say much about the novelty of the method.\n\n\n### Detailed comments\n\nProblem setup, set of coalitions: since C^1, ... C^K partition I, isn't C^0 necessarily empty?\n\nAxioms 1 and 2: these are conceptually quite similar to the notion of the core in cooperative game theory.  The authors may want to discuss the relation between the two.\n\nTheorem 2: this claim is technically fine, but I think you still want to discuss why Algorithm 1 terminates, which isn't totally trivial (since very superficially it's possible that none of the components are stable so the algorithm gets stuck).  Indeed it does terminate, because after the SCC decomposition the new graph (over SCCs) is acyclic, which means it can be topologically ordered, and there exists a component which doesn't have incoming edges from other components.  That is a stable coalition that can be removed from C to make progress.\n\nDefinition 5: I'd say \"Pareto-efficient (or Pareto-optimal) solution\" instead of \"Pareto solution\"\n\nFootnote 1: \"(for) more information\"\n\n\"Learning a best model\" paragraph: what's a \"model\"?  What's a \"Pareto model\"?  From what I understand, a \"model\" is the same as a \"solution\" (which is a hypothesis), and a \"Pareto model\" is a solution or a hypothesis on the Pareto frontier.  Is that right?  In any case it would help to clarify these terms and unify them if they are in fact the same thing. Overall I think this paper proposes a novel theoretically principled method for computing stable outcomes of data sharing or collaboration in general, which can also be applied to personalized federated learning.  Some of the theoretical results appear quite insightful.  The experiments are quite informative and support the main claims of the paper.  (Since I'm not familiar with the literature on federate learning, my evaluation regarding the novelty could be misled.)"], "review_score_variance": 3.1875, "summary": "The paper proposes a model of agent collaboration to improve outcomes for any participating agent in a setting where every agent does not always benefit from collaborating with all other agents. The reviewers did find some of the theoretical results interesting, however, in its current (revised) form, they still argued during the discussion post-rebuttal that: (i) the game theoretic formulation of this problem is not entirely new and has been studied in various forms before and (ii) the particular application of the results to federated learning comes after making various (questionable) assumptions. I would encourage the authors to take into account (i-ii) for preparing a revised version of their paper and resubmit to another conference.", "paper_id": "iclr_2022_CSw5zgTjXyb", "label": "train", "paper_acceptance": "Reject"}
{"source_documents": ["This work aims at transferring a Generative Adversarial Network (GAN) pre-trained on one image domain to a new domain $\\textit{referring to as few as just one target image}$. The main challenge is that, under limited supervision, it is extremely difficult to synthesize photo-realistic and highly diverse images, while acquiring representative characters of the target. Different from existing approaches that adopt the vanilla fine-tuning strategy, we import two lightweight modules to the generator and the discriminator respectively. Concretely, we introduce an $\\textit{attribute adaptor}$ into the generator yet freeze its original parameters, through which it can reuse the prior knowledge to the most extent and hence maintain the synthesis quality and diversity. We then equip the well-learned discriminator backbone with an $\\textit{attribute classifier}$ to ensure that the generator captures the appropriate characters from the reference. Furthermore, considering the poor diversity of the training data ($\\textit{i.e.}$, as few as only one image), we propose to also constrain the diversity of the generative domain in the training process, alleviating the optimization difficulty. Our approach brings appealing results under various settings, $\\textit{substantially}$ surpassing state-of-the-art alternatives, especially in terms of synthesis diversity. Noticeably, our method works well even with large domain gaps, and robustly converges $\\textit{within a few minutes}$ for each experiment.", " To be more specific, all results where the target domain is given by a painting are not good. The method successfully takes on the colors of the target image, but fails to take on the distinct characteristics of a painting, such as brush strokes. The results look scary. One can simply  look at the results in the first figure for the Van Gogh example. Full screen and then look at it for 5 minutes. Does the result look like a painting? No. Look at the adaption to Dix.\n\nIf the other reviewers indeed think the results are good I can accept that as a different opinion. But I do not think the domain adaption was successful in the important cases (paintings) and I am confident in my ability to judge visual quality. As I wrote before, I do appreciate the quality of the sketch transfer in Figure 2. This is a successfully and non-trivial case of domain adaption that is included in the paper. Also to amend that, the Superman example in figure 5 is reasonable considering the complexity of the task. But look at the top two rows of Figure 5 full screen. This is unreasonable. \n\nI know there is no chance to convince the authors and itâs fine that the authors want to insist in their opinion. At this point, I just want to make sure the authors understand my opinion. Itâs up for the area chairs to decide, since the discussion is getting repetitive.\n\n\n", " **Review:** \"if the generator network does not change, the domain also does not change\".\n\n**Answer:** This may be a misunderstanding. We have emphasized in previous response that **there are also multiple domains even for faces**. For example, real faces, sketches, cartoons all belong to different domains. Babies, children, adults, elderly also belong to different domains. Under such a background, it is possible to transfer the generator from one domain to another without touching the synthesis network. Here is the reason. The convolutional kernels of early layers are more likely to render basic shapes, like circle (low-level) and eyes (high-level). The convolutional kernels of later layers are more likely to render color. Prior arts agree to call these concepts as **prior knowledge**. The latent codes of StyleGAN tend to tell the synthesis network how to organize these basic concepts to produce a high-quality synthesis. **In this work, we propose to *reuse* these knowledge for domain adaptation**. We argue that, by **reorganizing** these concepts, we manage to transfer the domain. Hence, **even the generator network does not change, the domain *indeed* changes**, which has been demonstrated both qualitatively and quantitively. We **have also discussed our limitation in the submission**, which is that we cannot transfer domains that are highly different from each other, like faces to churches. That is because these is **only one** training image, **making it hard to learn new concepts for the synthesis network**.\n\n**Reviewer:** \"But I cannot understand why this part of the paper should be called domain adaption.\"\n\n**Answer:** Because this is a **standard protocol (or say, experimental setting)** in the previous literature. Please refer to Ojha et al. (CVPR 2021), which is currently the state-of-the-art approach in this field. It is **not fair** to question a well-defined task (defined by prior arts) by just raising \"I cannot understand why xxx is called xxx\". By the way, with all due respect, it seems unfair to reject ResNet by saying \"I cannot understand why the task should be called image classification and object detection\".\n\n**Reviewer:** \"How could the generator have learned to produce images in other domains without any training? Just by mapping to regions in the latent space that the mapping network usually does not access? If the results would look good, then I would fully agree with the authors. Then they would have found a remarkably simple and surprising method for domain adaption.\"\n\n**Answer:** We have explained many times on this \"how\". That is because **we manage to *reuse* the learned knowledge as much as possible**. Both the qualitative and quantitative results point to this conclusion. Also, the reviewer has agreed that ***If the results would look good, then I would fully agree with the authors. Then they would have found a remarkably simple and surprising method for domain adaption***. This is just what we want to claim in this paper. **The results are good and also appreciated by the other two reviewers**. Please be specific **on which part(s) the results are not good**? If you insist on judging a submission **just because of not believing**, then we have no further comments.\n\n**Reviewer:** \"Because the generator does not change, you donât have the required degrees of freedom to perform domain adaption.\" and \"I just try to convince the authors that changing the generator is likely necessary for domain adaption and that they should improve on their initial idea.\"\n\n**Answer:** Please refer to the first question-answer. Under the challenging one-shot setting in domain adaptation, **reusing the prior knowledge** is critical. If changing the entire generator with the naive fine-tuning, we even fail to transfer faces to sketches, let alone transfer faces to churches. StyleAlign studies a different topic, where they do not really care about the number of training images. **We agree that when there are sufficient training samples, learning the entire generator may lead to a better performance.** **However, this conclusion is orthogonal to the goal of our work, where we provide an *elegant and effective* solution to the one-shot setting.** Everyone should agree that, sometimes, we may only have one reference image, like Mona Lisa.", " I understood that the paper takes a w latent code and maps it to another one. I also understood that the generator network does not change.  So almost per definition, if the generator network does not change, the domain also does not change.\n\nThe authors also seem to agree that adding sunglasses is not a main focus, but only a byproduct. Then why does so much of the paper and the evaluation focus on this byproduct? This was one of my original complaints.\n\nI also agree with the authors that there are reasonable results for this byproduct. But this is what I call domain restriction because you map all latent codes to only latent codes of people wearing sunglasses. All the results were already in the original latent space. However, there are GAN editing methods that can take multiple labeled images as input and compute a linear edit vector to add sunglasses. This could be done in a single shot method, e.g. by computing an editing vector from a mean face to the sunglass face, but that would be contrived. Even so, do you compare to this baseline? That is what others did before going many years back. But this is not even the main issue for me. There is no problem learning a sunglass edit or similar, and one can easily label 100s of images of people with sunglasses. Itâs not difficult. So this is a contrived problem and not a single shot problem. Maybe someone is interested in this, possible. Itâs fine for the authors to argue so. But I cannot understand why this part of the paper should be called domain adaption.\n\nThere is another part of the paper that shows results for attempted true domain adaption, that is also correct. The authors argue that the results are good, but I argue that the results are poor and also not really evaluated. I do agree that the sketch results look fairly reasonable. Many of the other results are not good though. How could the generator have learned to produce images in other domains without any training? Just by mapping to regions in the latent space that the mapping network usually does not access? If the results would look good, then I would fully agree with the authors. Then they would have found a remarkably simple and surprising method for domain adaption. \n\nI mainly tried to be helpful to the authors. I provided a likely explanation as to why the results in challenging cases are not that good. Because the generator does not change, you donât have the required degrees of freedom to perform domain adaption. You may  consider moving to an extended latent space (I do not recommend this) or changing the generator. I would also like to refer to a recent paper StyleAlign. While oversimplifying a bit, i feel the paper also gives results that seem to indicate that most of the transfer results come from changing the generator and not from changing the mapping network. This has nothing to do with the evaluation. I just try to convince the authors that changing the generator is likely necessary for domain adaption and that they should improve on their initial idea.\n\n", " Thanks for your comments.\n\nFirst, **the task studied in this work is well-defined in the literature of generative modeling and raises wide attention in the past year**. Please refer to [1] (CVPR'20) [2] (CVPRW'20) [3] (NeurIPS'20) [4] (CVPR'21), which are all published at top conferences recently. These references are already cited and discussed in our submission, and we just follow them about the task name. Thus, with all due respect, **we *disagree* that \"why the technique should be called domain adaptation\" can be the core concern**.\n\nSecond, our task is far beyond domain collapse or domain restriction. For example, the sketches in the last row of Fig. 2 in our submission **cannot** be generated by the generator trained on the original domain. Under such a case, **\"collapse\" or \"restriction\" seems inaccurate**. Transferring a face model to synthesize only faces wearing eyeglasses (or baby faces) is only a sub-task (or say, byproduct) of our approach. From this point of view, with all due respect, **we *disagree* that \"the technique should be called domain collapse or domain restriction\"**.\n\nThird, about the concern \"domain collapse can be used for editing (as shown in the paper) but there are better methods\". To the best of our knowledge, existing approaches can **barely transfer a generative model to synthesize images regarding a second domain *referring to as few as one image* and achieve *high diversity***. Please correct us by naming a few *\"better methods\"*.\n\nHope that the above discussions address your concerns.\n\n[1] MineGAN: Effective Knowledge Transfer from GANs to Target Domains with Few Images. Wang et al. CVPR'20.\n\n[2] Freeze the Discriminator: a Simple Baseline for Fine-Tuning GANs. Mo et al. CVPRW'20.\n\n[3] Few-shot Image Generation withElastic Weight Consolidation. Li et al. NeurIPS'20.\n\n[4] Few-shot Image Generation via Cross-domain Correspondence. Ojha et al. CVPR'21.", " The rebuttal does not really address the core concerns. I still do not understand why the technique should be called domain adaptation. The technique should be called domain collapse or domain restriction. The technique takes points inside the domain and maps them to a smaller subset that looks similar to the input. It's really just restricting the domain to a much smaller subset. In the end, the generated images are inside the domain of the generator. Domain collapse can be used for editing (as shown in the paper) but there are better methods. Domain collapse cannot be used for challenging tasks that other researchers call domain adaptation and that is evident in the results.\n", " Thanks for liking the novel and interesting task studied in this work, which is also appreciated by the other two reviewers.\n\nFirst, we would like to reaffirm that, under such a challenging yet useful setting (*i.e.*, adapting a generative model **with only one reference image**), our approach **makes it work for the first time** to the best of our knowledge. From this point of view, it should already be considered as a major contribution and **of great interest to the community**. It **provides a valid starting point for this research direction**. Here, by saying \"make it work\", we provide **sufficient qualitative and quantitative proof regarding both the quality and the diversity criteria**. Also, as suggested, we visualize the latent representations before and after adaptation in Fig. A2. Our approach indeed transfers the latent space successfully.\n\nSecond, we argue that **novelty does not necessarily mean a complex system**, and that an algorithm should not be blamed for its simplicity. Instead, **simple but efficient** approaches should be encouraged because of the **easy implementation, good reproducibility, and strong generalization ability**. For example, ResNet (using skip-connection to solve the gradient vanishing problem) and MoCo (leveraging a memory bank to increase the number of negative samples for contrastive learning) are both this kind of methods. Our GenDA is **efficient** (only a few parameters are tuned) but far more **effective** than existing alternatives (see comparisons in Tab. 1 and Tab. 2). As a result, we manage to transfer a GAN model **within a few minutes**, which is another appealing advantage of our approach.\n\nThird, about the questions \"why they do work well is not clearly demonstrated in the paper\" and \"I noted that result, but just wonder why\". We have conducted comprehensive ablation studies and shown the results in **Appendix**.\n\n   - Tab. A1 suggests that **without the newly introduced attribute adaptor (AA) or attribute classifier (AC), the performance remains poor**. The reasons are already discussed in Sec. 2.2 and the rebuttal. Here, we carefully pick some discussions.\n      - On one hand, \"the generator focuses on transferring the most distinguishable characters of the only reference, **instead of learning the common variation factors repeatedly**\".\n      - On the other hand, \"the generated images before and after domain adaptation are expected to share most variation factors, therefore, **the knowledge learned by the discriminator in its pretraining could be also reused**\".\n      - Also, the comparison between the first row and the third row of Tab. A1 suggests that **tuning the whole discriminator achieves worth performance than our GenDA**. The comparison between the second row and the third row of Tab. A1 suggests that **without re-initializing AC also achieves worth performance than our GenDA**.\n      - \"Why the last layer is more important\" is explained in the rebuttal, as \"**there exists a gap** between (1) the classification of real and fake images in the source domain, and (2) the domain-specific attribute classification in our approach\".\n\n   - Tab. A2 suggests that **with a heavier attribute adaptor or attribute classifier, the performance also becomes worth**. That is because, under our one-shot setting, there is only one training sample, which may easily cause the overfitting problem. Our approach **works just because of its efficient design**.\n\nHope that the above discussions address your concerns. Thanks for your effort and suggestions again.", " Thanks for the author's reply. Part of my concerns are solved, especially for the feature visualization in Q5 and Q6. The added discussions are interesting. However, I still feel that the proposed method lacks novelty.\n- Q1: As claimed in the comments, I fully agree that one-shot generation is a novel and interesting task. However, the two modifications and one trick are simply designed, yet why they do work well is not clearly demonstrated in the paper. Zh5e \"The adaptor does not seem powerful enough to match the complexity of the task\".\n- Q3: I noted that result, but just wonder why? Does it mean the final layer in the pre-trained discriminator is much important in such a setting? We must use the whole pre-trained discriminator for the classifier, instead of different layers used in the perceptual loss. \n- Q4: I guess this is a training trick. I cannot buy this as a new contribution to the community.", " Dear Reviewer CemL,\n\nThank you so much for your effort in reviewing this submission! We have tried our best to address your concerns above the reply. Would you mind taking a look and letting us know what you think?\n\nFeel free to let us know if there is anything unclear or so. We are happy to clarify them.\n\nBest, \nAuthors", " Dear Reviewer Zh5e,\n\nThank you so much for your effort in reviewing this submission! We have tried our best to address your concerns above the reply. Would you mind taking a look and letting us know what you think?\n\nFeel free to let us know if there is anything unclear or so. We are happy to clarify them.\n\nBest, \nAuthors", " **The setting and challenge of few-shot generative domain adaptation.**\n\nBefore addressing the concerns, we would like to reaffirm the setting of few-shot generative domain adaptation.\n\nIt is a relatively new task, but has been formally defined and explored in the previous literature [Mo et al., 2020; Ojha et al., 2021]. Task of few-shot generative domain adaptation aims at âtransferring a generative model that is well-trained on the source domain to a target domain with limited training dataâ, **rather than performing the image-to-image translation**. Namely, both before and after training, the model synthesizes images by only taking random noises as the inputs. Therefore, there is no concept of **input images** in this task.\n\nFor a generative model, **the key evaluation criteria are the synthesis quality and diversity**. In other words, we donât want the transferred model to simply memorize the training data, instead, the transferred model should capture the pattern of the adapted distribution and generate new samples. It is only a *byproduct* that our approach can maintain some semantics between the images synthesized from the same latent code before and after adaptation. We have provided sufficient qualitative and quantitative experimental demonstration on the effectiveness of our approach in Tab. 1, and Fig. 2.\n\nThe main challenge of this task is that, under the few-shot setting, it is difficult to learn a new generative model for photo-realistic, and more importantly, highly-diverse synthesis. Especially, when the number of images in the target domain is reduced to one, this task becomes extremely challenging and all the previous approaches would fail (*i.e.*, the model after adaptation collapses to one mode). One of our main contributions is that **GenDA enables the task of generative domain adaptation under such a challenging setting**.\n\n \n**Q1. The adaptor does not seem powerful enough to match the complexity of the task.**\n\nWe have conducted experiments on adapting the same source model to a wide range of target domains, where each domain only contains one reference image. As shown in Fig. 2 and Tab. 1, our approach is efficient and effective. We significantly surpass the second competitor from both the quality and the diversity perspectives.\n\nWe also visualize the latent representations after adaptation in Fig. A3. Obviously, the original latent space is successfully transformed to a new space regarding the target sample. This verifies that the proposed adaptor is powerful enough.\n\nMeanwhile, due to the challenging setting of only having one image from the target domain, a more complex structure may aggravate the overfitting problem, which is shown in Tab. A2. Instead, our efficient design alleviates such a problem, resulting in a satisfying domain adaptation.\n\n**Q2. manipulate $\\mathcal{Z}$-space rather than $\\mathcal{W}$-space.**\n\nThis is a misunderstanding. In all the experiments, we always use the $\\mathcal{W}$-space of StyleGAN for domain adaptation. **Implementation** in Sec. 3 (on Page 4) of the submission already explains this. We denote the latent space as $\\mathcal{Z}$ in Sec. 2, just following the general formulation of deep generative models.\n\n**Q3. The task of Figure 4 is not that clear and itâs really difficult to see the relationship between input and output.**\n\nFirst of all, there are no input images in our task. Same as other experiments, the task of Figure 4 is to adapt a source GAN model to a target domain with only one/two images (*i.e.*, the first column). The top row shows the images synthesized by the source model, which are used for reference *only*. All samples from the remaining rows are synthesized using the same latent codes as those in the first row. As already pointed out in the caption, (1) pairing âthe woman with eyeglassesâ with âa man with eyeglassesâ, GenDA transfers the âeyeglassesâ attribute and maintains the âgenderâ attribute from the source model, (2) pairing the same woman with âanother woman without eyeglassesâ, GenDA transfers the \"femaleââ attribute and maintains the \"eyeglassesââ attribute from the source model.\n\n**Q4. All results transferring faces to other faces should be removed from the paper.**\n\nActually, human faces also consist of different domains, like âmaleâ and âfemaleâ can be viewed as two different domains. We follow the standard setting in the few-shot generative domain adaptation task introduced in [Ojha et al., 2021], which is also included in the submission as a baseline.\n\nIn addition, GenDA can achieve generative domain adaptation regarding both âattribute-levelâ (*e.g.*, child) and âstyle-levelâ (*e.g.*, painting style) semantics, as shown in Fig. 3. This is a completely different task to the attribute-based GAN editing.\n\n", " **Q1. The biggest weakness is that the proposed method has limited novelty.**\n\nThe main contribution of this paper is to **enable the task of one-shot generative domain adaptation**. Previous work barely achieves the goal of adapting a GAN model with **only one image**. Recall that generative domain adaptation is **a clearly different task from facial editing**, which is targeted by the mentioned work [r1] and [r2].\n\n**Q2. What are the differences between the proposed adaptor and these prior works? Why the proposed adaptor perform better?**\n\nAlthough these works also transform the latent space to some extent, the targets are totally different. For the purposes of disentangled controls, [r1] analyzes the latent spaces and leverages a pre-trained classifier to identify certains channels that control a specific attribute. In order to support conditional sampling, [r2] uses conditional continuous normalizing flows to learn the relationship between two latent spaces. Besides, [r3] proposes a framework that can generate high quality stylistic portraits with a hierarchical variational encoder that ensures the inversion consistency. These works are clearly in a different scope from our work. Please refer to **Q1**.\n\nConcretely, our attribute adaptor aims at adapting the most representative characters of the target domain to the source generator. In this way, through randomly sampling from the latent space, the adapted generator can always synthesize images that possess the characters of the target domain. Here, the most representative characters are identified in the data-driven manner, without the help of any pre-training. Moreover, our adaptor is designed as a lightweight transformation module, instead of continuous normalizing flows ([r2]) or a hierarchical variational encoder ([r3]). Such a design makes our adaptor more friendly to *one-shot* generative domain adaptation, where there is only one training sample. Experimental results in Tab. A2 also suggest that a heavier network might cause severe performance degradation. \n\n**Q3. Why the proposed attribute classifier is better? Why not just fine-tuning the final layer of the original discriminator?**\n\nThe attribute classifier we refer to is fundamentally different from the attribute classifier used in the mentioned literature. Specifically, the latter pours more attention to specific attributes (*e.g.*, gender, age, and hair) and is mostly pre-trained in the supervised manner. Instead, our attribute classifier aims at distinguishing the domain-specific attributes of the target domain from those of the source domain, and gets updated from scratch in the adversarial learning. \n\nOur experimental results in Tab. A1 suggest that incorporating a new classifier (the âAA + ACâ row) outperforms directly fine-tuning the final layer of the original discriminator (the âAAâ row). It implies that there exists a gap between (1) the classification of real and fake images in the source domain, and (2) the domain-specific attribute classification in our approach.\n\n**Q4. I cannot buy the novelty of reusing truncation trick for diversity-constraint strategy.**\n\nPrevious approaches apply the truncation trick to improve the quality **at the inference stage**. However, it is the first time to leverage it at the training stage as a diversity-constraint strategy. This is motivated by âthere is only one reference image from the target domain, but the source generator can produce high-diverse imagesâ. Such a truncation strategy helps lessen the diversity gap between the domains before and after adaptation. Tab. A1 also demonstrates the effectiveness of this strategy.\n\n**Q5. If the authors can visualize the learning representation distribution of Figure 4, it will be clearer to demonstrate such mapping in the representation domain.**\n\nThanks. As suggested, we include the visualization of latent representations in Fig. A2 of *the revised version*. Obviously, the latent representations are clearly pushed away given different reference images as the targets. Also, when using more than one reference image from the target domain, the transformed representations tend to locate at the overlapped region between the representations learned from each reference image independently.\n\n**Q6. How to visualize the representation change in Figure 5 and then demonstrate the swap of learning representation would be significant.**\n\nWe include the representation change after adaptation in Fig. A3 of *the revised version*. Apparently, the latent representations are successfully shifted compared with the original ones.\n", " **Q1. Ablation study on different architectural designs of attribute adaptor and classifier.**\n\nThanks. As suggested, we conduct ablation studies on the architecture of the attribute adaptor and the attribute classifier, respectively. The results are also included in Tab. A2 of *the revised version*. Specifically, we replace the lightweight adaptor and classifier with a two-layer MLP independently. Experimental results suggest that the synthesis performance becomes worse when increasing the capacity of either network due to the overfitting problem. This in turn verifies the effectiveness of our simple design.\n\n**Q2. Discussion with Exemplar SVM.**\n\nWe have included a discussion in Sec. 2.2 of *the revised version*.\n\n**Q3. The limitation is not clearly stated.**\n\nThanks for pointing this out. We have updated the limitation to *explicitly* state that our method would fail when the inter-subclass variation is huge in Sec. 4 of the revised paper.\n\n**Q4. Include the comparisons to the style-transfer methods.**\n\nWe compare our GenDA with the recent style-transfer method, SWAG (Wang *et al.* CVPR21). Results are shown in Fig. A4 of *the revised version*. It can be seen that GenDA could transfer the style in a more harmonious way, while SWAG transfers the color inconsistently, leading to obvious artifacts.\n", " **Q5. I think this would be more insightful if we can see the same inputs transferred to different domains in Figure 5.**\n\nAgain, there are no input images in our task. But as suggested, we feed the same latent codes into the models before and after adaptation to see how the synthesized images change. This is included in Fig. A6. Here, the synthesis from the source domain is only shown as the reference. We can tell that our GenDA is able to transfer the most distinguishable attributes of the target domain, but almost maintains other semantics (*e.g.*, the face pose and the church shape).\n\n**Q6. I also feel the results are hard to interpret in multiple figures (e.g. 3), because I do not understand where the corresponding images in the original domain are.**\n\nPlease refer to Q5, there are no input images in our task. The requested results are included in Fig. A5. Our task setting is clearly different from image-to-image translation or style transfer. \n\n**Q7. The evaluation of this type of work is primarily visual.**\n\nWe follow the same evaluation metric in previous work [Ojha et al., 2021]. Here, FID measures the distributional distance between the synthesized data and the real data. This is widely used to evaluate generative models. Moreover, we also include the precision and recall metrics [Kynkaanniemiet al., 2019], which are primarily proposed to evaluate the synthesis diversity of a generative model. All metrics are well-defined and commonly used for GAN evaluation. All quantitative results demonstrate the superiority of our approach.\n", "The paper proposes to do one-shot domain adaption by fine tuning a state of the art network StyleGAN. The paper introduces a few techniques to do so. First, the paper proposes to add a lightweight attribute adaption layer in the beginning of StyleGAN to modify the latent code. An existing latent code can be modified to give a new latent code that is in the new domain. Second, the paper proposes a novel type of discriminator reuse. A discriminator has its features frozen, but a new classification head is added. The paper shows various visual results. The paper is generally well written and understandable. The paper conveys the main ideas of the work to the reader and I believe I got a good understanding from what the authors did by reading the paper. It seems very doable to reproduce the results on the paper alone.\n\nThe two technical main ideas are simple, but somewhat novel and can be considered a contribution to the field. Most, I like the idea of reusing a pre-trained discriminator. I am not aware of similar work and this seems to be a creative idea.\n\nOn the downside, I do not like the idea of the adaptor layer. The adaptor does not seem powerful enough to match the complexity of the task. There are multiple concerns here. The layer is too early in the network and seems to manipulate z-space rather than w-space (or some of the other available latent spaces later in the network). The layer is not powerful enough to do a more complex computation. Also, naturally, domain transfer generally means that the generator does not have the capabilities to generate images in the new domain. What is this network really doing by only manipulating a z-vector? If the z-vector is not split, it is hard to imagine the generator has the range to produce the desired results. If the z-vector is split, this could be a bit better, but also carries more risks. As it is, we can only observe a limited form of domain transfer.\n\nOne concern regarding the results is Figure 4. Visually all faces look really nice. But the task is not that clear and it's really difficult to see a relationship between input and output. This is not a result that should be considered domain adaptation. I would strongly suggest that all results transferring faces to other faces (but both input and output are in the same domain) should be removed from the paper. While this uses the same software system, it is essentially a different task that has been addressed better by many other papers. For example, attribute-based GAN editing papers can do that as well and there are multiple of them. I am pretty sure the authors do not want to go down that route.\nThe challenging domain transfer results, e.g. Figure 5, are indeed what I was hoping to see more of. Unfortunately, these results do not look particularly good. We can mainly observe a slight adaptation of all results shifting to a particular color scheme. It would also suggest to synchronize the examples. I think this is would be more insightful if we can see the same inputs transferred to different domains. I also feel the results are hard to interpret in multiple figures (e.g. 3), because I do not understand where the corresponding images in the original domain are. Maybe the input changes a lot for the challenging examples. I am afraid that this is a considerable omission, because the images in the input domain are such an essential component of the results. How can anybody judge these results without seeing the input images? In addition, there should be corresponding results shown. E.g., the last two rows in Figure 5 should correspond to each other. I do like the result in Figure 2. In a future version of the paper it would be good to see more of these interesting results.\n\nThe evaluation of this type of work is primarily visual. The metrics are not especially revealing if the results are good. It's good to have them, but I feel the authors still need quite a bit of work to make the system function as desired. My recommendation would be to revisit the adaptor design and find something better.\n I am very positive about the potential of this work, but it needs a substantial improvement.", "This paper studies the challenging problem of transferring a pre-trained GAN from the source domain to a target domain with only one example available. To achieve the source-to-target domain adaptation while being able to synthesize diverse samples, this paper proposed a novel method called GenDA. The key idea is to freeze the generator and discriminator backbones while fine-tuning the linear layer added on top. Convincing experiment results have been demonstrated on the standard face and building benchmarks. Strengths:\n* This paper tackles a challenging domain adaptation problem which is very interesting.\n* This paper demonstrates convincing qualitative comparisons (e.g., realism and diversity) to the existing efforts including Mo et al., 2020 and Ojha et al. 2021.\n* This paper also shows comparable and improved quantitative results to the state-of-the-art methods in the case of a one-shot and ten-shot adaptation, respectively.\n\nWeaknesses:\n* This paper discovered an interesting phenomenon that a lightweight attribute adaptor could generate surprisingly-good domain adaptation results. Although it has been explained in the paper, the reviewer would appreciate it if some sort of ablation study (both qualitative and quantitative results) can be included in the paper (at least in the supplementary material of the final version). For example, what happens if we use different architecture or operators for the attribute adaptor.  The same rule applies to the attribute classifier (though it might be overfitting).\n* At a higher level, this paper reminds me of the Exemplar SVM published 10 years ago. The conclusion in the paper is that it is often sufficient to obtain a good decision boundary if you have one positive example and many negative examples. This is very similar to the attribute classifier proposed in the paper. The reviewer would suggest incorporating such discussions in the final version of the paper.\n* The limitation of the paper is not clearly stated. For example, the reviewer would like to know if the one-shot learning method applies to the âcar -> abandoned carâ application studied in the Ojha et al., 2021. It seems to the reviewer that the proposed method could fail at âcar -> truckâ application when the inter-subclass variations are huge. Please comment on this in the rebuttal.\n* Furthermore, the cross-domain experiment (see Figure 5) seems to be a special case of style transfer. In this sense, this paper should also include comparisons to the style-transfer methods.\n\nReferences:\nEnsemble of Exemplar-SVMs for Object Detection and Beyond, Malisiewicz et al., In ICCV 2011. Overall, this is a very interesting paper with convincing results. I believe the key idea from this paper can have a broader impact on the community (e.g., 3D and video synthesis) in the future. I recommend accepting this paper but would kindly ask the authors to incorporate the suggested discussions in the final version.", "In this work, the authors propose a framework for one-shot generation, which aims to tame a new GAN using a pre-trained GAN model as well as one target image. Here, the authors present three strategies to ensure the quality and diversity of generated images: introducing an attribute adaptor to map the latent space to the target attribute; presenting an attribute classifier in the discriminator, and applying the truncation trick for the training. Experiments are conducted on the face and building datasets.  Pros:\n1. The one-shot image generation is a novel and interesting task.\n\n2. The overall idea and the proposed pipeline towards addressing it are easy to follow.\n\n3. In the experimental, the claim about one-shot attribute-related results is being met.  \n\nCons:\n\nWhile the authors aim to address a challenging and novel task, I believe some parts need more clarification (even after considering the supplementary material):\n\n1. The biggest weakness is that the proposed method has limited novelty. While the authors propose a stacked pipeline to address the quality and diversity, the key contribution they made is unclear. \n\na. The z+/w/w+/s space analysis and adaption has been widely conducted in the latest works [r1, r2, r3]. What are the differences between the proposed adaptor and these prior works? Why the proposed adaptor would like to perform better?\n\nb. Related to the above, the attribute classifier has been used in StyleFlow [r2]. Why the proposed one is better? In addition, if I understand correctly, the attribute classifier only judges the output is real or fake, instead of predicting attribute labels, because some examples in Figures 2 and 3 should not have corresponding labels. If this classifier just outputs real or fake labels, why not just fine-tuning the final layer of the original discriminator?\n\nc. I cannot buy the novelty of reusing truncation trick for diversity-constraint strategy. As mentioned by the authors, this trick is a normal one in the current generation code. The authors did not provide a new direction to sell this strategy. \n\n2. The impressive results in Figures 4 and 5 are interesting, but the analysis is not clear enough. It would like to be better to visualize the learning representation after the adaptor as in AgileGAN [r3].\n\na.  The results in the final two rows of Figure 4 are quite interesting. I guess the learned w space has been pushed to a narrow space (the final one will be more narrow). If the authors can visualize the learning representation distribution, it will be clearer to demonstrate such mapping in the representation domain. \n\nb. A similar situation is in Figure 5.  It is interesting to use the one-shot pipeline for style translation. As the pre-trained G and D have not been updated, I guess the learned w space has been pushed into a different distribution to the original w space. How to visualize such change and then demonstrate the swap of learning representation would be significant. \n\n[r1] Wu, Z., Lischinski, D., & Shechtman, E. (2021). Stylespace analysis: Disentangled controls for stylegan image generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 12863-12872).\n[r2] Abdal, R., Zhu, P., Mitra, N. J., & Wonka, P. (2021). Styleflow: Attribute-conditioned exploration of stylegan-generated images using conditional continuous normalizing flows. ACM Transactions on Graphics (TOG), 40(3), 1-21.\n[r3] Song, G., Luo, L., Liu, J., Ma, W. C., Lai, C., Zheng, C., & Cham, T. J. (2021). AgileGAN: stylizing portraits by inversion-consistent transfer learning. ACM Transactions on Graphics (TOG), 40(4), 1-13. My preliminary rating for this submission is marginal reject. While I like this novel task that aims to generate diverse images with high quality, the key novelty and contribution are unclear explained to the prior related works. In addition, interesting experimental results are provided, but they are not well analyzed in the representation domain. The realistically visual results cannot demonstrate the contribution perfectly. "], "review_score_variance": 4.222222222222222, "summary": "This work was the subject of significant back and forth (between authors and reviewers, but also between reviewers & myself) due to the wide range of opinions. Two of the reviewers have found this work below the bar: they have provided multiple reasonings that I would rather not repeat here. The third reviewer found this work more compelling and argued for its acceptance. My attempts at reaching a consensus have yielding the following conclusions:\n\n  * There's agreement that one-shot generation is indeed a challenging task\n  * Some of the results are indeed impressive, but many results are not compelling.\n  * The rebuttal addressed some of the concerns (e.g. visualization of latents), but some issues are unaddressed (e.g. more motivation, explanation of why the proposed method works better)\n  * One of the reviewers has argued rather forcefully that the work doesn't quite do domain adaptation in the typically understood sense. Moving beyond definitions of domain adaptation, the same reviewer was not very convinced by the quality of the results themselves.\n  * The reviewer most positive about this work agrees that this work only explores a limited form of domain transfer. They argued that some of the potential applications of this work do make the submission interesting. \n\nFundamentally, the discussion did not necessarily resolve the differences in opinion one way or another. Ultimately, all 3 reviewers believe that it would fine if this work was not accepted to ICLR at this time, despite some of the interesting results and promise. Given the discussion and this mildest consensus, I am inclined to recommend rejection too. I do think there's a substantial amount of constructive feedback in the reviews that would make a subsequent revision of this work quite a bit better.", "paper_id": "iclr_2022_swbAS4OpXW", "label": "train", "paper_acceptance": "Reject"}
{"source_documents": ["Graph Neural Networks (GNNs) are a powerful representational tool for solving problems on graph-structured inputs. In almost all cases so far, however, they have been applied to directly recovering a final solution from raw inputs, without explicit guidance on how to structure their problem-solving. Here, instead, we focus on learning in the space of algorithms: we train several state-of-the-art GNN architectures to imitate individual steps of classical graph algorithms, parallel (breadth-first search, Bellman-Ford) as well as sequential (Prim's algorithm). As graph algorithms usually rely on making discrete decisions within neighbourhoods, we hypothesise that maximisation-based message passing neural networks are best-suited for such objectives, and validate this claim empirically. We also demonstrate how learning in the space of algorithms can yield new opportunities for positive transfer between tasks---showing how learning a shortest-path algorithm can be substantially improved when simultaneously learning a reachability algorithm.", "This paper investigates using GNNs to learn graph algorithms. It proposes a model which consists of algorithm-dependent encoder and decoder, and algorithm-independent processor. \nAuthors try to learn BFS, Bellman-Ford and Prim algorithms on various types of random graphs. \nExperimental results suggest that MPNN with max aggregator outperforms other variants significantly in terms of generalization. \n\nOverall, this paper presents a solid contribution on learning graph algorithms using GNNs, despite the caveat for some clarifications on the model and experiments. \nGiven these clarifications in an author response, I would be willing to increase the score.\n\nPros:\n\n1, Although it is less satisfying to learn to solve graph problems where polynomial-time algorithms exist, I still appreciate the contribution of the paper, especially the algorithm-independent processor. It is one step forward to models which could learn meta-level representation of algorithms. The findings of this paper may suggest that different types of operators used in the GNN may have different inductive bias in learning different types of algorithms.\n\n2, Experimental comparisons are adequate and convincing. The detailed analysis of empirical results also provide good explanation.\n\nCons & Suggestions:\n\n1, Given the dynamic programming nature of the most of tasks, it is not that surprising that MPNN with max aggregation could solve them pretty well. What surprises me is that MPNN-mean / MPNN-sum could not generalize well (i.e., performance drops significantly on 50 and 100 nodes settings) on the reachability task. In my opinion, the reachability task could be easily handled by any diffusion/propagation based models including, e.g., MPNN, GCN, GAT, as long as the information is spread over the input graph. Could you explain why does this happen? \n\n2, Training details are sparse. If I understood correctly, the training of various GNNs is done by teacher forcing such that each step some supervised information collected from the underlying graph algorithms is provided to GNNs. However, it is not clear that what supervised information is exactly provided under each graph algorithm. It would be great to have a table to summarize what the input and supervised output information is for each graph algorithm. \n\n3, The processor is trained to learn multiple graph algorithms simultaneously. A natural question to ask is how does the performance change when you train the processor with different combinations of algorithms? What is the impact of correlations between different graph algorithms? Did you explore learning with graph algorithms following some sequential schedule, e.g., curriculum learning?\n\n4, It would be great to provide more results on larger size graphs, e.g., trained on 20 nodes but test on 1000 or more nodes. I saw one set of experiments trained on 100 and test 1000 nodes in the appendix. More results along this line would make the paper more convincing on the generalization.\n\n5, It would be great to discuss [1] as it also studies how to use GNNs to learn a special class of graph algorithms, i.e., probabilistic inference algorithms on graphs. It is shown in [1] that belief propagation algorithm could be seen as a specially constructed GNN. Interestingly, some well-known graph algorithms could be re-formulated as probabilistic inference algorithms, e.g., graph-cut could be reformulated as max-product [2].\n\n[1] Yoon, K., Liao, R., Xiong, Y., Zhang, L., Fetaya, E., Urtasun, R., Zemel, R. and Pitkow, X., 2018. Inference in probabilistic graphical models by graph neural networks. arXiv preprint arXiv:1803.07710.\n[2] Tarlow, D., Givoni, I.E., Zemel, R.S. and Frey, B.J., 2011, July. Graph Cuts is a Max-Product Algorithm. In UAI (pp. 671-680).\n\n======================================================================================================\n\nThanks for the thorough response! It resolves my concerns. I improved my score.\n", "We hope that the revisions we have made to the paper have properly addressed the comments of the reviewers on our work - and that its overall contribution, quality and clarity is now improved! We would like to thank everyone once again for their thoughtful comments on our paper.\n\nWe provide a summary of the changes made to the paper:\n\n* We have now provided additional experiments, testing the MPNN-max model on graphs of 500, 1000 and 1500 nodes (after training on graphs of 20 nodes). They may be found in Table 4. We find that the generalisation properties of MPNN-max carry over to these graph sizes and further solidify our contribution in terms of scale.\n\n*  We provide results for a âcurriculum learningâ strategy, in which a network is first pre-trained on breadth-first search (until reaching perfect validation accuracy), followed by learning to imitate Bellman-Ford. These results are added in Tables 2 and 3 as an additional row, and demonstrate that such a sequential learning strategy performs worse than the simultaneous one in this case -- although it still provides benefits over the no-algo variant.\n\n* To aid clarity, we summarise all inputs and supervised signals of the algorithms considered here, within Table 7 in Appendix A;\n\n* We confirm that, when learnt in isolation, all of the GNN architectures considered are capable of strongly generalising on the reachability task, and have now made that point clear in the paper (see Footnote 2 on page 6).\n\n* In Section 1, we now cite the related work of Yoon et al.\n\n* We have increased the size of the plots and modified the colour of the MPNN-sum curve in Figure 3, hoping that this will further aid clarity.", "Thank you very much for the kind review, and we are very glad you enjoyed the paper!\n\nAs recommended, we have now provided additional experiments, testing the MPNN-max model on graphs of 500, 1000 and 1500 nodes (after training on graphs of 20 nodes). They may be found in Table 4. We find that the generalisation properties of MPNN-max carry over to these graph sizes and further solidify our contribution in terms of scale. We agree that graphs of these sizes donât really pose any problems for classical algorithms, and instead focus on the multi-task and transfer learning aspect, which could enable us to tackle more challenging problems in the future.\n\nWe have also increased the size of the plots and modified the colour of the MPNN-sum curve in Figure 3, hoping that this will further aid clarity.", "Thank you for the very careful review and kind words about our contributions.\n\nWe provide responses to your comments in turn, hoping that they have adequately addressed your concerns. We are happy to discuss further on any of these points, of course!\n\n1. Regarding the performance of MPNN-mean/sum on reachability, it should be highlighted that the results are presented in the *multi-task* setup, where reachability has to be learnt simultaneously with shortest-paths. In this case, the summation architecture suffers from exploding messages (exemplified by the NaN values on MSE), while the averaging architecture ends up allocating most of its capacity to learning Bellman-Ford. We confirm that, when learnt in isolation, all of these architectures are capable of strongly generalising on reachability, and have now made that point clear in the paper (see Footnote 2 on page 6).\n\n2. Thank you for the comment regarding the clarity of the experimental setup! We fully agree, and now provide a table summarising all the inputs and supervision signals used -- see Table 7 in Appendix A. We also refer to this Appendix properly within Section 3.\n\n3. Initially, we havenât experimented with a sequential schedule. As per your recommendation, we provide results for a âcurriculumâ strategy, in which a network is first pre-trained on breadth-first search (until reaching perfect validation accuracy), followed by learning to imitate Bellman-Ford. These results are added in Tables 2 and 3 as an additional row, and demonstrate that such a sequential learning strategy performs worse than the simultaneous one in this case -- although it still provides benefits over the no-algo variant.\n\n4. As recommended, we have now provided additional experiments, testing the MPNN-max model on graphs of 500, 1000 and 1500 nodes (after training on graphs of 20 nodes). They may be found in Table 4. We find that the generalisation properties of MPNN-max carry over to these graph sizes and further solidify our contribution in terms of scale.\n\n5. We now directly cite reference [1] in the paper -- namely, in Section 1, where we mention other related work. Thank you for pointing this reference out to us, it is certainly relevant to our work!", "We thank the reviewer for their comments. We would like to address a number of points raised here:\n\n1. As pointed out by the review, we trained a graph neural network to execute a graph algorithm on an arbitrary graph. Our objective is to enforce an inductive bias towards âalgorithmic reasoningâ within the GNNâs update rule. This bias can be a very useful prior for e.g. discovering novel algorithms, or improving existing ones. We also experimentally demonstrate transfer between learning two different algorithms (BFS and Bellman-Ford), which directly points out the potential for one learnt algorithm executor to reinforce the predictions of another.\n\n2. Besides the transfer learning aspect, the algorithm execution task is a challenging problem in its own right, as shown in our baseline experiments (namely, many state-of-the-art GNN architectures such as GATs or MPNN variants are unable to generalise). Note that previous work has studied specific cases of these problems as well (e.g., Pointer Networks, Neural Turing Machines, etc).\n\n3. In the current version of the paper, our model is explained in one place (in Section 2), and our related work is outlined in one place (in the Introduction). Is there a specific part of the submission the reviewer would like us to move to the model description to help improve clarity of the paper?\n\n4. We have upgraded the clarity of the paper now by making substantial changes and performing additional experiments, such as:\n\n* Summarising all inputs and supervised signals of the algorithms considered here (Table 7 in Appendix A);\n* Additional related work cited throughout the paper;\n* Ablation studies, such as testing the generalisation of MPNN-max on larger graphs and assessing the benefits of a âcurriculum learningâ strategy.\n\n5. Regarding executing two algorithms simultaneously, this is done by, at each step, concatenating the relevant x(t) and y(t) together as inputs/targets for the network. We mention this at the bottom of page 4, right after introducing the term âsimultaneouslyâ.\n\nWe are happy to discuss further on any of these points!", "The paper suggests training neural network to imitate graph algorithms in a more fine-grained way than done before: by learning primitives and subroutines rather than the final output. The paper makes quite a strong case for the advantage of this approach, citing the fact that many graph algorithms share subroutines, which could simplify learning and support joint training and transfer learning. The experiments are detailed an elaborate.\n\nThe main weakness I see is the size of the graphs in the experiments. They are mainly limited to graphs with up to 100 nodes, with additional brief results for 1000 nodes in the appendix. These sizes are so small so as to raise doubts if the reported accuracy results would indeed scale, or whether they might require a significantly heavier network architecture. Moreover graphs of this size do not actually pose any difficulty for classic graph algorithms, that would justify invoking such heavy cannons like neural networks.\n\nNonetheless, I find this to be a conceptually strong paper with interesting ideas and thorough experiments (which in the least establish proof of concept; I am willing to accept leaving the issue of handling larger graphs to future work). I think the paper should be accepted.\n\nOther comments:\n1. The legend font in Figure 3 is to small (I am positively unable to read it off page) and the MPNN-sum plot is invisible in print. I hope the authors can reproduce the plots more clearly.\n2. I don't quite see the point in Appendix A, brief as it is. It apparently just states the fact that if two random variables share mutual information then knowing one reduces the entropy of the other. This is rather obvious both intuitively and formally.", "Summary:\n\nThis paper uses message-passing neural networks to learn to predict which\nnodes to update with what metadata. Experiments are shown that the algorithm\ncan learn to visit nodes in the same order as a breadth-first-search as well\nas the Bellman-Ford shortest-path algorithm.\n\nFeedback:\n\nI'm not sure what problem this paper is trying to solve. We are provided\nthe graph and graph algorithm as input to the network so that we can\nlearn what the algorithm will do next? I'm not sure why this is a problem?\nAre these algorithms badly written and need to be improved? Do we want to\nlearn how to execute graph algorithms in general?\n\nI found the paper fairly hard to read and follow. I wish the\nmodel were described all in one place and the related work also\nin just one place. I think this paper would be greatly improved\nby more work on explaining the motivation as well as more\nclearly. I also feel the paper could be much stronger if it was grounded\nin an existing problem others in the community might have.\n\nClarifications:\n\nIn page 4, I don't know what it means to execute these two algorithms\nsimulatenously?"], "review_score_variance": 10.888888888888891, "summary": "It seems to be an interesting contribution to the area. I suggest acceptance.", "paper_id": "iclr_2020_SkgKO0EtvS", "label": "train", "paper_acceptance": "accept-poster"}
{"source_documents": ["State-of-the-art quantization methods can compress deep neural networks down to 4 bits without losing accuracy. However, when it comes to 2 bits, the performance drop is still noticeable. One problem in these methods is that they assign equal bit rate to quantize weights and activations in all layers, which is not reasonable in the case of high rate compression (such as 2-bit quantization), as some of layers in deep neural networks are sensitive to quantization and performing coarse quantization on these layers can hurt the accuracy. In this paper, we address an important problem of how to optimize the bit allocation of weights and activations for deep CNNs compression. We first explore the additivity of output error caused by quantization and find that additivity property holds for deep neural networks which are continuously differentiable in the layers. Based on this observation, we formulate the optimal bit allocation problem of weights and activations in a joint framework and propose a very efficient method to solve the optimization problem via Lagrangian Formulation. Our method obtains excellent results on deep neural networks. It can compress deep CNN ResNet-50 down to 2 bits with only 0.7% accuracy loss. To the best our knowledge, this is the first paper that reports 2-bit results on deep CNNs without hurting the accuracy.", "I appreciate the authors' responses to my questions. I can see that the paper now considers the efficiency issue of the mixed-precision feedforward more fairly. ", "\nWe thank all reviewers for their careful reviews, insightful comments and feedback on our paper. The draft has been revised accordingly. The revised draft has been uploaded. The main revisions are summarized below:\n\n-\tWe cited the ICIP paper mentioned by Reviewer 1 and discussed the differences with the ICIP paper in the related work section. We added the results of the ICIP paper in Table 1 and compared our method with the ICIP paper in the experiment section. (response to Reviewer 1)\n-\tWe added a section (section 6.1) to clarify the computational complexity of our method. We made a comparison of the amount of arithmetic operations to the equally quantized method in section 6.1. (response to Reviewer 2)\n-\tThe optimization method is elaborated in section 4.2. A figure is also added to show an example of the optimization method (Fig. 3). (response to Reviewer 2)\n-\tWe discussed the relationship between the variances and the bitrates in the supplementary material. (response to Reviewer 3)\n\nHere we summarize the main differences with the ICIP paper mentioned by Reviewer 1:\n\n-\tOur ICLR submission shows the additivity property of the output error and provides a mathematical derivation for the additivity property. \n-\tOur quantization framework differs from the ICIP paper in two-fold. First, we adopt a dead zone to the quantization function of weights. Second, we provide a scheme to support the retraining for both quantized weights and activations.\n-\tOur work demonstrates that the optimal bit allocation solved by our method has very positive impacts on inference speed, which has been verified by the hardware simulation experiments.\n-\tBy combining the dead-zone quantization and STE based retraining with the optimal bit allocation strategy, our quantization framework achieves state-of-the-art results. To the best of our knowledge, our work is the first to report 2-bit results on deep neural network ResNet-50 without hurting the accuracy on ImageNet.\n\nBest,\nAuthors\n", "We revised the draft based on the comments:\n-\tWe added section 6.1 to clarify the computational complexity of our method. \n-\tWe made a comparison of the amount of arithmetic operations to the equally quantized method in section 6.1. \n-\tThe optimization method is elaborated in section 4.2. A figure is also added to show an example of the optimization method (Fig. 3). \nThe updated version has been uploaded.\n", "We revised the draft based on the comments: \n-\tWe cited the ICIP paper and discussed the differences with the ICIP paper in the related work section. \n-\tWe added the results of the ICIP paper in Table 1 and compared our method with the ICIP paper in the experiment section. \nThe updated version has been uploaded. \n", "\nThank you for the careful reviews and for the comments. We answer your questions below.\n\nQ1: Do the authors mean to conclude that layers with large number of weights hold a lot of redundancy and don't have a significant impact on the overall accuracy of the model? This needs to be clarified further.\n\nWe empirically found that the layers having a larger number of weights receive lower bitrates (and vice-versa). The reason could be the values of the variances of the layers. According to the classical Lagrangian rate-distortion formulation, the optimal bit allocation follows a rule,\n\nRate = G( - 1 / sigma^2 ), \n\nwhere G(.) is a strictly increasing function and sigma^2 is the variance of the variables. Based on the rule above, the layers with larger variances receive larger bitrates (and vice-versa). \n\nWe calculated the variances of layers for two deep networks ResNet-50 and MobileNet-v1 (see Table 1 and Table 2 below). The results show that the layers with a smaller number of weights typically have a larger variance, and thus these layers receive larger bitrates. We added a paragraph and a figure in the supplementary material to discuss the relationship between variances and bitrates. The draft has been updated accordingly. Thank you for this good question.\n\nTable 1 â Variances of Weights across Layers on ResNet-50\n+-------------------------+----------+----------+----------+-----------+------------+\n|      Layer Index      |      5     |      15   |     25   |      35     |      45     |\n+-------------------------+----------+----------+----------+-----------+------------+\n| #Weights (10^5)   |  0.16   |    1.47  |   2.62  |    2.62    |    23.6    |\n+-------------------------+----------+----------+----------+-----------+------------+\n|    Variance (10^3) |  1.33    |    0.59  |   0.51   |    0.37   |    0.11    |   \n+-------------------------+----------+----------+----------+-----------+------------+\n|        Bitrate             |    4.2    |    3.5   |     3.3   |     2.8    |     1.2      |\n+-------------------------+----------+----------+----------+-----------+------------+    \n\nTable 2 â Variances of Weights across Layers on MobileNet-v1\n+-------------------------+----------+----------+----------+-----------+------------+\n|      Layer Index      |      2     |      8     |    14     |     20     |      26     |\n+-------------------------+--------- +----------+----------+-----------+------------+\n| #Weights (10^7)   |   0.29  |   1.15   |   4.61   |   4.61    |     9.22   |\n+-------------------------+----------+----------+----------+-----------+------------+\n|      Variance            |   7.83  |    0.49  |  0.54   |   0.23    |    0.07     |\n+-------------------------+----------+----------+----------+-----------+------------+\n|       Bitrate              |   7.9    |   5.38   |   5.86   |  5.29     |    4.1       |\n+-------------------------+----------+----------+----------+-----------+------------+\n", "Thank you for your interest in this paper and for your comments. Below we answer your questions.\n\n\nQ1: Uniformity of quantization\n\nDead zone quantization can also support integer arithmetic if we set the values of the first negative and the first positive quantization centroids as k * delta, where k is an integer value and delta is the length of quantization interval. By doing this, every quantization centroid becomes an integral multiple of delta and we can use the integral multiplier for integer arithmetic.\n\nFor example, if we set k = 2, the corresponding quantization centroids are:\n\n ... , -n * delta , ... , -3 * delta , -2 * delta , 0 , 2 * delta , 3 * delta , ... , n * delta , ...\n\nand the integral multipliers \"... , -n , ... , -3 , -2 , 0 , 2 , 3 , ... , n , ...\" can be used for integer arithmetic.\n\nWe will introduce how to apply integer arithmetic with dead zone quantization and update the paper accordingly. Thank you for this good point.\n\n\nQ2: Computational complexity vs. memory requirements\n\nWe calculated the amount of arithmetic operations of our method required to perform a single inference on ResNet-50, and did a comparison with the equally quantized method (please see our response to Q1 of Reviewer #2). The results show that our method has fewer operations than the equally quantized method at 4 bits and 6 bits. While, at 2 bits, our method has 1.4x more operations than the equally quantized method.  \n\nIn practice, the inference time on hardware devices is constrained by both compute and memory access. The Pareto-optimal bit allocation tends to allocate fewer bits per weight for layers that have a lot of weights. As a result, it helps to reduce the corresponding memory-access time which in turn reduces compute idle time and improves the overall inference speed. The simulation results on the Google TPU platform show that our method is 1.5x faster than the equally quantize method on ResNet-50 at 2 bits. Please see our response to Reviewer #2 for the details. \n", "\nQ2: I wish the actual optimization part briefly mentioned in section 4.2 could be elaborated more. It is a crucial part but somewhat understated. \n \nThank you for this suggestion. We will elaborate section 4.2 to show the optimization steps in more details. We will respond to this comment again once we finish the revision.\n \n\nQ3: I also wonder whatâs the effect or limitation of using MSE for this optimization, where cross-entropy is a more suitable choice. I know that the objective function in eq 5 is just to find the best combination of bit allocations per layer, but still, the error space might not be the best for this classification problem. \n \nWe agree that MSE does not directly optimize accuracy and thus may not be the best choice for classification problem. The reason we choose MSE as the measurement of the quantization impact is mainly because it ensures that the additivity property of output error holds, from both empirical observations and mathematical derivations (as shown in the draft), and the additivity property is essential for Pareto condition. Besides, optimization with MSE not only supports classification tasks but also can be applied to any other tasks like object detection and semantic segmentation where regression loss is also required.\n\n+-----------------------+-----------+----------+-----------+-----------+\n |            size          |  4 bits   | 6 bits  |  8 bits   | 10 bits  | \n+-----------------------+-----------+----------+-----------+-----------+ \n |  cross-entropy  |    41.3   |  43.6    |   46.0    |   57.0    |\n+-----------------------+-----------+----------+-----------+-----------+\n |   MSE                  |   63.6    |   70.8   |    70.9   |   70.9    |\n+-----------------------+-----------+----------+-----------+-----------+    \n\nCross-entropy is a more suitable choice for classification, but our empirical observations show that it is not compatible with the Pareto optimal bit allocation framework. The table above shows the results on MobileNet-v1 when replacing MSE in Eq. 3 with cross-entropy for optimization. One can see that there is a noticeable accuracy drop using cross-entropy in the optimization framework. We also observed that the additivity property doesnât hold anymore if we use cross-entropy as the measurement. From the mathematical point of view, it is unclear whether or not the additivity property is still valid for metrics beyond MSE, we would like to leave it for future study. Thank you for this insight.", "Thank you for the careful reviews and for the comments. We answer your questions below.\n \n\nQ1: First of all, the paper is not about 2bit quantization. It seeks an âaverageâ 2bit quantization. â¦ Is it really more efficient to do multiplication-and-addition between 2 bit weights and 5 bit input (the output of the previous activation) than between 4bit weights and 4bit input?\n\nWe did a comparison of the computational complexity of our method and the equally quantized method on ResNet-50. We calculated the number of arithmetic operations of both methods required to perform single inference.\n\nSpecifically, we define a 32-bit multiplication/addition operation as one operation. To count the number of operations of the mixed-precision computation (e.g., 3 bit weight and 5 bit input), we follow the protocol defined by MicroNet challenge (https://micronet-challenge.github.io/scoring_and_submission.html) and consider the resolution of an operation to be the maximum bit-width of the 2 operands of this operation. For example, a multiplication operation with one 3-bit and one 5-bit operand will count as 5/32 of an operation.\n \n+-------------------------+-------------------+-------------------+--------------------+\n|            size              |        2 bits       |        4 bits       |         6 bits        |\n+-------------------------+-------------------+-------------------+--------------------+\n| equally quantized|   3.6 x 10^8    |   7.2 x 10^8    |    10.8 x 10^8  |\n+-------------------------+-------------------+-------------------+--------------------+\n|     our method      |   5.1 x 10^8    |   7.0 x 10^8    |    9.4 x 10^8     |\n+-------------------------+-------------------+-------------------+--------------------+\n \nThe table above shows the amount of operations required when weights and activations are compressed to 2 bits, 4 bits and 6 bits respectively. Our unequally quantized method has less amount of operations than the equally quantized method when weights and activations are compressed to 4 bits and 6 bits on average. While, at 2 bits, our method has 1.4x more operations than the equally quantized method. \n \nOn the other hand, the amount of operations does not imply equivalent inference speed in practice, as the processing of deep networks on hardware devices is constrained by both compute and memory access. We would like to reiterate that our method is effective to reduce the memory access time and thus provide higher inference rate compared to the equally quantized method, particularly for memory-bound hardware platforms where data movements are much slower and less energy efficient than compute. This is achieved by Pareto-optimal bit allocation which tends to allocate fewer bits per weight for layers that have a lot of weights. Thus, given fixed bandwidth, more weights can be loaded from off-chip memory to on-chip memory when processing the layers with a lot of weights, which in turn reduces compute idle time and improves the overall inference rate.\n \nTo verify the point above, we simulated the inference speed on Google TPU v1 at 2 bits for both equally and unequally quantized methods with ResNet50. As existing hardware does not well support mixed-precision operations, we assume the weights and activations with unequal bit-widths are fetched from off-chip memory, then decoded to fixed 8-bit stream and fed to compute unit that supports 8-bit multiplications (e.g. TPU). The simulation results on Google TPU platform show that our method is 1.5x faster than the equally quantize method.\n\nWe will add a paragraph to clarify the computational complexity of our method and the equally quantized method. \n\n\n\n\n", "\nThank you for your reviews and for pointing out the ICIP paper. We notice that the ICIP paper was posted on IEEE Xplore website on 22 Sept, which is 3 days prior to the ICLR deadline (Sept 25). According to the ICLR 2019 reviewer guideline, âno paper will be considered prior work if it appeared on arxiv, or another online venue, less than 30 days prior to the ICLR deadlineâ. We believe that our submission meets the ICLR regulations and rules.\n\nOur ICLR submission has substantial differences with the mentioned ICIP paper including the theoretical analysis, methods and insights, and experimental results. Moreover, with the new compression framework, the ICLR submission achieves 2-bit quantization results on deep architecture ResNet-50. To our best knowledge, this is the first work that reports 2-bit results without hurting the accuracy. Below we summarize the main differences with the ICIP paper:\n\n(1) Our ICLR submission provides a mathematical derivation for the additivity property. With two reasonable assumptions, we demonstrate that the additivity property holds for any neural networks which are continuously differentiable in the layers.\n\n(2) Our quantization framework differs from the ICIP paper in two-fold. First, we adopt a dead zone to the quantization function of weights. Second, we apply the straight-through estimator (STE) to perform back-propagation on the retraining stage for both quantized weights and activations. The ICIP paper uses the simple uniform quantizer and the framework does not provide a scheme to support the retraining for quantized weights and activations. However, as we illustrated in the experiment section, dead zone and STE retraining are critical for improving the accuracy.\n\n(3) In our ICLR submission, we reveal that the pattern of Pareto-optimal bit allocation across layers has positive impacts on neural network inference rate in practice. It tends to allocate fewer bits per weight for layers that have a lot of weights, which helps to reduce memory-access time which in turn reduces compute idle time and improves the overall inference rate. We verified this point by designing hardware simulation experiments on Google TPU v1 platform. Results show that the Pareto-optimal bit allocation improves the inference rate on ResNet50 by 1.5x compared to its equal bit allocation counterpart.\n\n(4) Combined the dead-zone quantization and STE based retraining with the optimal bit allocation strategy, our quantization framework achieves state-of-the-art result on deep neural network ResNet-50 at 2 bits. To the best of our knowledge, this is the first work that reports 2-bit results without hurting the accuracy. The ICIP paper can only compress ResNet-50 down to 4 bits and the accuracy drops significantly at 2 bits.\n\nWe will change our ICLR draft accordingly, and then upload it to the review website. We would also like to answer any other questions.\n", "Very good paper that studies the error rate of low-bit quantized networks and uses Pareto condition for optimization to find the best allocation of weights over all layers of a network. The theoretical claims are strongly supported by experiments, and the experimental analysis covers state-of-the-art architectures and demonstrates competitive results. The paper in addition also analyzes the inference cost of their approach (in addition to the accuracy results), and shows positive results on ResNet and MobileNet architectures.\n\nThe paper primarily shows that the mean squared error of the final output of a quantized network has the additive property of being equal to the sum of squared errors of the outputs obtained by quantizing each layer individually. Although there is no reason why this should be case, experimental results from the authors on AlexNet and VGG-16 validate this. Based on this assumption, the authors then use a Lagrangian based constrained optimization to minimize the sum of squared errors of outputs when individual weights/activations are quantized, with the constraint being the total bit budget for weights and activations. The authors show that this can be optimized under the Pareto condition easily.\n\nThe experimental section is quite detailed and covers the popular architectures instead of toy ones. The accuracy results compared to other 2-bit and 4-bit approaches are competitive. It's also nice to see analysis of inference cost where unequal bitrate allocation performs better than other methods.\n\nThe authors show that given the constrained optimization, layers that have a large number of weights receive lower bitrates and vice-versa. While it makes sense that this would contribute to stronger inference speedup compared to methods with either equal bitrate allocation across layers or those that allocate higher bitrate to layers with large number of weights, it's not entirely clear why the optimization would produce this allocation in the first place. Do the authors mean to conclude that layers with large number of weights hold a lot of redundancy and don't have a significant impact on the overall accuracy of the model? This needs to be clarified further.", "This work nicely proposes a new theoretically-sound unequal bit allocation algorithm, which is based on the Lagrangian rate-distortion formulation. Surprisingly, the simple Lagrange multiplier on the constraints leads us to the convenient conclusion that the rate distortion curves for the weight quantization and the activation quantization have to match. Based on this conclusion, the authors claim that their search for the best bit allocation strategy is with a less complexity.\n\nI found this paper interesting and enjoyed reading it. However, I wish the paper could address some issues that are a little bit confusing to me. \n\nFirst of all, the paper is not about 2bit quantization. It seeks an âaverageâ 2bit quantization. It means that some weights in some layers can be quantized with higher or lower bits per weight.  Same story goes on for the activation quantization. I donât exactly know the implication of this, but it seems that the hardware implementation of a convolution layer could be either too complicated to benefit from this quantization scheme, or doesnât really improve the efficiency of, say 4bit quantization for all layers. Is it really more efficient to do multiplication-and-addition between 2 bit weights and 5 bit input (the output of the previous activation) than between 4bit weights and 4bit input? Iâm not a hardware person, but this part needs to be clearly addressed. Storage-wise, lowering the bitrate might be a clear benefit (I guess)\n\nI wish the actual optimization part briefly mentioned in section 4.2 could be elaborated more. It is a crucial part but somewhat understated. \n\nI also wonder whatâs the effect or limitation of using MSE for this optimization, where cross-entropy is a more suitable choice. I know that the objective function in eq 5 is just to find the best combination of bit allocations per layer, but still, the error space might not be the best for this classification problem. ", "This works presents a method for inferring the optimal bit allocation for quantization of weights and activations in CNNs. The formulation is sound and the experiments are complete. My main concern is regarding the related work and experimental validation being incomplete, as they don't mention a very recent and similar work published in ICIP19 https://ieeexplore.ieee.org/document/8803498: \"Optimizing the bit allocation for compression of weights and activations of deep neural networks\". A reference in related work as well as a comparison in experimental validation would be necessary  and the novelty of this work is rather weak given the above mentioned 2019 publication.", "Dear Authors, \nThanks for your comment. From review of your code, I cannot see the code related to your optimization section. The details regarding how you calculated the slopes and how you considered the rate constraints are missing. ", "Thanks for your interest in our work. Apologies that we didn't have enough time to clean up our code before the deadline, also, we felt it is necessary to double-check the quantized models and redo evaluations again to make sure all the results reported here are reproducible.\n\nFinally, we have uploaded the evaluation code and quantized models to the dropbox link provided earlier. Kindly let us know if there is any question regarding the code.", "Hi,\nAs of close to 56 hours after submission deadline , no code is present in the provided dropbox link. It is not fair to provide a placeholder link for code submissions (which impact the review process) and submit code taking considerable buffer time after submission deadline.\n", "Nice work. The result you have achieved are really spectacular. \nIn the simulations you assume that all calculations are performed in full precision available to the accelerator (8 or 16 bits), while for custom hardware it would make more sense to use lower-precision arithmetic, which can provide significant speedups. However, I have two concerns regarding application of this approach to the proposed method which I hope you can address:\n\n1. Uniformity of quantization.\nThe main advantage of uniform quantization is the fact it is isomorphic, which allows to apply integer arithmetic to operate over bin indices rather than values themselves. If I understand correctly, dead zone quantization, unfortunately, lacks this property, meaning it would require some more complicated implementation to perform matrix multiplication, for example, using lookup tables. \nPossibly it can be done by taking account of beta separately, but it's not 100% clear for me and might introduce additional computational overhead. \n2. Computational complexity vs. memory requirements.\nMost of work you compare to, do not perform additional compression except quantization. That means, the number of bits provided by those works applies both to computational complexity and memory requirements. On the other hand, since your work performs additional compression of the weights and activation, in your case those numbers are not equal anymore. From my understanding, provided numbers are the average amount of storage required for one value (of either weights or activations). That would probably mean that amount of computation required for the network would not be equivalent to an equally quantized two-bit network. \nCould you provide some number regarding computational requirements of inference for your method (for example amount of bit-operations required for single inference)?"], "review_score_variance": 8.666666666666666, "summary": "This works presents a method for inferring the optimal bit allocation for quantization of weights and activations in CNNs. The formulation is sound and the experiments are complete. However, the main concern is that the paper is very similar to a recent work by the authors, which is not cited.", "paper_id": "iclr_2020_H1eKT1SFvH", "label": "train", "paper_acceptance": "reject"}
{"source_documents": ["Out-of-distribution (OOD) detection and lossless compression constitute two problems that can be solved by the training of probabilistic models on a first dataset with subsequent likelihood evaluation on a second dataset, where data distributions differ. By defining the generalization of probabilistic models in terms of likelihood we show that, in the case of image models, the OOD generalization ability is dominated by local features. This motivates our proposal of a Local Autoregressive model that exclusively models local image features towards improving OOD performance. We apply the proposed model to OOD detection tasks and achieve state-of-the-art unsupervised OOD detection performance without the introduction of additional data. Additionally, we employ our model to build a new lossless image compressor: NeLLoC (Neural Local Lossless Compressor) and report state-of-the-art compression rates and model size.\n", "The paper discussed the counterintuitive phenomenon in OOD detection using generative models, and proposed a new method called non-local feature density which fixed the issue and achieved the SOTA performance, because non-local features are shown to contain more semantic information. Further, the authors proposed an image compressor method, NeLLoC, based on the local features, because local features are shown to constitute a domain prior for all images so that NeLLoC is more generalizable to OOD images.   - Originality: the authors provides a new method for fixing the issue of higher likelihood of OOD inputs in the generative model based OOD detection methods. The general idea of the proposed method is similar to the previous methods: the full generative models include both local (non-semantic) and non-local features (semantic). Local image features appear largely common across the real-world image manifold and can be treated as a domain-prior;  only non-local features which typically contain semantic image information, are useful for OOD detection. So the designed OOD score is the unnormalized likelihood of non-local features, i.e. p(x|full model)/p(x|local model).  \nCompared with the existing likelihood ratio methods [35] and [38,39], the proposed method is more direct to address the issue of common local features dominating the likelihood. But the proposed method seems to be specific to the PixelCNN model architecture. I wonder if the method can be generalized to other generative models.\n\n- Quality: the paper is well written, and the results are clearly presented. \n\n- Clarity: It would be great if the algorithm for NeLLoC can be presented, describing the exact computational steps for compression or decompression.\n\n- Significance: The proposed method is specifically designed based on the PixelCNN model. It would be great if the method can be generally applied to other types of generative models. \n\n- Minor comments:\n- Figure 3 (a) shows a slight overlap between the IND and OOD distributions, but Table 3 shows the AUROC for the same experiment is 1.00.\n- Typo: eq(3), k->d\n\n\n*** Update: Thank the authors for your responses. It is great that the framework can be applied to other autoregressive models such as Transformer. I wonder if Transformer model can achieve even better performance. After reading other reviews and responses, I decided to keep my score. *** The authors adequately addressed the limitations and potential negative societal impact of their work.", " # Running time performance\nMultiple reviewers raise questions regarding the method runtimes. We highlight that compression and decompression speed is dominated by implementation language choice (eg. C++ is much faster than python), coder choice (rANS is faster than AC), and other engineering tricks. We actively select to only compare computational complexity in our manuscript, which we consider a fair comparison of different models. \n\nIn the following section, we give a demonstration of computational performance c.f. another VAE based compression method: HiLLoC. We briefly highlight key differences here:\n- NeLLoC:  PyTorch implementation with decimal AC coder, the encoding and decoding is autoregressive;\n- HiLLoC [1]: JAX implementation with rANS coder, the encoding and decoding is fully parallelized.  \n\nWe note that comparisons are not entirely fair, yet duly demonstrate the competetive performance of our method.\n\n## Demostration\n\nThe code of all the comparisons can be found at this anonymous link: https://anonymous.4open.science/r/NeLLoC-AC-B4FE .\n\nThe model structure of NeLLoC is a local PixelCNN with one CNN layer followed by two 1x1 conv nets (0 ResNet). We use a discretized logistic-uniform mixture distribution as emission distribution. The model size is only *105 KB* (size of PyTorch .pt file).\n\n### Performance of NeLLoC on CPU (MacBook Air 2020, M1 chip)\nHere we list compression performance. All experiments are tested using a single CPU (M1 chip, MacBook Air 2020). See demo.ipynb file for details.\n\n| NeLLoC   (105 KB)     |    SVHN        | CIFAR  |\n| ------------- |:-------------:| -----:|\n| BPD      | 2.38 | 3.64 |\n| Compression time (s)     | 0.376      |   0.434 |\n| Decompression time (s)      | 0.401      |  0.471 |\n\n### Comparison to HiLLoCon CPU (Razor Blade 15, i7-10750H)\nWe do not manage to run HiLLoC (JAX implementation) on the MacBook Air M1 chip. Alternatively, we run both models on a Razor Blade 15 with CPU i7-10750H. We test two models for compressing a single image (see the file hilloc_comparisons for details).\n\n\n| Method |    BPD  |loading time (s) | Compression time (s)| Decompression time (s) | CPU memory usage |\n| ------------- |:-------------:| -----:| -----:|-----:|-----:|\n| NeLLoC      | 3.99 | 0.0013| 0.71| 0.82|  0.126 MB|\n| HiLLoC     | 4.0  |0.682    |   5.21 | 0.35 |  317.0 MB |\n\nWe observe that NeLLoC (with decimal arithmetic coding) is slightly slower than HiLLoC (with rANS) in decompression, but much faster for compression and loading time. We also find the CPU memory cost is negligible to run NeLLoC. This entails that our approach is much less demanding for the device and therefore more applicable in practice. We also noticed that the NeLLoC can be further accelerated by using a faster coder (like integer AC or rANS), we leave that for future work.\n\n## Significance \n\nA major criticism of deep generative-based compression methods is that they need huge computational resources (e.g. modern GPU), which restricts the practicability of such methods (comparing to, e.g.  PNG or FLIF). However, we show that our method can easily run on a CPU with negligible CPU memory cost (so massive images can be parallelized for compression or decompression, we leave to the future work). This provides evidence, for the first time, that computation need not be a limiting factor for learning-based lossless compression. We believe with a better implementation (C++, a faster coder like rANS, or other engineering improvements), NeLLoC represents a powerful candidate towards the replacement of traditional image compression methods.\n\nAdditionally, our paper shows that by only modelling local features, NeLLoC can exhibit better generalization ability in comparison with other global generative model-based methods. This suggests that if the goal is universal-purpose lossless compression, we should focus on local models rather than traditional global generative models.\n\n## Reference\n[1] Townsend, James, et al. \"Hilloc: Lossless image compression with hierarchical latent variable models.\" arXiv preprint arXiv:1912.09953 (2019).", " We are encouraged by the fact that all reviewers acknowledge our ***lossless compression contributions***. We here highlight our additional contributions and novelty in the task of OOD detection to further address the comments of reviewer XCL4.\n\n1. We propose a novel path to verifying the recently proposed hypotheses: ``likelihood is dominated by local features''. We evaluate the local likelihood using a local model such that the dominant effects can be directly observed, for the first time, in terms of the likelihood (BPD). In comparison to previous verification attempts [1-2], our method offers a principled approach (likelihood comparison).\n\n2. Based on our verification, we propose a new model for OOD detection -- a product of experts that enables OOD detection scoring and additionally allows for a likelihood interpretation: the likelihood of a semantic (non-local) model. We observe that our principled method achieves state-of-the-art results. We are not aware of any other OOD detection methods using a product of experts model or that afford a score possessing a semantic likelihood interpretation.\n\n3.  We proposed the local auto-regressive model as a building block (the local expert) of the product-of-experts model. The proposed local model has been further applied to the lossless compression task.\n\n4. We illustrate an unconventional connection between OOD detection and lossless compression by using the concept of generalization. We believe the connection we highlight to be of both interest and value to the community and has the potential to inspire further work towards linking these largely independent research fields.\n\nIn summary, our contribution to the OOD detection task is both novel and significant, enabled by our simple and yet principled methodology. \n\n### Reference\n[1] Understanding anomaly detection with deep invertible networks through hierarchies of distributions and features. Schirrmeister, Robin Tibor, et al.\n\n[2] Why normalizing flows fail to detect out-of-distribution data. Kirichenko et al.", " We thank the reviewer for their frequent communication and discussion, it is appreciated and helpful. We are encouraged by the acknowledgment of our lossless compression contributions. Towards addressing the final remaining novelty concerns, regarding our OOD contributions, we highlight and restate the significance of these parts at the start of the rebuttal and would draw the reviewer's attention to this summary for their consideration.\n", "A surprising observation in the OOD literature is that OOD detection based on density estimation fails on some image datasets since the learned density tends to be higher on OOD data. A hypothesis for this phenomenon is that the likelihood is dominated by the local features of the image, resulting in the high-level features being ignored. Motivated by this observation, this paper proposes a model that learns local features of images. This model is used for two different applications: (1) by combining it with a full density estimation model, it gives a better OOD detection method, achieving state-of-the art performance (2) by pairing the model with the artihmetic coding algorithm, it gives a dataset compression method that achieves state-of-the-art compression rates on in- or out-of-distribution datasets.  Both the ideas of utilizing the problematic and puzzling phenomenon of failures of density-based OOD detectors for a different approach (compression) and likelihood-ratio of the full and local model are novel and valuable. The reported results are impressive, making this method a promising approach for both these tasks. In the compression task, being able to achieve such results with way smaller models is also impressive.\n\nQuestions/comments:\n\n- I am wondering how the runtime of different methods compare. The paper does comment on how the runtime of their proposed method scales and regarding its parallelizability, but an additional table of results showing the exact time for compression/decompression is useful.\n\n- Why are many entries in table 3 missing? (although, they are irrelevant for all but the last column, since the AUROC of the proposed method 1)\n\n---\nPost-author response update: I appreciate authors taking the time to respond and provide table of run-times. I have read other reviews and responses and decided to keep my score the same. I cannot think of limitations beyond what is mentioned in the paper.", "Summary: This paper study on applying generative models on unsupervised out-of-distribution detection. Authors hypothesize that local features common to both in-distribution and out-of-distribution data dominate the likelihood of generative models. The authors show evidence of the hypothesis via comparing the fully autoregressive modelâs likelihood and autoregressive model with local dependencies. Motivated by the results, the authors propose a ratio between the likelihood of model trained with full-dependencies and the likelihood of model trained with local dependencies. The authors show that the proposed metric outperforms conventional generative-model-based methods on CIFAR-10 and FashionMNIST domains. Finally, the authors apply local autoregressive models on universal lossless compression. The proposed compression scheme outperforms conventional methods.\n  UPDATE : \nI acknowledge that I have read the author response as well as the other reviews.\nAlthough authors replied my concerns on the novelty, I still believe the main intuition of the paper, \"directly model the in-distribution dataset, using only local feature information\" is straighforward application from the idea of previous works. \nDue to the previous reasoning, I insist deleting section 3.2 and Figure 1. \nHowever, I understand the virtue of the method on unsupervised novelty detection, which doesn't need specific augmentations.\nFurthermore, I appreciate the clarifications on lossless compression.\nTherefore, I am changing my score to 5 and confidence to 4.\n\n=========================\n\nUPDATE (2):\n\nWhile this is relatively minor, I question the following points in the reply.\n\nOur major goal of OOD detection experimental work is to show that our simple and principled approach can perform comparatively strongly. We believe our experimental results strongly support this claim. At the time of submission, we are not aware of any data augmentation free, model ensemble free methods, capable of consistently outperforming our approach.\n\n=> Consider looking at the paper \"Multiscale score matching for out of distribution detection\" [https://arxiv.org/pdf/2010.13132.pdf]\n\nWhile the experiments are performed only on CIFAR-10 vs SVHN, the stark contrast on the performance reasons me whether the scheme proposed by the authors is competitive, or just a method that can be outperformed by a better generative model.\n===========================================\n\nUpdate (3)\n\nI acknowledge that I read the response from the authors as well as the other reviews. I believe that the methodology proposed in the paper shows State-of-the-art performance among augmentation-free unsupervised out-of-distribution detection methods. However, I'm still on the side that the main novelty of the paper is relatively minor. Therefore, I still stick to the current ratings. \n\n==========================================\n\nPros\n-       Application on the universal lossless compression task is interesting, while this is not the first work to apply generative models on lossless compression. Furthermore, the proposed method outperforms conventional methods\nCons \n\n-       My deepest concern on the paper is that the proposed hypothesis is not new and published in NeurIPS 2020. We can find in [1] where the authors verified that GLOW and RealNVP encode representations overfitted on local pixel correlations. I would not be surprised that the same thing happens to PixelCNN since they all failed in unsupervised anomaly detection [2] and they both exhibit an encoder-decoder-like structure. As a result, this paper sounds like an extension of existing ideas to a different generative model. \n \n-       Experiment results are limited. In table 3, the authors compare their proposed metric against diverse OOD detection methods. However, the authors compared their results against comparably weak baselines. I can find other published practices [3] [4] in unsupervised novelty detection that outperform the result. \n\nOverall, I think the main idea of this paper is nothing different from the idea of [1], and the experimental results are not compelling or convincing compared to recently published unsupervised novelty detection methods [4]. Therefore, I am leaning towards rejecting the paper.\n\nComments\n\n-       Authors should cite [1].\n\n-       I think FashionMNIST is comparably too âeasyâ dataset for verifying out-of-distribution detection performance. I suggest experimenting on diverse in-distribution datasets, e.g., TinyImageNet, CelebA, LSUN. Furthermore, there are too many blanks in the experiment result that it is hard to convince that the proposed metric improves over conventional methods. Furthermore, it would be beneficial to compare the performance of the paper against more diverse unsupervised OOD detection methods.\n\n-       I would like to see the effect of variation in local horizontal length(l) and kernel size(k) as means of OOD detection performance across different in-distribution datasets. It would be beneficial to show whether the optimized hyperparameters can be applied in other unobserved datasets.\n\n\nReferences.   \n[1] Why normalizing flows fail to detect out-of-distribution data. Polina Kirichenkoâ , Pavel Izmailovâ , Andrew Gordon Wilson\n\n[2] Do deep generative models know what they donât know? Eric Nalisnick et al.\n\n[3] Novelty detection via blurring. Sungik Choi and Sae-Young Chung\n\n[4] CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instance. Jihoon tack, Sangwoo mo, Jongheon Jeong, and Jinwoo Shin.\n While authors did not focus on explaining the potential negative social impact of their work, I believe that is not such an issue.", " We want to thank the reviewer for the comments and questions.\n\nWe are wondering have our replies addressed your concerns or make you furthur change the score of the paper? If there are any additional questions, we can try our best to solve them in the last minute. We're very much looking forward to hearing your further feedback on the response.\n\nBest!\n\nAuthors", "This paper proposes a new probabilistic image modeling approach based on a local autoregressive model. The local autoregressive model is implemented like the masked convolution operation in the pixelCNN model. The model is applied to two downstream tasks of OOD detection and lossless image compression. The OOD score is computed using the ratio between the likelihood from the full model versus the one from the local model. The idea is simple but shows some improvement over previous models. \n\n  [Update] I have read the author responses and comments by the other reviewers. My previous concerns about clarity and significance have been partly resolved, so I'm changing my score from 5 to 6. \n--------------------------------------------------------------------- \n\nThe main idea comes from the intuition that the local features are shared between different image datasets and dominate the generalization ability, which is interesting. \n\nIn terms of clarity, it was quite hard to follow the main idea of the paper at first, probably because it is not clearly introduced how the core model is connected to the two downstream tasks which seem quite unrelated. Moreover, the target tasks are explained in sections 2, 4, and 5 while the main component of the proposed approach is explained in sec 3. Also, the methods and results are mixed in the same section.  For better readability, the overall structure needs to be improved, for example, the authors may provide more introduction about the overall flow of the paper in the beginning and rearrange the following materials. \n\nIt is not clear from Table 3  if the performance gain over the previous methods for OOD detection is significant. Actually, it is not clear where the main focus of this paper is.  It might be better to choose one target task (probably OOD detection) and put more emphasis on that by investigating the performance behavior in more details. \n\nAs the author argues, time complexity is an important factor in the case of lossless compression.  I wonder how the actual encoding and decoding time compares with those of other methods.  There is no explicit discussion on the limitations or societal impact of the proposed work, but there appears to be no direct negative societal impact from this work. It will be helpful if more discussion on the limitations of the proposed method is included. ", " We thank the reviewer for their time to partake in the discussion and for further considering our replies and additional points we highlight.\n\n### Novelty of contributions in OOD detection\n\nWe would respectfully disagree with the suggestion to remove Figure 1 and section 3.2 for the following reasons:\n\n1. In line 50 we clearly state that the phenomenon: ``OOD data may have a higher likelihood than in-distribution data, for a probabilistic model'' is observed in previous work [1], and that it is not our contribution. We would however argue that the figure in question helps to make our work self-contained and increases understanding for readers who are less familiar with OOD detection. \n2.  In line 68, we cite the paper that initially explicitly posed the hypothesis: ``likelihood is dominated by local features''. We thank the reviewer for drawing [3] to our attention, where the hypothesis is implicitly raised in relation to flow models. We add this citation to our work.  \n\nCrucially, we do not attempt to argue that the stated hypothesis is part of our contribution. Alternatively, we emphasize that our contribution, stated in section 3.2, proposes a novel path to verifying, and collecting evidence in support of, such hypotheses. We evaluate the local likelihood using a local model such that the dominant effects can be directly observed, for the first time, in terms of the likelihood (BPD). In comparison to previous verification attempts [2-3], our method is more principled (using pure likelihood comprisons).\n\nThis verification method futhur enables our related contributions:\n 1. An OOD based method with a principled likelihood interpretation.\n 2. A lossless compressor with improved generalization.\n 3. An illustration of the unconventional connection between OOD detection and lossless compression.\n\nWe further emphasize that our model of the data is a ***product-of-experts model*** (Equation 5), and yet critically one expert is locally autoregressive. The score used for OOD detection is the (unnormalized) likelihood of a non-local (semantic) model. We are unaware of any such product-of-experts style approach being used previously in the OOD detection field.\n\nThese points lead us to disagree with the notion that our OOD detection method constitutes a simple extension of any previous method. \n\n### Additional analysis relating to [4]\n\nWe thank the reviewer for highlighting an additional relevant paper [4] (ICLR 2021). We note that this was published very near to the NeurIPS submission deadline (May of 2021), however, we agree the paper is pertinent and we will now include a citation in our updated work. Towards initial comparison with [4], we here compare their results with our own. Their work actually reports results for both SVHN vs CIFAR (their Table 2) and FashionMNIST vs MNIST (their Table 14, in Appendix A.6.).\n\n\n| methods/datasets          | SVHN vs CIFAR  | FashionMNIST vs MNIST|\n| ------------- | -----:|-----:|\n|    MSMA GMM      |  91.9  | 82.56|\n|MSMA Flow        |  93.4 |82.05 |\n|MSMA KD Tree |99.1| 69.32|\n|Ours| 96.9| 100|\n\nIn the work of [4], three variants of their MSMA method are proposed. We observe that our method is competitive in the SVHN vs CIFAR case (lower than their MSMA KD Tree, and improves upon the other two approaches). Further, we note our approach offers consistent and significant improvements for FashionMNIST vs MNIST. Our method is consistently reliable and we would suggest is also simple and principled in comparison to such two-stage approaches. We would ask the reviewer to comment further on these observations.\n\nFurther; the results of [4] further support our previous rebuttal argument (see point 2 in \"***Results are limited, additional datasets***\"); grey-scale images are typically -not- easier than color images for the OOD detection task. \n\n### Others\nFinally, beyond OOD detection, we also believe our lossless compression contribution to be significant. Our reported observations may influence and open one direction of AI-based compression research towards the modeling of local images (cf. global).  See e.g. our updated 'vectorized rANS implementation of NeLLoC' rebuttal discussion.\n\nWe thank the reviewer for their extended time and ask them to further take into consideration the additional points highlighted here when providing their assessment of our work. \n\n### Reference\n[1] Do deep generative models know what they donât know? Eric Nalisnick et al.\n\n[2] Understanding anomaly detection with deep invertible networks through hierarchies of distributions and features. Schirrmeister, Robin Tibor, et al. \n\n[3] Why normalizing flows fail to detect out-of-distribution data. Kirichenko et al.\n\n[4] Multiscale Score Matching for Out-of-Distribution Detection. Mahmood, Ahsan et al.", " We provide here a vectorized rANS [1] python implementation of NeLLoC  (the previously provided runtime performance of NeLLoC is based on a decimal AC coder).\nThe code can be found: https://anonymous.4open.science/r/NeLLoC-batch-1F60/README.md. Other details are the same as stated in the \"Running time performance\" message.\n\n### Results and significance\nThe results are produced on a single CPU (Razor Blade 15, i7-10750H), the time is averaged over 1000 CIFAR images. \n\n| NeLLoC   (105 KB)           | CIFAR  |\n| ------------- | -----:|\n| Compression time (s)          |   0.014 |\n| Decompression time (s)         |  0.035 |\n\nWe can see the speed is 50x faster in compression and 20x faster in decompression comparing to the decimal AC implementation, see the table in the \"Running time performance\" message. Therefore, we show that the NeLLoC can not only achieve competitive BPD comparing to the deep generative model-based compression, but also eliminates the computation bottleneck of the AI-based lossless compression models.  We believe it is a significant contribution to the lossless image compression application.  \n\n### Other contributions of our paper in addition to lossless compression.\nDespite the success in lossless compression, we want to re-emphasize other contributions in our paper which we believe are also very important both in theory and practice.\n1. Build a boundary-breaking connection between OOD detection and lossless compression by exploring the generalization of the probabilistic models. See the reply to reviewer t6SW for details.\n2. Verify the assumption that the local feature dominates the generalization by directly building a local model. We believe such a direct-modeling approach is more elegant and convincible comparing to previous methods.\n3. Provide an elegant OOD detection framework that using a novel product of the local-global experts model, and allows a principled likelihood interpretation of the score function. This elegant framework also achieves competitive performance without any data augmentation. See the reply to reviewer XCL4 for details.\n\nWe would appreciate it if the reviewers could take the time to assess our additional explanations and indicate whether this addresses the raised concerns and changes the assessment of our work. Please feel free to point out anything else that might be considered relevant.\n\n[1] Duda, Jarek. \"Asymmetric numeral systems.\" arXiv preprint arXiv:0902.0271 (2009).", " We thank the reviewer for their time and valuable feedback that improves the quality of our work. We are encouraged by the positive comments regarding our novelty and impressive result quality.\n\n1. We believe the runtime performance investigation, located at the start of our rebuttal, can help to address the reviewer's concern.\n\n2. We note that many works do not consider FashionMNIST and KMNIST pairs. This unfortunately results in a number of unavoidable blank Table column entries. We further remark that other recent OOD detection papers, e.g. published at ICML 2021 [1], only consider two experiments (FashionMNIST/MNIST and CIFAR/SVHN pairs). We consider it impractical to run all competing methods; some code is not public and as such it becomes difficult to reproduce methods faithfully. We consider our results to be significant and we offer a meaningful and direct comparison with four other methods.\n\n## Reference\n[1] Havtorn, Jakob D., et al. \"Hierarchical VAEs Know What They Don't Know.\" ICML 2021.\n\n", " We thank the reviewer for their time and valuable feedback that improves the quality of our work. We are encouraged by the positive comments relating to our method performance and also the interest in application to compression tasks.\n\n\n**Connection to prior work [1].**\nWe appreciate the pointer to relevant work cite this paper in our updated version, appropriately. In contrast to the highlighted paper, our contributions can be summarized as follows:\n\n1. We attribute the low-level feature hypothesis appropriately (we cite Schirrmeister et al. on line 68, which is very similar to [1]). We then go further; we are the first work to build an explicit model in order to verify the phenomenon that 'the likelihood is dominated by local features'.\n2. Specifically, we provide direct evidence in support of the hypothesis by observing the BPD in both local and full models. Our work goes beyond simply testing correlations between local features or visualizing intermediate network layers.\n3. The highlighted alternative work provides an explanation for why Flow fails, yet stops short of proposing an OOD detection strategy and further, does not evaluate AUROC over dataset pairs.\n4. The proposed OOD approach is (i) simple; it does not require augmentation or validation data and (ii) principled; the score has a likelihood interpretation and may be considered an un-normalized non-local likelihood. \n5. We propose the first method that employs a product of experts to model entire images for the OOD detection task.\n6. Our local (PixelCNN) model is based on an auto-regressive structure that significantly differs from an encoder-decoder structure. Our model contains no encoder or decoder (c.f. paper [1]).\n\n**Results are limited, additional datasets.**\n\n1. We note that the two papers [3], [4] that the reviewer mentions both necessitate data augmentation. Specifically [3] requires construction of blurry images. Alternatively, the design of data transformations, to facilitate contrastive learning, is necessary in [4]. Data augmentation may improve performance in some cases, however, it heavily depends on manual heuristics and design of data transformations. In stark contrast, our approach requires no data augmentation whatsoever. We thank the reviewer for the pointers and update our manuscript by adding these works to our comparisons, highlighting this key difference. \n\n2.  Greyscale datatsets (FashionMNIST/MNIST) do not constitute an easier OOD detection task in comparison to data containing color images. It is well understood that the distributions of such data support a more discrete topology and much lower dimensional manifolds. Therefore, methods that perform well on color images may certainly underperform on greyscale data. We refer the reviewer to the WAIC method in Table 3 of our paper in support of this point. \n\n3.  We actively select not to include dataset pairs such as CIFAR10/ImageNet or CIFAR10/CIFAR100, since these data contain duplicate classes (e.g. horse or ship) and thus cannot be treated as two disjoint datasets (or OOD dataset), see the discussion in Appendix A of [5].  We thus alternatively choose to conduct experiments on datasets where humans are able to reliably distinguish OOD data.  This is also the reason why recently published work (ICML 2021) [6] still only considers Fashion/MNIST and CIFAR/SVHN datasets pairs. We realize there are many bars in the KMNIST section, we will reform the table to present a neater comparison. \n\n4. Our major goal of OOD detection experimental work is to show that our simple and principled approach can perform comparatively strongly. We believe our experimental results strongly support this claim. At the time of submission, we are not aware of any data augmentation free, model ensemble free methods, capable of consistently outperforming our approach. \n\nWe would appreciate it if the reviewer could take the time to assess our clarifications, additional details and indicate whether this addresses your concerns and changes your assessment of our work. Please feel free to point out anything else you might consider relevant. \n    \n**Local horizon size**\n    \nWe thank the reviewer for this suggestion. We only conducted the ablation study in the context of the lossless compression application, see Table 5. We will update our manuscript to add the suggested ablation study in our revised version. We emphasize that the only difference between the local and full models is the horizon length. When the local horizon length increases, the local model converges to a full model. In such cases, the ratio becomes one everywhere and OOD detection will fail. This phenomenon suggests the importance of using a local model.\n\n**Other contributions**\nWe highlight that our additional contributions are also significant, e.g.\n1. Establishing a boundary-breaking connection between two different applications by exploring the model generalization. See related reply to reviewer t6SW.\n2. We use knowledge, gained from OOD detection, to inspire a new lossless compression algorithm that achieves state-of-the-art generalization with low computational requirements. See the runtime performance section at the start of our rebuttal.\n\n## Additional reference, [1]-[4] are  in the reviewer's feedback\n[5] SerrÃ , Joan, et al. \"Input complexity and out-of-distribution detection with likelihood-based generative models.\" ICLR 2020.\n\n[6] Havtorn, Jakob D., et al. \"Hierarchical VAEs Know What They Don't Know.\" ICML 2021.", " We thank the reviewer for the encouraging reviews!  We address the raised questions below.\n1. As stated in line 80; our approach, based on an autoregressive structure, may also be implemented by e.g. transformer or PixelRNN models. We think our proposed method in the current form will not easily generalize to a latent variable model (e.g. VAE) or change of variable model (like flow) since such models directly model all the information in the data. However, the hierarchy latent variable may be possible to learn local features in the shallow layers and global features in deep layers, we leave that for future exploration.\n2.  We provide source code for NeLLoC by following the anonymous link: https://anonymous.4open.science/r/NeLLoC-AC-B4FE. Our code provides clarifications for the implemented compression and decompression steps. Post-publication, we will provide fully de-anonymized and documented source code towards ease of reproducibility.\n3. As stated in the Table 3 caption; reported values are rounded to three decimal places, we, therefore, plot 1.000 when the AUROC is larger than 0.9995.\n4. We thank the reviewer for flagging typos and correct these appropriately.", " We thank the reviewer for their time and valuable feedback that improves the quality of our work. We are encouraged by the positive comment regarding our underlying main idea.\n\n**Relationship between applications and paper structure:**\n\nWe agree with the reviewer that the relation between tasks and the core model may not be immediately obvious. Our paper aims to demonstrate an elegant affinity between the considered tasks and the resulting model design. We update our manuscript towards making this connection more clear. To further address raised clarity concerns we re-emphasize hereafter the structure of the paper:\n\n1. We begin by defining OOD generalization in terms of probabilistic models.\n2. We highlight that lossless compression requires *encouragement* of generalization and, conversely, that the OOD detection task requires *discouragement* of the generalization. We thus build a connection between the considered tasks.\n3. We verify the assumption that local features are shared between different datasets and dominate the generalization. From this, we can proceed to intuitively leverage the previously noted task connection by:\n    - Exclude local features for the task of OOD detection, due to their noted generalization discouragement\n    - Include exclusively local features for lossless compression, which encourage generalization.\n4. In practice, we build a model that only models the local features; \n    - Divides the full model likelihood by the local model likelihood for the OOD detection task (equivalent to an un-normalized likelihood of a non-local or semantic model).\n    - Only uses the local model for the lossless compression task.\n\n4.  Finally, we report that the proposed method achieves competitive results for both applications.\n\n\nWe hope that this analysis addresses your concern in two ways. Firstly we consider an illustration of the fundamental connection between these two tasks to be an important motivation for our work and utilize the findings from one task to significantly benefit the other. We believe such a boundary-breaking connection to be both of interest to the community and possesses the ability to benefit both research areas. Secondly, our investigation adds novelty; such an analysis of the affinity between these tasks has, to the best of our knowledge, never been conducted and we demonstrate the efficacy of leveraging this relationship.\n\nWe would appreciate if the reviewer could take the time to assess our additional explanations and indicate whether this addresses the raised concerns and changes the assessment of our work. Please feel free to point out anything else that might be considered relevant.\n\n**Significance of Table 3**\nComparing to the existing OOD detection methods, our approach is (i) simple; it does not require augmentation or validation data and (ii) principled; the score has a likelihood interpretation and may be considered an un-normalized non-local likelihood. We believe the significance is in the elegance of the proposed framework.\n\nTherefore, our major goal of providing the evidence found in Table 3 is to show that our simple and principled approach can perform comparatively strongly. At the time of submission, we are not aware of any data augmentation free, model ensemble free methods, capable of outperforming our approach.\n\n**Encoding and decoding time**\nPlease see our runtime performance message at the beginning of the rebuttal.\n"], "review_score_variance": 0.1875, "summary": "The main concerns about this work shared by the reviewers were around novelty and presentation. One reviewer felt that a key idea underlying the work has already featured in several other works in recent years, and thus the novelty of the work is limited. I am inclined to agree with this, however, I believe this work could be a useful reference to help more people understand the intricacies of OOD detection and the biases of likelihood-based models (especially autoregressive models), and the practical demonstration that a tiny local model is all you need for efficient lossless image compression, is valuable in itself.\n\nTherefore, I have decided to recommend acceptance. This is of course conditional on the authors including in the manuscript all the additional results they have provided, and reworking the parts that were deemed unclear as set out in the authors' responses.", "paper_id": "nips_2021_q1yLPNF0UFV", "label": "train", "paper_acceptance": "accept"}
