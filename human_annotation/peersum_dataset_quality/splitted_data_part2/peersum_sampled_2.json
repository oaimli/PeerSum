{"source_documents": ["Coding theory is a central discipline underpinning wireline and wireless modems that are the workhorses of the information age. Progress in coding theory is largely driven by individual human ingenuity with sporadic breakthroughs over the past century. In this paper we study whether it is possible to automate the discovery of decoding algorithms via deep learning. We study a family of sequential codes parametrized by recurrent neural network (RNN) architectures. We show that cre- atively designed and trained RNN architectures can decode well known sequential codes such as the convolutional and turbo codes with close to optimal performance on the additive white Gaussian noise (AWGN) channel, which itself is achieved by breakthrough algorithms of our times (Viterbi and BCJR decoders, representing dynamic programing and forward-backward algorithms). We show strong gen- eralizations, i.e., we train at a specific signal to noise ratio and block length but test at a wide range of these quantities, as well as robustness and adaptivity to deviations from the AWGN setting.", "Thanks!", "Thanks for your comments. Indeed, the Turbo decoder is not nearest neighbor, and therefore there is no theorem that the turbo decoder will perform better on every other noise distribution with the same variance. Indeed, if such was the case, there would be no way for the turbo decoder to do worse (since it is mathematically proven). \n\nOn the other hand, Turbo codes do well on the AWGN channel, even when no theorem fully explains its performance. Thus this is an empirical fact, and sets up an empirical expectation that such good performance may extend to other distributions. Furthermore, Turbo decoder is deployed routinely in practice and its bad performance when the distribution is perturbed can affect co-existence with other technologies (like radar) and this has not been fully appreciated. And we show that it can be remedied. ", "Let me summarize what you said: \n-- The theory says: for a decoder based on nearest neighboring (like Viterbi), Gaussian is the worst noise.\n-- Performance of turbo decoder on Gaussian+burst noise is worse than Gaussian, because turbo is not a nearest neighbor decoder.\n\nThen you concluded: \"This is a case where the decoder behaves very differently from that of our expectation from the theoretical result.\" \n\nWhy did you *expect* Gaussian to be the worst noise for turbo, given that turbo is not nearest neighbor-based and hence the theory doesn't apply?\n\nI'm confused how does this suggest Gaussian+burst noise is an adversarial example for turbo decoder? We actually *don't expect* the decoder to work better for burst noise than Gaussian and the poor performance is *not surprising*. \n", "As someone who has worked on coding theory for many years, I would like to add a comment, explaining \nwhy I found this paper very interesting and how it is related to this review. \n\nAs mentioned, using density evolution we can design degree sequences for LDPCs that have thresholds that get very close to the Shannon limit. The only case where we can actually approach arbitrarily close is the erasure channel. For BIAWGN and BSC we can get quite close (but not actually arbitrarily close).\nHowever, for slightly more complicated channels we have no idea how to do that or even what the fundamental limits are (e.g. deletion channel).  I find this paper exciting because it defines a new family of possibilities in code and decoder design. It took us 50 years to go from Shannon's paper to modern LDPC and Turbo codes. So we should not expect that this paper beats LDPCs in their own game but rather as opening a new area of investigation. ", "In this paper the authors propose to use RNNs and LSTMs for channel coding. But I have the impression the authors completely miss the state of the art in channel coding and the results are completely useless for any current communication system. I believe that machine learning, in general, and deep learning, in particular, might be of useful for physical layer communications. I just do not see why it would be useful for channel coding over the AWGN channel. Let me explain.\n\nIf the decoder knows that the encoder is using a convolutional code, why does it need to learn the decoder instead of using the Viterbi or BCJR algorithms that are known to be optimal for sequences and symbols, respectively. I cannot imagine an scenario in which the decoder does not know the convolutional code that it is being used and the encoder sends 120,000 bits of training sequence (useless bits from information standpoint) for the decoder to learn it. More important question, do the authors envision that this learning is done every time there is a new connection or it is learnt once and for all. If it is learnt every time that would be ideal if we were discovering new channel codes everyday, clearly not the case. If we learnt it one and for all and then we incorporated in the standard that would only make sense if the GRU structure was computationally better than the BCJR or Viterbi. I would be surprise if it is. If instead of using 2 or 3 memories, we used 6-8 does 120,000 bits be good enough or we need to exponentially increase the training sequence? So the first result in the paper shows that a tailored structure for convolutional encoding can learn to decode it. Basically, the authors are solving a problem that does not need solving. \n\nFor the Turbocodes the same principle as before applies. In this case the comments of the authors really show that they do not know anything about coding. In Page 6, we can read: “Unlike the convolutional codes, the state of the art (message-passing) decoders for turbo codes are not the corresponding MAP decoders, so there is no contradiction in that our neural decoder would beat the message-passing ones”. This is so true, so I expected the DNN structure to be significantly better than turbodecoding. But actually, they do not. These results are in Figure 15 page 6 and the solution for the turbo decoders and the DNN architecture are equivalent. I am sure that the differences in the plots can be explained by the variability in the received sequence and not because the DNN is superior to the turbodecoder. Also in this case the training sequence is measured in the megabits for extremely simple components. If the convolutional encoders were larger 6-8 bits, we would be talking about significantly longer training sequences and more complicated NNs.\n\nIn the third set the NNs seems to be superior to the standard methods when burst-y noise is used, but the authors seems to indicate that that NN is trained with more information about these bursts that the other methods do not have. My impression is that the authors would be better of focusing on this example and explain it in a way that it is reproducible. This experiment is clearly not well explained and it is hard to know if there is any merit for the proposed NN structure. \n\nFinally, the last result would be the more interesting one, because it would show that we can learn a better channel coding and decoding mechanism that the ones humans have been able to come up with. In this sense, if NNs can solve this problem that would be impressive and would turn around how channel coding is done nowadays. If this result were good enough, the authors should only focus in it and forget about the other 3 cases. The issue with this result is that it actually does not make sense. The main problem with the procedure is that the feedback proposal is unrealistic, this is easy to see in Figure 16 in which the neural encoder is proposed. It basically assumes that the received real-valued y_k can be sent (almost) noiselessly to the encoder with minimal delay and almost instantaneously. So the encoder knows the received error and is able to cancel it out. Even if this procedure could be implemented, which it cannot be. The code only uses 50 bits and it needed 10^7 iterations (500Mbs) to converge. The authors do not show how far they are from the Shannon limit, but I can imagine that with 50 bit code, it should be pretty far.  \n\nWe know that with long enough LDPC codes we can (almost) reach the Shannon limit, so new structure are not needed. If we are focusing on shorter codes (e.g. latency?) then it will be good to understand why do we need to learn the channel codes. A comparison to the state of the art would be needed. Because clearly the used codes are not close to state of the art. For me the authors either do not know about coding or are assuming that we do not, which explains part of the tone of this review. \n", "Error-correcting codes constitute a well-researched area of study within communication engineering. In communication, messages that are to be transmitted are encoded into binary vector called codewords that contained some redundancy. The codewords are then transmitted over a channel that has some random noise. At the receiving end the noisy codewords are then decoded to recover the messages. Many well known families of codes exist, notably convolutional codes and Turbo codes, two code families that are central to this paper, that achieve the near optimal possible performance with efficient algorithms. For Turbo and convolutional codes the efficient MAP decodings are known as Viterbi decoder and the BCJR decoder. For drawing baselines, it is assumed that the random noise in channel is additive Gaussian (AWGN).\n\nThis paper makes two contributions. First, recurrent neural networks (RNN) are proposed to replace the Viterbi and BCJR algorithms for decoding of convolutional and Turbo decoders. These decoders are robust to changes in noise model and blocklength - and shows near optimal performance.\n\nIt is unclear to me what is the advantage of using RNNs instead of Viterbi or BCJR, both of which are optimal, iterative and runs in linear time. Moreover the authors point out that RNNs are shown to emulate BCJR and Viterbi decodings in prior works - in light of that, why their good performance surprising?\n\nThe second contribution of the paper constitutes the design and decoding of codes based on RNNs for a Gaussian channel with noisy feedback. For this channel the optimal codes are unknown. The authors propose an architecture to design codes for this channel. This is a nice step. However, in the performance plot (figure 8), the RNN based code-decoder does not seem to be outperforming the existing codes except for two points. For both in high and low SNR the performance is suboptimal to  Turbo codes and a code by Schalkwijk & Kailath. The section is also super-concise to follow. I think it was necessary to introduce an LSTM encoder - it was hard to understand the overall encoder. This is an issue with the paper - the authors previously mentioned (8,16) polar code without mentioning what the numbers mean. \n\nHowever, I overall liked the idea of using neural nets to design codes for some non-standard channels. While at the decoding end it does not bring in anything new (modern coding theory already relies on iterative decoders, that are super fast), at the designing-end the Gaussian feedback channel part can be a new direction. This paper lacks theoretical aspect, as to no indication is given why RNN based design/decoders can be good. I am mostly satisfied with the experiments, barring Fig 8, which does not show the results that the authors claim.\n", "This paper shows how RNNs can be used to decode convolutional error correcting codes. While previous recent work has shown neural decoders for block codes results had limited success and for small block lengths. \nThis paper shows that RNNs are very suitable for convolutional codes and achieves state of the art performance for the first time. \nThe second contribution is on adaptivity outside the AWGN noise model. The authors show that their decoder performs well for different noise statistics outside what it was trained on. This is very interesting and encouraging. It was not very clear to me if the baseline decoders (Turbo/BCJR) are fairly compared here since better decoders may be used for the different statistics, or some adaptivity could be used in standard decoders in various natural ways. \n\nThe last part goes further in designing new error correcting schemes using RNN encoders and decoders for noisy feedback communication. \nFor this case capacity is known to be impossible to improve, but the bit error error can be improved for finite lenghts. \nIt seems quite remarkable that they beat Schalkwijk and Kailath and shows great promise for other communication problems.\n\nThe paper is very well written with good historical context and great empirical results. I think it opens a new area for information theory and communications with new tools. \n\nMy only concern is that perhaps the neural decoders can be attacked with adversarial noise (which would not be possible for good-old Viterbi ). It would be interesting to discuss this briefly. \nA second (related) concern is the lack of theoretical understanding of these new decoders. It would be nice if we could prove something about them, but of course this will probably be challenging. \n\n", "Thank you for the references. We will cite them appropriately in the final version.", "Thanks for continuing this interesting discussion. Indeed, the presented definition of adversarial examples in the question is quite interesting: i.e., the departure from expectation. Measured that way, the example of Viterbi decoder operating on bursty signal will not qualify as an adversarial example (we had intended a different definition based on adversary injecting a signal to the channel whose goal is to make the decoder fail). \n\nHowever, if you take a Turbo decoder operating on a bursty signal, indeed one can justify that it is an adversarial example under the definition in question. This is because of the following: there is a theorem asserting that Gaussian noise is the worst case noise, i.e., once you fix the average power of the noise, the performance of a nearest-neighbor decoder will be worst if the noise is Gaussian. Therefore the performance on any other channel with the same average power should be *better.* However, in the case of the channel with Gaussian noise + bursty noise having the same average power, the performance of the *turbo* decoder is much worse than in the channel with only Gaussian noise. This is a case where the decoder behaves very differently from that of our expectation from the theoretical result; this is because the iterative BCJR decoder is not carrying out nearest neighbor decoding (unlike the Viterbi decoder).\n\nFurthermore, we would like to point out another nuance in adversarial examples. In the aforementioned cases, we are only changing the distribution of the channel (without looking at the data). A more stringent version, studied in the CS theory literature as worst-case noise, would allow the adversary to choose the noise after looking at the data input into the channel. Even in computer-vision, this is the usual definition, where the adversary looks at the image before injecting the noise. We would like to point out that for real communication problems, the coarse-grained adversary, which can only control the noise distribution maybe a bit more realistic. ", "Thanks for your interest. We agree that latency is an important factor and the throughput demand in decoding is even more aggressive than in computer vision. We would like to point out that our neural networks are much more shallow (2 layers) compared to the 1000 layers employed in vision.   It is not immediately obvious how the computational tradeoffs will play out in this case. This is beyond the scope of the present paper and an important direction for further research.  ", "Neat idea and results, and I'm excited to see more people working on this.\n\nYou wrote \"generalization is difficult [when using neural networks to decode non-sequential codes]\", and the focus of your paper is on convolutional codes. \n\nHowever, there actually have been a few papers recently that get it to work for arbitrary linear codes and longer polar codes:\n\n\"Learning to Decode Linear Codes Using Deep Learning\"-  https://arxiv.org/abs/1607.04793\n\"Neural Offset Min-Sum Decoding\" - https://arxiv.org/abs/1701.05931\n\"Deep Learning Methods for Improved Decoding of Linear Codes\" - https://arxiv.org/abs/1706.07043\n\"Scaling Deep Learning-based Decoding of Polar Codes via Partitioning\" - https://arxiv.org/abs/1702.06901\n\"improved Polar Decoder Using Deep Learning\" - https://www.researchgate.net/publication/321122117_Improved_polar_decoder_based_on_deep_learning", "As far as I know, adversarial examples are inputs that we *expect* the model to process correctly, but it *surprisingly* doesn't. As an example, assume we have an image that is classified correctly. We *expect* small perturbations of that image to be correctly classified as well. A such perturbed image is called \"adversarial example,\" if, to our *surprise*, it can fool the model. \n\nNow consider, say, Viterbi decoder and burst noise. Do we *expect* the model to process such cases correctly, and that it *surprisingly* doesn't?\n", "Ideas, such as distillation or binarization, have been mostly applied to image data and is not immediately clear whether they will work on other data types as well. Honestly, I don't think they will reduce complexity without significantly losing performance, unless experimental results will prove otherwise. \n\nAlso, compared to vision, there is a really real-time constraint in decoding, as typically millions of bits needs to be decoded every second...\n\nI do like the idea of the paper (this is why I'm commenting here after all), but not sure if it will be practical. ", "The answer is subtle and we explain in detail below.  We weren't as clear in our earlier response and we apologize for that. \n\nFor an apples-to-apples comparison of two different (memoryless, random) noise sequences, let us keep the average energy (i.e., the expected value of the sum of squares of the noise values) to be the same. Then Shannon showed in his original 1948 paper that among all memoryless noise sequences (with the same average energy), Gaussian is the worst in terms of capacity. However it was not clear for a long time, if a decoder trained to be optimal for the Gaussian noise (i.e, the minimum distance decoder) would be robust to other noise pdfs. This was confirmed by a strong result of Lapidoth ’96 (Nearest Neighbor Decoding for Additive Non-Gaussian Noise Channels, IEEE Transactions on Information Theory): for any finite block length, the BER achieved by the minimum distance decoder for any noise pdf is *lower bounded* by the BER for Gaussian noise. Since Viterbi decoding is the minimum distance decoder for convolutional codes, it is naturally robust in the precise sense above. \nOn the other hand, turbo decoder does not inherit this property, making it vulnerable to adversarial attacks. As can be seen in Section 3, the performance of turbo decoder (designed for the AWGN) under T distributed noise/bursty noise is extremely poor. \n\nWhen the noise is not Gaussian (which is the worst-case scenario), then there could be decoders that achieve much better performance. This is the sense in which our allusion to susceptibility of Viterbi decoding to adversarial/other noise pdfs was made. Specifically, we consider the practical scenario of bursty noise as an important example of non-Gaussian noise in this paper. Practical considerations suggest that we shouldn't keep the average noise comparable to Gaussian (which is the background noise and generally much smaller (20~50dB lower) than interference), so the apples-to-apples comparison setting discussed in the para is not as relevant. In this case, Viterbi decoder is not as effective as another decoder that harnesses the specific property of the bursty noise statistics -- indeed, as we see in Section 3, the neural network decoder is adaptive to this situation. Furthermore, when the noise is bursty, the turbo decoder with its constituent BCJR decoders is subject to severe error propagation that leads to a significant degradation in performance. We demonstrate that our learned neural network decoder outperforms well known hand-coded methods in the literature for this exact same setting.", "We accept this point in entirety. Both BER and complexity are important metrics of performance of a decoder. In this paper our comparison metrics have focused on the BER. We will make this point very clear in the revised paper. The main claim in the paper is that there is an alternative decoding methodology which has been hitherto unexplored and to point out that this methodology can yield excellent BER performance. Regarding the circuit complexity, we would like to point out that in computer vision, there have been many recent ideas to make large neural networks practically implementable in a cell phone. For example, the idea of distilling the knowledge in a large network to a smaller network and the idea of binarization of weights and data in order to do away with complex multiplication operations have made it possible to implement inference on much larger neural networks than the one in this paper in a smartphone. Such ideas can be utilized in our problem to reduce the complexity too. We would like to point out that a serious and careful circuit implementation complexity optimization and comparison is significantly complicated and submit that it is outside the scope of a single paper. Having said this, a preliminary comparison is discussed below with another anonymous reviewer, but we provide it here for completeness: \n\nThe number of multiplications is quadratic in \n- the dimension of hidden states​ of GRU​ (200) for the proposed neural decoder, and \n- the number of encoder states (4) for Viterbi and BCJR. \n\nThe number of add-compare-select units is \n- 0 for the proposed neural decoder, and \n- linear in the number of encoder states (4) for Viterbi.  \n\nApart from optimizing the size/complexity of the current neural decoder, significant parallelization is possible in the multiplicative units in the neural decoder, as well as pipelining. These designs in conjunction with a careful analysis of the fixed point arithmetic requirements of the different weights are under active research, and outside the scope of this paper.\n\nMore generally circuit implementation complexity improves with time due to both hardware design and component improvements. This has been the case throughout the history of reliable communication: promising algorithms are first proposed and then followed by a surge of research in efficient circuit implementation. A case in point is the recently proposed polar codes where significant recent research has made its decoding competitive in practice (and indeed has been accepted for parts of the 5G wireless standard earlier in the summer of 2017). \n\n  ", "The paper has not compared the complexity of decoders per information bit. This is a basic and essential comparison, especially in this case that efficient implementation is key for e.g., mobile devices. I think it is not fair to compare a highly more complex algorithm against a simpler one and claim superior performance. ", "Can you elaborate on how the Viterbi decoder is vulnerable to adversarial examples?", "Below are detailed comments.\n\nQ1. Why should one use data to learn the Viterbi/BCJR/Turbo when we know them already?\nA1. This is because, we only know the optimal algorithms in simple settings and how to generalize them to more complicated or unknown channel models is sometimes unclear. We demonstrate that neural networks that learn from data can yield more robust and adaptable algorithms in those settings. This is the point of Section 3 and is elaborated below.\n\nTwo advantages to RNN decoders, that go beyond mimicing Viterbi or BCJR:\n(1) Robustness: Viterbi and BCJR decoders are known to be vulnerable to changes in the channel, as those are highly tailored for the AWGN. We show in Section 3, via numerical experiments with T-dsitributed noise, that the neural network decoder trained on AWGN is much more robust against the changes in the channel. This makes, among other things, our neural network decoder much more attractive alternative to Viterbi or BCJR decoders in practice, where the channel model is not available.\n(2) Adaptivity: It is not easy to extend the idea of Viterbi decoder and iterative Turbo decoding beyond the simple convolutional codes and the standard Gaussian channel (or any other Discrete Memoryless Channel). On the other hand, our neural network decoder provides a new paradigm for decoding that can be applied to any encoder and any channel, as it learns from training examples. To showcase the power of this “adaptivity”, we show improved performance on bursty channels. \n\nA more stark example of the utility presents itself in the feedback channel. There exists no known practical encoding-decoding scheme for a feedback channel. Only because we have a neural network decoder that can adapt to any encoder, we are able to find a novel encoder (also NN based) that uses the feedback information correctly and achieves the performance significantly better than any other competing schemes. This would have not been possible without a NN decoder and the techniques we learned in training one to mimic the simple Viterbi. \n  \nQ2. Learning is done every time there is a new connection or it is learnt once and for all?\nA2. We are not sure if we understand the question. The channel models in communication are *statistical* (and in particular the AWGN one) and codes are built to have a probabilistically good performance. The question of \"learning done every time a connection is made\" does not arise. \n\nQ3. If instead of using 2 or 3 memories, we used 6-8 does 120,000 bits be good enough or we need to exponentially increase the training sequence?\nA3. First note that even the Viterbi/BCJR decoder's computational complexity increases exponentially in the (memory) state dimension. While we have not tried a careful analysis on the complexity of neural decoders for codes with state dimension higher than 3, we observe the following: from dimension 2 to 3, we increased the size of neural decoder - from 2 layered bi-GRUs (200 hidden nodes) to 2 layered bi-LSTMs (400 hidden nodes).  The reason we havent explored a careful study of the memory size in neural network decoding is the following: modern coding theory recommends improving the 'quality' of the convolutional code not by increasing the memory state dimension, but via the 'turbo effect'.  The advantage of turbo codes over convolutional codes is that ​it uses convolutional codes with a short memory as the constituent codes, but the interleaver allows for very long range memory, that is naturally decoded via iterative methods. The end result is that turbo codes can be decoded with a far lesser decoding complexity than convolutional codes with a very long memory, for the same BER performance. Indeed, turbo codes have largely replaced convolutional codes in modern practice.  \n\nQ4. In Figure 15 page 6, the solution for the turbo decoders and the DNN architecture are equivalent? I am sure that the differences in the plots can be explained by the variability in the received sequence and not because the DNN is superior to the turbodecoder. \nA4. Turbo codes have been used in every day cellular communication systems since 2000 and their decoders have been highly optimized. \n(1) A nontrivial improvement in BER performance over state of the art would be  considered a major development and discussion topic in standard body documents (we refer the reviewer to Annex B of 3GPP TS 36.101 (cited at the bottom of page 1 of our manuscript) from this summer for a feel for how large an impact on standard body decisions minor improvements to BER performance can have). Indeed, a \"significantly better than turbo decoding\" performance would qualify as a very major result in communication theory with correspondingly large impact on practice.\n(2) Our BER/BLER performance is averaged over 100000 blocks and the standard deviation is infinitesimally small. This is contradiction to the statement of being \"sure that it can be can be explained by the variability in the received sequence.\"", "\nQ5. NN is trained with more information about burst noise model than others? My impression is that the authors would be better of focusing on this example and explain it in a way that it is reproducible. \nA5. The two state-of-the-art heuristics - erasure thresholding and saturation thresholding (Safavi-Naeini et al. 2015) that we are comparing the NN decoder against to -  fully utilize the knowledge on the bursty channel model. Specifically, the threshold value in those methods is choosen based on the burst noise model. We believe the experiment is fully explained and entirely reproducible (we are also uploading our code base on Github after the ICLR review process is completed).  Perhaps the reviewer can be specific on exactly which parts of the experiment could use a better explanation. \n\nQ6. The feedback proposal is unrealistic. It basically assumes that the received real-valued y_k can be sent (almost) noiselessly to the encoder with minimal delay and almost instantaneously. So the encoder knows the received noise and is able to cancel it out.\nA6. (1) The AWGN channel with output feedback is the most classical of models in communication theory (studied by Shannon  himself in 1956. There has been a huge effort in the literature over the ensuing decades (the important  of which we have amply cited in our manuscript) and is of very basic importance to  multiple professional societies (including IEEE communication society and IEEE Information theory society). Although idealistic, it provides a valuable training ground to understand how to use feedback to more efficiently communicate.\n(2) The \"W\" in the  phrase AWGN (which is our channel model  refers to \"white\" which means the noise is memoryless across different time symbols. So even a single time step delay (not to mention \"minimal delay\") does not allow the \"the encoder knows the received noise and is able to cancel it out.\"   Perhaps the reviewer would like to reconsider his/her ratiocination?", "Thank you for your comments. \n\n1. Neural decoders can be attacked with adversarial noise: \nThis is a great point, which is related to the current ongoing advances in other areas of neural networks (e.g. classification). At a high level, there are two types of adversarial noise that can hurt our approach. The first one is poisoning training data. If we are training on data collected from real channels, an adversary who knows that we are training can intervene and add adversarial noise to make our trained decoder useless. This proposes an interesting game between the designer (us) and the attacker, in the form of how much noise power does the adversary need in order to make our decoder fail. This we believe is a fascinating research question, and we will add discussions in the final version of our manuscript.\nThe second type of attack is adversarial examples, where at the test time an adversary changes the channel to make our decoder fail. In this scenario, both Viterbi and our decoder are vulnerable. Our numerical experiments on robustness is inspired by such scenarios, where we show that neural network decoders are more robust against such attacks (or natural dynamic changes) in Section 3.\n\n2. Fair comparison to baseline decoders: \nThere are two ways to run fair experiments on other channels, in our opinion. One is to mimic dynamic environment of real world by using encoder-decoders that are tailored for AWGN (both Turbo/BCJR and Neural Network decoder trained on AWGN) and see how robust it is against changes in the channel. This is the experiments we run with T-distribution. Another is, as suggested by the reviewer, to design decoders based on the new statistics of the channel that work well outside of AWGN. This is the experiments we run with bursty channels. We agree that these two experiments are addressing two different questions, but we believe we are fair in the comparisons to competing decoders within each setting. \n\n3. Theoretical understanding of these neural decoders/coding schemes is a challenging but very interesting future research direction. \n", "Thank you for your comments. \n\n1. Representability, Learnability and Generalization:\nThere are three aspects to showing that a learning problem can be solved through a parametric architecture. \n\n(1) Representability: The ability to represent the needed function through a neural network. For Viterbi/BCJR algorithms, this representability was shown in prior work by handcrafting parameters that represent the Viterbi/BCJR algorithms. We note that neural networks with sufficient number of parameters can indeed represent any function through the universal approximation theorem for feedforward networks and RNNs (Cybenko,G.1989, Siegelmann,H.T.&Sontag,E.D.1995) and therefore this result is not that surprising. \n\n(2) Learnability: Can the required function be learnt directly through gradient descent on the observed data? For Viterbi and BCJR, learnability was neither known through prior work nor is it obvious. One of the main contributions of our work is that those algorithms can be learnt from observed data. \n\n(3) Generalization: Does the learnt function/algorithm generalize to unobserved data? We show this not only at the level of new unobserved codewords, but also show that the learnt algorithm trained on shorter blocks of length 100 can generalize well to longer blocks of length up to 10,000. Such generalization is rare in many realistic problems.\n\nTo summarize, out of the three aspects, only representability was known from prior work (and, we agree with the reviewer, that it is the least surprising given universal representability). Learnability and generalization of the learnt Viterbi and BCJR algorithms to much larger block lengths are both unknown from prior art and they are surprising, and interesting in their own right. We note that Viterbi and BCJR algorithms are useful in machine learning beyond communications problem, representing dynamic programming and forward-backward algorithms, respectively.\n\nPeter Elias introduced convolutional codes in 1955 but efficient decoding through dynamic programming (Viterbi decoding) was only available in 1967 requiring mathematical innovation. We note that ability to learn the Viterbi algorithm from short block length data (which can be generated by full-search) and generalizing them to much longer blocks implies an alternative methodology to solve the convolutional code problem. Such an approach could have significant benefits in problems where corresponding mathematically optimal algorithms are not known at the moment.\n\nWe demonstrate the power of this approach by studying the problem of channel-with-feedback where no good coding schemes are known despite 70 years of research.\n\n2. Advantages of using RNNs instead of Viterbi or BCJR:\nThere are two advantages to RNN decoders, that go beyond mimicing Viterbi/BCJR.\n\n(1) Robustness: Viterbi and BCJR decoders are known to be vulnerable to changes in the channel, as those are highly tailored for the AWGN. We show in Section 3, via numerical experiments with T-dsitributed noise, that the neural network decoder trained on AWGN is much more robust against the changes in the channel. This makes, among other things, our neural network decoder much more attractive alternative to Viterbi/BCJR decoders in practice, where the channel model is not available.\n\n(2) Adaptivity: It is not easy to extend the idea of Viterbi decoder and iterative Turbo decoding beyond the simple convolutional codes and the standard Gaussian channel (or any other Discrete Memoryless Channel). On the other hand, our neural network decoder provides a new paradigm for decoding that can be applied to any encoder and any channel, as it learns from training examples. To showcase the power of this “adaptivity”, we show improved performance on the bursty channel.\n\nA more stark example of the utility presents itself in the feedback channel. There exists no known practical encoding-decoding scheme for a feedback channel. Only because we have a neural network decoder that can adapt to any encoder, we are able to find a novel encoder (also neural network based) that uses the feedback information correctly and achieves the performance significantly better than any other competing schemes. This would have not been possible without a neural network decoder and the techniques we learned in training one to mimic the simple Viterbi.\n\n3. Updated curve for new codes on AWGN channel with feedback:\nWe have improved our encoder significantly by borrowing the idea of zero-padding from coding theory. In short, most of the errors occurs in the last bit, whose feedback information was not utilized by our encoder. We resolved this issue by padding a zero in the end of information bits (Hence, the codeword length is 3(K+1) for K information bits). This significantly improves the performance as shown in the new Figure 8. A full description of the encoder-decoder architecture is provided in Appendix D. \n\n4. We replaced \"(8,16) polar code\" by “rate 1/2 polar code over 8 information bits”.", "Tables 1 and 2 are for the code of Fig. 1. \n\nRe codes with state dimension higher than 2 (or 3):\n\nFirst note that the Viterbi/BCJR decoder's computational complexity increases exponentially in the (memory) state dimension. While we have not tried a careful analysis on the complexity of neural decoders for codes with state dimension higher than 3, we observe the following: from dimension 2 to 3, we increased the size of neural decoder - from 2 layered bi-GRUs (200 hidden nodes) to 2 layered bi-LSTMs (400 hidden nodes). It seems that the network has to scale as the state dimension increases, but we don't have a good guess of in what order it will scale. \n\nOn a related note: ​Modern coding theory recommends improving the 'quality' of the convolutional code not by increasing the memory state dimension, but via the 'turbo effect'.  The advantage of turbo codes over convolutional codes is that ​it uses convolutional codes with a short memory as the constituent codes, but the interleaver allows for very long range memory, that is naturally decoded via iterative methods. The end result is that turbo codes can be decoded with a far lesser decoding complexity than convolutional codes with a very long memory, for the same BER performance. Indeed, turbo codes have largely replaced convolutional codes  in modern practice. \n", "Thanks for your interest. \n\n1) Viterbi algorithm is not a simple deterministic function but an algorithm to find the shortest path on a directed graph (defined by the encoding structure as well as the number of information bits) with non-negative weights on edges (defined by the Gaussian noise samples).  In other words, it is the Dijkstra's shortest path algorithm (dynamic programming) on a specific graph that changes instance-by-instance (since the noise samples and number of information bits vary). While it is conceivable that Viterbi algorithm can be represented with a high capacity neural network, it is unclear if it can be learnt from data in reasonable training time. This is what we demonstrate. \n\n2) Re memory/computation complexity: please see our response to \"complexity comparison\" below. \n\n3) Why should one use data to learn the Viterbi algorithm (or BCJR or Turbo decoding) when we know them already? This is because, we only know the optimal algorithms in simple settings and how to generalize them to more complicated or unknown channel models is sometimes unclear. We demonstrate that neural networks that learn from data can yield more robust and adaptable algorithms in those settings; see Section 3.\n\n4) We agree that it will be very interesting if the ML model leads to discovery of new class of coding schemes. Indeed, this is exactly what we show in Section 4, that for the Gaussian channel with feedback, the NN discovered codes beat the state-of-the-art codes. \n", "\nThe complexity of all decoders (Viterbi, BCJR, Neural) is linear in the number of information bits (block length). \n\nThe actual run times are hard to compare since ​some operations can be​ ​parallelized: e.g., matrix vector multiplications in the neural decoder can be easily parallelized in a GPU.\n\nThanks for pointing out the typo. ", "Thanks for your interest. \n\nThe number of multiplications is quadratic in \n- the dimension of hidden states​ of GRU​ (200) for the proposed neural decoder, and \n- the number of encoder states (4) for Viterbi and BCJR. \n\nThe number of add-compare-select units is \n- 0 for the proposed neural decoder, and \n- linear in the number of encoder states (4) for Viterbi.  \n\nThe dimension of hidden states in the GRU can be potentially reduced, using ideas such as network distillation. Apart from optimizing the size/complexity of the current neural decoder, significant parallelization is possible in the multiplicative units in the neural decoder, as well as pipelining. These designs in conjunction with a careful analysis of the fixed point arithmetic requirements of the different weights are under active research, and outside the scope of this paper.   \n", "Interesting work; however, given that Viterbi algorithm, for example, is a simple (but elegant) well-defined algebraic function, isn't it expectable that a neural network with sufficient capacity would be able to approximate that? \n\nAlso, given the existing algorithm with efficient implementation, is it reasonable to replace it with an RNN? Will the time and memory complexity of such an RNN not be a major issue? \n\nAnd, in general, is it a good practice to replace (or replicate) deterministic functions with \"learning\" data-driven models?\n\nOf course, it would be very interesting if the ML model leads to the discovery of (or gives some insight into) a new class of coding schemes. But, this direction is not specifically pursued or examined in paper.", "For the results in Tables 1 and 2: are you using the code of Fig.1 or one of the codes of Fig.9 ?\n\nAlso, did you try similar analysis for codes with state dimension higher than 2 (or 3) ? \nIf not, what is your educated guess for the case of higher state dimensions?", "Thanks for your answer. \n\nCan you approximately calculate how many operations per information BIT you have in the neural decoer as compared to the viterbi decoder (like add-compare-select , multiplication, etc.) ?", "Can you please elaborate on the complexity of the proposed neural decoder as compared to this of the Viterbi/BCJR decoder ?\n\nAlso, note a typo in Fig. 9: (a) and (b) figures should be exchanged."], "review_score_variance": 8.222222222222221, "summary": "This paper studies trainable deep encoders/decoders in the context of coding theory, based on recurrent neural networks. It presents highly promising results showing that one may be able to use learnt encoders and decoders on channels where no predefined codes are known.\n\nBesides these encouraging aspects, there are important concerns that the authors are encouraged to address; in particular, reviewers noted that the main contribution of this paper is mostly on the learnt encoding/decoding scheme rather than in the replacement of Viterbi/BCJR. Also, complexity should be taken into account when comparing different decoding schemes.\n\nOverall, the AC leans towards acceptance, since this paper may trigger further research in this direction. ", "paper_id": "iclr_2018_ryazCMbR-", "label": "train", "paper_acceptance": "accepted-poster-papers"}
{"source_documents": ["Data poisoning has been proposed as a compelling defense against facial recognition models trained on Web-scraped pictures. Users can perturb images they post online, so that models will misclassify future (unperturbed) pictures.\n  \n We demonstrate that this strategy provides a false sense of security, as it ignores an inherent asymmetry between the parties: users' pictures are perturbed once and for all before being published (at which point they are scraped) and must thereafter fool all future models---including models trained adaptively against the users' past attacks, or models that use new technologies discovered after the attack.\n  \nWe evaluate two systems for poisoning attacks against large-scale facial recognition, Fawkes (500,000+ downloads) and LowKey. We demonstrate how an \"oblivious\" model trainer can simply wait for future developments in computer vision to nullify the protection of pictures collected in the past. We further show that an adversary with black-box access to the attack can (i) train a robust model that resists the perturbations of collected pictures and (ii) detect poisoned pictures uploaded online.\n  \nWe caution that facial recognition poisoning will not admit an \"arms race\" between attackers and defenders. Once perturbed pictures are scraped, the attack cannot be changed so any future successful defense irrevocably undermines users' privacy.", " Could the reviewer please clarify the rationale for reducing their score to a strong reject following our rebuttal?\n\nWe have clarified our paper's scope and claimed contributions.\nDoes the reviewer disagree with these, or are there other points we could aim to address?", "This paper studies the effect of data poisoning in face recognition and the relation to the defense techniques. Conventionally, the poisoned data will fail the face recognition models who is trained without defense strategy. Two solutions of defense are given: oblivious trainer and adaptive trainer. The claim is that, any existing poisoning methods cannot protect the privacy of users in the face images. + The insight of this paper is very useful for the proctecter of user face.\n- It is not clear how the oblivious trainer works. \n- There is no clear presentation about the poisoning details of Flawkes and LowKeys.\n- The technical novelty is very limited. Rather than fancying legislative alternative, a research paper needs to propose technical solution.\n Overall, this is a facial privacy analysis with insightful claims, but the presentation and the discussion is very confusing. Thus, we are not able to agree this argument whether is reasonable and solid. The final rating will depend on the authors’ feedback.", "This paper points out that current data poisoning techniques cannot effiectively protect users privacy, i.e., face data, on the Internet. The authors have examined several strategies to enable modern face recognition models to defense attacks from widely used data poisoning methods. Experimental results suggest that those data poisoning attacks can be easily defensed by adaptively tuning the face recognition models or using more advanced algorithms which would be developed in the future. The main conclusion is that people should not rely on technical solutions to protect users privacy and legislation actions are what is actually needed. ### Strengths:\n1. The paper is well written and easy to follow.\n2. The topic discussed in this paper is of significant importance as the rapid development of deep learning techniques nowadays also poses great threats to people's privacy, especially for the face data.\n3. Extensive experiments have been conducted to statistically ascertain the authors' claims.\n\n### Weaknesses:\nFrom technical point of view, there is less innovation in this paper. It is widely known that adversarial attacks, either obtained in white-box or black-box manners, can be effectively guarded by robust training or by adopting a different algorithm. The experimental results are within expectation and little technical insight is gained.\n This paper has addressed an important problem that, data poisoning techniques are insufficient to protect people's privacy from modern development of face recognition models and it is of great importance to draw people's attention to the discussed topic, to potentially push any legislation actions instead of searching for technical solutions to protect users privacy. However, I think the technical contribution from this paper is limited as little new insight is provided.", " The authors have made a good point that the limitation of adversarial attack may not be so obvious to non-professional users without relevant background and therefore existing attack systems like Fawkes and LowKey may have misled ordinary users to some extent. I agree that there should be some different voice on such an influential platform like ICLR. Therefore, I am willing to increase my rating by one level.\n\nHowever, I still think the claimed technical contributions are not very significant and the main value of this paper is pointing out the fragility of existing data poisoning techniques by conducting extensive experiments in order to raise more attention from the public.", " We thank the reviewer for clarifying their review of our paper. We answer the reviewer's three comments below, and have edited our submission accordingly (the changes are marked in blue).\n\n(1)\nThe oblivious defense *is* extremely simple. That's our whole point, that even just waiting for newer facial recognition systems will break current poisoning attacks.\n\nWe thank the reviewer for linking to related work on face anonymization and purification. We have added a discussion in Section 2.2 (\"A note on evasion and obfuscation attacks\") where we explain that these works consider a very different threat model than ours:\n\n- anonymization approaches are *not* clean-label (and they are also not necessarily poisoning attacks). Their aim is to make faces non-identifiable (even for humans). Our defenses and our take-aways do not apply to such approaches.\n- the two linked papers for purification are defenses against *evasion* attacks: here it is assumed that a user's training pictures are unaltered, but the test-time pictures are perturbed. This is again a very different threat model for which we make no claims.\n\nClean-label poisoning attacks are very compelling because they still let users upload pictures online so as to share them with others, and they don't require users to have control over the pictures that are ultimately fed to the facial recognition system. This makes these attacks very user-friendly, and explains why attacks such as Fawkes have had a huge success in building a user base.\n\nRegarding the definition of $X, Y$, these are standard notations used for features and labels. We have added a note clarifying that in our setting, $X$ represents the facial images of users, and $Y$ the corresponding labels. The formal analysis in Section 2.2. is not limited to facial recognition though, and applies to any clean-label poisoning attack.\n\n(2)\nWe hope that the above distinction between poisoning, evasion and anonymization helps to clarify how Fawkes and LowKey differ from other approaches. The setting considered in our paper and in Fawkes & LowKey is that a user perturbs the pictures they post online (but minimally, so that their friends can still identify them), with the goal that machine learning models trained on these pictures will fail to identify unperturbed pictures of the user. This setup is summarized in Figure 1.\n\nOur paper shows that such poisoning attacks will not work. We make no claims about evasion attacks or face anonymization techniques, as these correspond to very different threat models. \n\n(3)\nOur claim about the need for legislation is not a contribution of our paper, and we never say that it is. This is simply a concluding thought we make (once in the introduction and once in the conclusion), based on our technical evaluation. \n\nMore specifically, we note that if users want to continue uploading identifiable pictures of themselves online, we don't have a technical way of preventing facial recognition systems from being developed (and thus legislation may be the only alternative).\nWhether this position happens to be \"mainstream\" or not is irrelevant.", " (1) As there is no clear definition of oblivious defense in this paper, we are fairly confused about the defense, and find it extremely simple as waiting for better face recognition models which is a primary version of purification. Besides, there are also many existing works to anonymize facial images which do not appear in this paper as the role of attacker/protector. So, in this part, the problem should be the missing important reference and important experiments. \nAlso, there is no formal definition of $X$ and $Y$.\n\n(2) We clarify that these systems should be presented with more details so that they can be compared with the existing facial identity anonymizing methods which can work well to fool the state-of-the-art face recognition models without significant visual modification.\n\n(3) \n\nFirstly, let us clarify that we do recognize the major tech contribution of this paper which is that the authors find that the existing poisoning methods fail to protect the facial identity. This finding, however, is based on the incomplete survey and experiment (see above). The poisoning/protectors are definitively hopeless or not, may the authors provide more solid verification about this?\n\nSecondly, the contribution of this paper, thus, narrows down to the second one, which is appealing the legislative roundabout. Considering this is a legislative-only claim as the remaining contribution, we suggest the authors to submit this paper to the conferences/journals related to the sciences of law.\n\nFinally, sure, banning human face recognition is the MAINSTREAM sense nowadays. Making contribution to the mainstream is understandable. Yet, the challenge is the way we contribute. Should we ban the using of current water for preventing inundation, or develop our technology and invent a hydropower station? \n\n\n\n", " Facial Identity Anonymizing\n\n[1]Cao J, Liu B, Wen Y, et al. Personalized and Invertible Face De-Identification by Disentangled Identity Information Manipulation[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 3334-3342.\n\n[2]Maximov M, Elezi I, Leal-Taixé L. Ciagan: Conditional identity anonymization generative adversarial networks[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 5447-5456.\n\n[3]Gafni O, Wolf L, Taigman Y. Live face de-identification in video[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2019: 9378-9387.\n\n\nPurification\n\n[1]Deb D, Liu X, Jain A K. FaceGuard: A Self-Supervised Defense Against Adversarial Face Images[J]. arXiv preprint arXiv:2011.14218, 2020.\n[2]Agarwal A, Singh R, Vatsa M, et al. Image transformation based defense against adversarial perturbation on deep learning models[J]. IEEE Transactions on Dependable and Secure Computing, 2020.", " I find your answer reasonable. Hence, I have increased your score to 8.", "Recent works propose to protect users from facial recognition by poisoning their images before uploading them to the Internet (called poisoning \"attacks\"). This paper reveals the flaws of these methods by designing two effective methods (called \"defenses\") to defeat that protection mechanism. The first approach is adaptive defense, in which the model trainer assumes to have access to the poisoning function as a black-box. He then can collect a clean facial image dataset, create perturbed and unperturbed versions, and finetune the poisoned face recognition model to learn robust features. The second approach, called obvious defense, relies on the fact that poisoned examples do not transfer well over time to newer models. Hence, the model trainer can wait to obtain a better face recognition model and properly safely finetune it on the perturbed images. Both methods successfully defeat two poisoning attack baselines, raising awareness on the inefficiency of the poisoning-based identity protection mechanism. ### Strengths\n- This paper defines the dynamic game scenario, which is more practical than the static game scenario used in the previous poison-based identity protection works\n- It proposes two defenses that can defeat the poison-based identity protection methods\n- The authors propose a strategy for the model trainer to defense from poisoning attacks without sacrifying accuracy\n- The authors give a good discussion on the flaws of the poison-based identity protection approach. The game is already lost, and users should not rely on the methods in that category to have a false sense of security.\n- This paper has a good amount of references\n\n### Weaknesses\n- In the adaptive defense, the authors assume access to the poisoning function, which may be unrealistic. The poisoning function should be secret for a better protection,\n- Obvious defense can break LowKey only once (Figure 6). There is no guarantee that robust models, like CLIP, will be popular in the future facial recognition models.\n\n### Not a weakness of the paper itself\nI agree with the section \"The game is already lost\": the poison-based identity protection approach is very unrealistic and has a low value. This paper reveals the flaws of previous works that use poison attacks to protect user identity from face recognition systems. It has some good discussions and provides two methods to break those protections. There are still some concerns about the experiments and the significance of the previous works the paper is targeting. Hence, I give it a Borderline, slightly towards Acceptance.", " We thank the reviewer for their feedback. \n\n**Unfortunately, the current review offers very limited actionable criticism of the paper. The reviewer claims the paper is “confusing”. What parts of the paper would the reviewer want us to clarify?**\n\nBelow, we address the points raised by the reviewer.\n\n> *“It is not clear how the oblivious trainer works.”*\n\nThe process is detailed in Section 2.2 and again in Section 3.4. Which part would the reviewer want us to clarify? The oblivious trainer simply collects facial data and trains an undefended model.\n\n> *“There is no clear presentation about the poisoning details of Flawkes and LowKeys”*\n\nThe general principle behind the attacks is explained in Section 3.1. The exact details of what the attacks do is not important for our purpose, and we thus refer the interested reader to the original papers. \n\nBut, we’re happy to provide some additional details on these attacks in our final version if the reviewer could clarify which aspects of these systems could merit further discussion. \n\n> *“The technical novelty is very limited. Rather than fancying legislative alternative, a research paper needs to propose technical solution.”*\n\nCould the reviewer point us to the section of the call-for-papers that mandates that a research paper must propose a technical solution to a problem that the paper identifies?\n\nICLR’s call-for-papers reads: *“the scope includes \"societal considerations of representation learning including fairness, safety, privacy, and interpretability\".*\n**We believe that our paper falls well within this scope.**\n\nThere are many papers that highlight issues in ML without being able to propose an actionable solution. For example, papers that show that ML models are: (1) vulnerable to adversarial examples; (2) not robust to various distribution shifts; (3) biased against various subgroups, etc.\n\nIt is also not clear to us that a technical solution to the problem of large-scale facial recognition necessarily exists. Humans are very good at performing facial recognition and thus, in principle, it should be possible to automate this procedure with machine learning. In this sense, the attacks that we evaluate are essentially trying to defer the inevitable (and we show that they will fail at doing that even against oblivious defenders).\n\nThis is why we argue that a technical solution may be hopeless and that legislation may be the only way to prevent abuses of facial recognition. \n\nFinally, we do consider the following as novel technical contributions in our paper:\n- The formal game analysis of dynamic poisoning attacks in Section 2, which clarifies some subtle differences between the attack dynamics of evasion and poisoning attacks. \n- A rigorous evaluation of various defense techniques against poisoning attacks.\n- The design of defense strategies that achieve high robustness and accuracy, in Section 3.5 \n", " We thank the reviewer for their valuable comments and for their positive assessment of our paper. Below, we address the reviewer's main points.\n\n> *“In the adaptive defense, the authors assume access to the poisoning function, which may be unrealistic. The poisoning function should be secret for a better protection”*\n\nA secret poisoning function would indeed be harder to adapt to, yet this would also make it harder for systems such as Fawkes or LowKey to protect the privacy of a large number of users.\n\nAn individual tech-savvy user may decide to develop a secret attack. In this case, our oblivious defenses would obviously still apply. \nWe also find that our adaptive defenses transfer moderately between attacks. For example, in Appendix A.4 we show that it is possible to build a robust detector for the attacks of Fawkes or LowKey, without requiring access to the poisoning function.\n\nWe will include a more detailed discussion of secret attacks in our final paper.\n\n> *“There is no guarantee that robust models, like CLIP, will be popular in the future facial recognition models”*\n\nOur point here is that future facial recognition models **could** use CLIP, in which case all users’ privacy would be lost. The existence of even a **single** defense against a poisoning attack invalidates any guarantees that the attack can provide (since it is the defender that gets to adapt to the attack, and not vice-versa).\n\nMoreover, users typically don't know what type of models are being used by facial recognition companies. So a user of current attacks would have to \"blindly\" hope that models such as CLIP won’t be used now or in the future.\n\n> “There are still some concerns about the experiments and the significance of the previous works the paper is targeting”\n\nFawkes got a very significant amount of media attention and a large user base (500k downloads according to the authors). In this sense, Fawkes is orders-of-magnitude more significant than *any* other ML defense that has been evaluated in the past (e.g., there exists a large body of work on evaluating various defenses against adversarial examples, but to our knowledge none of these defenses have actually ever been deployed in practice).\n\nMoreover, we note that LowKey was published at ICLR 2021 and we thus argue that a paper that thoroughly evaluates this system should be of significant interest for ICLR 2022.", " We thank the reviewer for their valuable comments. We argue that the contributions of our paper (both technical and conceptual) are significant and can contribute to a better understanding of the limits of adversarial ML. \n\n> *“It is widely known that adversarial attacks, either obtained in white-box or black-box manners, can be effectively guarded by robust training or by adopting a different algorithm. The experimental results are within expectation and little technical insight is gained.”*\n\nWhile our results might not be surprising in hindsight, systems such as Fawkes and LowKey were published at top venues in security and machine learning (USENIX Security 2020 and ICLR 2021), and have attracted a lot of media attention and real users. So presumably it is not obvious to everyone that these systems are ineffective. A study like ours is thus important to underline the limitations of poisoning attacks in order to avoid luring users into a false sense of security.\n\nWe further consider the following as novel technical contributions in our paper:\n- The formal game analysis of dynamic poisoning attacks in Section 2, which clarifies some subtle differences between the attack dynamics of evasion and poisoning attacks. \n- A rigorous evaluation of various defense techniques against poisoning attacks. The original evaluations performed by the Fawkes and LowKey papers were deemed sufficient by reviewers at the time. We believe our paper thus makes an important contribution in demonstrating how such evaluations may have overestimated the protections offered to users.\n- The design of defense strategies that achieve high robustness and accuracy, in Section 3.5. These strategies demonstrate that robustness need not come at a cost in accuracy in all situations, as is often claimed in the adversarial examples literature. \n", " We thank the reviewer for their very positive assessment of our paper and their insightful comments. Below we address the main points raised by the reviewer.\n\n> *“A more concrete solution to the problem would have strengthened the paper.”*\n\nIt is not clear to us that a technical solution to the problem of large-scale facial recognition necessarily exists. Humans are very good at performing facial recognition and thus, in principle, it should be possible to automate this procedure with machine learning. In this sense, the attacks that we evaluate are essentially trying to defer the inevitable (and we show that they will fail at doing that even against oblivious defenders).\n\nIn any case, we believe that papers that identify problems in machine learning systems can be of significant importance even if they fail to identify a concrete solution to the problem at this stage.\n\n>  *“however, it can still be considered an arms race with the constraint that the defender is in a better position to win”*\n\nYes, we agree. This is a question of the semantics of what we mean by an “arms race”.\n", "Paper presents an analysis of two systems for poisoning attacks. The paper shows that perturbing facial images does not offer long term security; future systems can still recognize the once perturbed image(s). Strengths\nThis is an interesting paper. The evaluation criteria and the game setup was well conducted. A large number of feature extractors were evaluated showing the problem is consistent across multiple. It is especially interesting to see how even \"oblivious\" systems can just wait and see to get better. Figure 5 is shows how Fawkes deteriorates over time with new extractors causing it to fail. The paper is well-written and easy to read. Ethical concerns are well documented in ethics statement.\n\nWeaknesses\nThis is a strong statement \"Ultimately, we believe that the only viable course of action for privacy-conscious users is to avoid posting pictures online, or to support policy and legislation that restrict the use of facial recognition (Singer, 2018; Weise & Singer, 2020; Winder, 2020).\" and may not be a feasible solution to the problem, although supporting policy is certainly feasible. A more concrete solution to the problem would have strengthened the paper.\n\nMinor point: The paper argues that it is not an arms-race, however, it can still be considered an arms race with the constraint that the defender is in a better position to win. This is arguably just a semantic difference, and a minor point. The paper does a good job analyzing poisoning attacks. It shows that the methods fail over time and they do not generalize to future attacks. It is in interesting paper and has value for the community to consider longer term security measures for facial recognition privacy concerns."], "review_score_variance": 8.1875, "summary": "This paper reveals that popular data poisoning systems, Fawkes and LowKey, fail to effectively protect user privacy in facial recognition. The methods to defend against poisoning attacks are quite simple---you can either adaptively tune the face recognition models or just wait for more advanced facial recognition systems. Given these “disappointed” findings from the technical solution side, this paper further argues that legislation may be the only viable solution to prevent abuses of facial recognition.\n\nOverall, all the reviewers highly appreciate the comprehensive and rigorous evaluations provided in this paper and enjoy reading it. The biggest concern is raised by the Reviewer 6s7m, given this work fails to discuss/compare to previous works on Facial identity anonymizing and the technical contribution is incremental. During the discussion period, all other reviewers reach a consensus that 1) facial identity anonymizing is not relevant; and 2) this work make enough contributions and is worthy to be heard by the general community; the Reviewer 6s7m still hold the opposite opinion, but is okay for accepting this paper anyway. \n\nIn the final version, the authors should include all the clarification provided in the discussion period.", "paper_id": "iclr_2022_B5XahNLmna", "label": "test", "paper_acceptance": "Accept (Poster)"}
{"source_documents": ["Learning with noisy labels has drawn a lot of attention. In this area, most of recent works only consider class-conditional noise, where the label noise is independent of its input features. This noise model may not be faithful to many real-world applications. Instead, few pioneer works have studied instance-dependent noise, but these methods are limited to strong assumptions on noise models. To alleviate this issue, we introduce confidence-scored instance-dependent noise (CSIDN), where each instance-label pair is associated with a confidence score. The confidence scores are sufficient to estimate the noise functions of each instance with minimal assumptions. Moreover, such scores can be easily and cheaply derived during the construction of the dataset through crowdsourcing or automatic annotation. To handle CSIDN, we design a benchmark algorithm termed instance-level forward correction. Empirical results on synthetic and real-world datasets demonstrate the utility of our proposed method.", "Thank you for your appreciation and comments! Please find our responses below.\n\n\"This paper also introduces an assumption that the confidence score for each data is given. To me, this is also a strong assumption. Although the authors have provided examples of how to collect confidence score, collecting confidence scores may not be easy for many specific problems.\"\n\n- We agree that this is a substantial assumption. However, without any additional assumption the IDN setting is an ill-posed problem, hence the current lack of feasible solutions for real-world applications. With this assumption, we aim to propose a possible solution to this setting that has real-world applications as shown by the proposed examples.\n\n\n\"In this section, the authors further assume that the off-diagonal entries of the flip matrix are independent of instance. After seeing the explanation, I personally agree that the assumption is reasonable for some cases . However, I found that in the experiments, the authors synthesized label noise where the off-diagonal entries depend on the instance. The proposed method also shows its advantages on this case. Can you explain this?\"\n\n- Please note that we only assume that the off-diagonal entries of the flip matrix are independent of the instance conditionally on (\\hat{Y} \\neq Y). Therefore, following Eq. (5), we still have T_ij, i \\neq j as a function of x but T_ij(x) is only dependent of x through the diagonal term T_ii(x) since our assumptions boils down to \\alpha_ij(x) = \\alpha_ij. Sorry for the confusion, we will clarify this point in the following version.\n\n\n\"I have another concern that the obtained confidence score may not accurate. Is the proposed method sensitive to the confidence scores?\" \n\n- We are currently running some sensitivity analysis on the confidence scores and we will add the results in the following version.\n\n", "Thanks for being so responsive and I apologize if I am missing something. \n\nPerhaps I should be more specific: If Y _|_ \\bar{Y} | X, then why does equation 3 not reduce to I[\\bar{Y} = f(x)] and why does P(Y = i | \\bar{Y}=i, X=x) =/= P(Y = i | X=x)?", "This paper focuses on instance-dependent label noise problem, which is a new and important area in learning with noisy labels. The authors propose confidence-scored instance-dependent noise (CSIDN) to overcome strong assumptions on noise models. They clearly define confidence scores and justify their availability. To solve CSIDN model, they propose instance-level forward correction with theoretical guarantees. Their experiments on both synthetic and real-world datasets show the advantage of this algorithm.\n\nPros:\n\n1. This paper is clearly written and well-structured in logic. For example, in Section 2, they introduce from class-conditional noise to instance-dependent noise first, which paves the way for confidence-scored instance-dependent noise. This make readers easy to follow the main contribution, namely the new noise model.\n\n2. This paper pushes the knowledge boundary of learning with noisy labels, since it focuses on more realistic and challenge topic \"instance-dependent label noise\". The authors leverage the idea of confidence scores, and propose confidence-scored instance-dependent noise (CSIDN). Compared to previous solutions, CSIDN is a tractable instance-dependent noise model, which enjoys several benefits, such as multi-class classification, rate-identifiability and unbound-noise.\n\n3. This paper proposes an algorithm to solve CSIDN inspired by forward correction called instance-level forward correction (ILFC). Their algorithm has been verified in both synthetic datasets and real-world datasets. The empirical results show the advantage of ILFC.\n\n(Minor) cons:\n\n1. Section 3 is a bit dense in understanding the estimation of transition matrix. The authors are encouraged to polish this section. \n\n2. Although ILFC outperform CT and LQ in real-world datasets, the authors need to add the reasults of MAE and FC to more thoroughly verify the performance of ILFC.", "Thanks for the prompt reply and new results. I am further convinced and consider the paper strong and worthy of acceptance. ", "Thank you for your insightful comments and suggestions. We address\nyour remaining comments below.\n\n--- Major comments ---\n\n\"2. The other scenario considered by the authors is when there are\nmultiple annotators; however, there is substantial literature on\nlearning from multiple noisy annotations which the authors do not\nreview. I suggest the authors start with \"Modeling annotator\nexpertise: Learning when everybody knows a bit of something\" by Yan et\nal. (2010)  (and the citations therein) which also considers the\ninstance dependent noise case.\"\n\n- Thank you for this reference. We currently give a brief survey of\nworks modelling multiple annotator's expertise to produce more\naccurate labels in the Appendix, but we agree that the branch of\ndirectly learning with multiple noisy annotations is missing from the\ncurrent literature review and we will refer to those works in the following version.\n\n\n\"3. Under what conditions does the proposed algorithm converge and to\nwhat does it converge to?\"\n\n- Our method is shown to empirically showed to converge well (cf\nFigures 3 and 4). We plan on studying the proposed algorithm from a\ntheoretical viewpoint and derive convergence guarantees in future\nworks.\n\n\n\"4. The proposed method relies on several assumptions that are\nscattered throughout the description of the algorithm. I highly\nrecommend making these assumptions clear near the beginning of the\npaper. Specifically, my understanding is that the main assumptions\nare:\n\ni. Confidence scores r_x are available for each instance and r_x\n\\approx P(Y=y|\\bar{Y}=y,X=x).\nii. Y _|_ X | Y\\neq\\bar{Y}, \\bar{Y} = y\niii. Anchor points are available on some portion of the data.\n\nBeyond the presentation, I find this to be a fairly strong set of\nassumptions, particularly the first assumption.\"\n\n- These are indeed the main assumptions of our approach. We point out\nthat (i) and (ii) are currently stated in the introduction, but we\nagree that (iii) is missing and that the paper would benefit from\nmaking those three assumptions clearer. We will update the\nintroduction accordingly in the following version.\n\n\n--- Minor comments ---\n\n\"1. I really appreciated the synthetic example demonstrating the\npotential pitfalls of the small loss approach; however, I would spend\na bit more time clearly explaining the small loss approach so that\nreaders understand why it fails and how you are solving it's problems.\n\n2. Also in the synthetic example, the authors state that covariate\nshift leads poor accuracy, however, I think this point would be\nstronger if demonstrated instead of just asserted.\"\n\nThank you for those additional suggestions. We took due note of them\nand will aim to make those points clearer in the following version.\n", "In order to change the mathematical notations, we need to revise the whole paper and carefully proofread it to guarantee the consistent. We promise to do this in the next version.", "We have added empirical results of FC and MAE on CIFAR10 and SVHN with instance-dependent noise. Please check the updated PDF. \n\nWe are sorry that Section 3 is a bit dense in understanding the estimation of transition matrix. We will try our best to polish this Section in the next version.", "Yes, it's the case that given X the true label Y and the predicted label Y_hat are statistically independent for any fixed classifier f(x). However, f(x) should be a well trained classifier and it depends on the distributional information of X and Y itself. Thus, even though Y_hat doesn't depend on Y | X, it still depends on p(Y | X) as a whole information source.\n\nAnyway, it's true that P(Y_hat=i | Y=i, X=x) = I[Y_hat = f(x)] where it doesn't matter which value Y takes. This is because we are considering model evaluation instead of model training, where the predictions don't depend on the true labels but the performance measure does.\n\nWe are sorry for the confusion and will try to clarify this point by simplifying the notations later.", "Thank you for this clarification! If I understood correctly, what you show in your proof is that if (A) r_x = P(Y=y_hat | Y_hat=y_hat, X=x), then (B) it is a well-calibrated score (i.e. A-->B). I do not disagree with this. What the paper assumes, however, is the converse. That is, the paper assumes that if (B) r_x is well-calibrated, then (A) r_x = P(Y=y_hat | Y_hat=y_hat, X=x) (i.e. B-->A). Fortunately, given the conditional definition of calibration you stated above, this appears true:\n\nP(Y=\\hat{Y}|\\hat{P}=\\hat{p}(x), X=x) = \\hat{p}(x)\nP(Y=\\hat{y}(x)|\\hat{P}=\\hat{p}(x), X=x) = \\hat{p}(x) (the prediction is deterministic function of X)\nP(Y=\\hat{y}(x)| X=x) = \\hat{p}(x) (the confidence score is also a deterministic function of X)\n\nwhere \\hat{p}(x) is the determinist mapping of X to a confidence score and \\hat{y}(x) is the deterministic mapping of X to a label. However, this raises another problem. Both your proof and mine rely on the assumption that \\hat{Y} (and therefore \\bar{Y}) is a deterministic function of X. If this is the case, then shouldn't it also be the case that \\bar{Y} \\perp Y | X? In which case:\n\nP(\\bar{Y} = i | Y = i, X=x) = P(\\bar{Y} = i | X=x) = I[\\bar{Y} = \\hat{y}(x)]\n\nwhere I[.] is the indicator and \\hat{y}(x) is the deterministic mapping from X to \\bar{Y}.", "Thanks for your appreciation! We are running the experiments of Forward Correction (FC) and MAE on both CIFAR10\nand SVHN with instance-dependent noise. We will update results soon.", "A major concern of R3 is that s/he cannot agree with us r_x = P(Y=y_hat | Y_hat=y_hat, X=x), where Y_hat is the variable representing the predicted label, is a proper confidence score. However, we would like to show that it is a proper confidence score because it can fit the definition of perfect calibration in the calibration area.\n\nThe perfect calibration is defined in Guo et al., i.e., \nP(Y_hat=Y | P_hat=p) = p,\nwhere P_hat is the confidence score. Note that neither X nor x is involved but this definition is still about the class posterior rather than the class prior. It is because Y_hat implicitly depends on X: Y_hat is a random variable obtained by wrapping a learned classifier f(x) on top of the random variable X, i.e., Y_hat = f(X) and y_hat = f(x). Thus, the random source of Y and Y_hat is from the underlying data distribution (Y itself and X respectively), but the nature of them are completely different.\n\nTo make our claim clear, we want to extend the definition of the perfect calibration, i.e.,\nP(Y_hat=Y | P_hat=p_x, X=x) = p_x.\nThe extension is reasonable because there is a confidence score for each single data point. In order to make it possible after adding X=x into the condition, we allow p_x to depend on x as well. Observe that X=x makes Y_hat no longer random but just y_hat or f(x); or equivalently, we can regard Y_hat as a one-hot random variable given X=x.\n\nSubsequently, we have\nr_x\n= P(Y=y_hat | Y_hat=y_hat, X=x)\n= P(Y=y_hat, Y_hat=y_hat, X=x) / P(Y_hat=y_hat, X=x)\n= P(Y=y_hat, X=x) / P(X=x)\n= P(Y=y_hat | X=x)\n= P(Y=Y_hat | X=x),\nsince Y_hat and y_hat are exactly equivalent given X=x. As a consequence,\nP(Y_hat=Y | r_x=p_x, X=x)\n= P(Y_hat=Y | P(Y=Y_hat|X=x)=p_x, X=x)\n= p_x,\nwhich concludes our proof that r_x is a proper confidence score similarly to P_hat.\n\nPS, letting the confidence score depend on x is very popular in importance reweighting and related learning methods, for example, a NeurIPS 2018 spotlight paper entitled \"binary classification for positive-confidence data\".", "--- Overall ---\n\nI think the problem of incorporating information about labeling uncertainty (when such information is available) is an interesting and important problem; however, I think this paper contains a crucial misunderstanding of the definition of calibration (as defined in Guo et al. 2017), is missing some important parts of the literature, and does not provide adequate convergence guarantees for the proposed method.\n\n--- Major comments ---\n\n1. In section 3.1, the authors substitute the confidence score r_x for the conditional probability P(Y=y|\\bar{Y}=y,X=x); however, even if the confidence scores are perfectly calibrated, these quantities are not necessarily equal (or even particularly close). As defined in Guo et al. (2017), a confidence score is well calibrated if the probability that a prediction is correct given the confidence score is equal to the confidence score. Using their notation: P(Y=\\hat{Y}|\\hat{P}=p) = p. Importantly, this is not conditioned on \\hat{Y} or X. One way to see that these two quantities are not equal is to observe that there are many possible confidence score functions that satisfy the above definition whereas the conditional probability defined above is a unique function. In particular, if the confidence score function is a constant equal to the accuracy of the model, then the confidence score is well calibrated, but clearly not equal to the conditional probability above.\n\n2. The other scenario considered by the authors is when there are multiple annotators; however, there is substantial literature on learning from multiple noisy annotations which the authors do not review. I suggest the authors start with \"Modeling annotator expertise: Learning when everybody knows a bit of something\" by Yan et al. (2010)  (and the citations therein) which also considers the instance dependent noise case.\n\n3. Under what conditions does the proposed algorithm converge and to what does it converge to?\n\n4. The proposed method relies on several assumptions that are scattered throughout the description of the algorithm. I highly recommend making these assumptions clear near the beginning of the paper. Specifically, my understanding is that the main assumptions are:\n\ni. Confidence scores r_x are available for each instance and r_x \\approx P(Y=y|\\bar{Y}=y,X=x).\nii. Y _|_ X | Y\\neq\\bar{Y}, \\bar{Y} = y\niii. Anchor points are available on some portion of the data.\n\nBeyond the presentation, I find this to be a fairly strong set of assumptions, particularly the first assumption. \n\n--- Minor comments ---\n\n1. I really appreciated the synthetic example demonstrating the potential pitfalls of the small loss approach; however, I would spend a bit more time clearly explaining the small loss approach so that readers understand why it fails and how you are solving it's problems.\n\n2. Also in the synthetic example, the authors state that covariate shift leads poor accuracy, however, I think this point would be stronger if demonstrated instead of just asserted.", "Learning with noise labels is a hot topic now due to the reason that deep learning algorithms often require large-scale supervised training samples and labelling a large amount of data is costly. However, almost all of the existing methods assume that the label noise is instance-independent. It either depends on the clean classes or is completely random. This paper studies the instance-dependent label noise, which is more realistic and applicable, but difficulty to address. The authors target to solve this problem. A feasible solution would contribute to the community a lot.\n\nThe challenging part for dealing with instance-dependent label noise is to learn the instance-dependent label flip function, which is hard to learn by only exploiting noisy data without any assumption. Few existing papers proposed assumptions to make the flip function learnable. This paper also introduces an assumption that the confidence score for each data is given. To me, this is also a strong assumption. Although the authors have provided examples of how to collect confidence score, collecting confidence scores may not be easy for many specific problems. \n\nGiven the confidence score, the authors proposed to learn the flip function. The clean class posterior can be inferred by using the noisy class posterior and the label flip function. So, how to learn the instance-dependent flip function is an essential step. Some technical contribution has been made to learn the flip function. In this section, the authors further assume that the off-diagonal entries of the flip matrix are independent of instance. After seeing the explanation, I personally agree that the assumption is reasonable for some cases. However, I found that in the experiments, the authors synthesized label noise where the off-diagonal entries depend on the instance. The proposed method also shows its advantages on this case. Can you explain this?\n\nThe experiment parts show the effectiveness of the proposed method both on synthetic data and real-world data. Overall, the paper is well-motivated and well-written. \n\nI have another concern that the obtained confidence score may not accurate. Is the proposed method sensitive to the confidence scores?\n"], "review_score_variance": 10.888888888888891, "summary": "While two reviewers  rated this paper as an accept, reviewer 3 strongly believes there are unresolved issues with the work as summarized in their post-rebuttal review. This work seems very promising and while the AC will recommend rejection at this time, the authors are strongly encouraged to resubmit this work.", "paper_id": "iclr_2020_SyevDaVYwr", "label": "val", "paper_acceptance": "reject"}
